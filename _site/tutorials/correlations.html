<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>R Programming @ UC</title>
    <meta name="description" content="">

    <link rel="stylesheet" href="http://r-uc.github.io//css/main.css">
    <link rel="canonical" href="http://r-uc.github.io/http://r-uc.github.io//tutorials/correlations">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="http://r-uc.github.io/">R Programming @ UC</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="http://r-uc.github.io//404">404 - Page not found</a>
          
        
          
          <a class="page-link" href="http://r-uc.github.io//about/">About</a>
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="http://r-uc.github.io//categoryview/">Archive</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="http://r-uc.github.io//cv/">CV</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="http://r-uc.github.io//tutorials/">Tutorials</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="http://r-uc.github.io//tutorials/scraping_with_apis_DSCOE.Rmd">Scraping Data with APIs</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <article class="post-content">
    <p><a href="index">R Vocab Topics</a> » <a href="analytics">Analytics</a> » Correlations</p>

<p><br /></p>

<p>Correlation is a bivariate analysis that measures the extent that two variables are related (“co-related”) to one another. The value of the correlation coefficient varies between +1 and -1. When the value of the correlation coefficient lies around ±1, then it is said to be a perfect degree of association between the two variables (near +1 implies a strong positive association and near -1 implies a strong negative association). As the correlation coefficient nears 0, the relationship between the two variables weakens with a near 0 value implying no association between the two variables. This tutorial covers the different ways to visualize and assess correlation.</p>

<center>
<img src="/public/images/analytics/correlation/correlation_icon.png" alt="Correlation Matrix" />
</center>

<p><br /></p>

<h1 id="tldr">tl;dr</h1>
<p>This tutorial serves as an introduction to assessing correlation between variables. First, I provide the data and packages required to replicate the analysis and then I walk through the ways to visualize associations followed by demonstrating four different approaches to assess correlations.</p>

<ol>
  <li><a href="#replication">Replication requirements</a>: What you’ll need to reproduce the analysis in this tutorial.</li>
  <li><a href="#visualization">Visualizing relationships</a>: Dots can tell you a lot about a relationship, so why not start with them?</li>
  <li><a href="#pearson">Pearson’s correlation</a>: Measure the strength of the linear relationship between two variables. This approach is so widely used that when most people refer to correlation they are referring to the Pearson product-moment correlation approach.</li>
  <li><a href="#spearman">Spearman’s Rank correlation</a>: A non-parametric approach that does not assume any assumptions about the distribution of the data. Great when variables are measured on an ordinal scale.</li>
  <li><a href="#kendall">Kendall’s tau</a>: Another non-parametric approach. Less sensitive to outliers and more accurate with smaller sample sizes.</li>
  <li><a href="#partial">Partial correlation</a>: Measuring the relationship between two variables while controlling for the effect of one or more covariates.</li>
</ol>

<p><br /></p>

<h2 id="replication">Replication Requirements</h2>
<p>This tutorial leverages the following packages:</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">readxl</span><span class="p">)</span>         <span class="c1"># reading in data
</span><span class="n">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span>        <span class="c1"># visualizing data
</span><span class="n">library</span><span class="p">(</span><span class="n">gridExtra</span><span class="p">)</span>      <span class="c1"># combining multiple plots
</span><span class="n">library</span><span class="p">(</span><span class="n">corrgram</span><span class="p">)</span>       <span class="c1"># visualizing data       
</span><span class="n">library</span><span class="p">(</span><span class="n">corrplot</span><span class="p">)</span>       <span class="c1"># visualizing data       
</span><span class="n">library</span><span class="p">(</span><span class="n">Hmisc</span><span class="p">)</span>          <span class="c1"># produces correlation matrices with p-values
</span><span class="n">library</span><span class="p">(</span><span class="n">ppcor</span><span class="p">)</span>          <span class="err">#</span> <span class="n">assesses</span> <span class="n">partial</span> <span class="n">correlations</span></code></pre></figure>

<p>To illustrate ways to visualize correlation and compute the statistics, I will demonstrate with some <a href="https://www.dropbox.com/s/t8uxau3sanra2f0/Golf%20Stats.xlsx?dl=0">golf data</a> provided by <a href="http://espn.go.com/golf/statistics">ESPN</a> and also with some artifical <a href="https://www.dropbox.com/s/2ahf1ixgm97la5s/Survey_Results.xlsx?dl=0">survey data</a>. The golf data has 18 variables, which you can see the first 9 below; and the survey data has 11.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">readxl</span><span class="p">)</span>

<span class="n">golf</span> <span class="o">&lt;-</span> <span class="n">read_excel</span><span class="p">(</span><span class="s2">"Golf Stats.xlsx"</span><span class="p">,</span> <span class="n">sheet</span> <span class="o">=</span> <span class="s2">"2011"</span><span class="p">)</span>

<span class="n">head</span><span class="p">(</span><span class="n">golf</span><span class="p">[,</span> <span class="m">1</span><span class="o">:</span><span class="m">9</span><span class="p">])</span>
<span class="c1">##   Rank         Player Age Events Rounds Cuts Made Top 10s Wins Earnings
## 1    1    Luke Donald  34     19     67        17      14    2  6683214
## 2    2   Webb Simpson  26     26     98        23      12    2  6347354
## 3    3    Nick Watney  30     22     77        19      10    2  5290674
## 4    4      K.J. Choi  41     22     75        18       8    1  4434690
## 5    5 Dustin Johnson  27     21     71        17       6    1  4309962
## 6    6    Matt Kuchar  33     24     88        22       9    0  4233920
</span>
<span class="n">survey</span> <span class="o">&lt;-</span> <span class="n">read_excel</span><span class="p">(</span><span class="s2">"Survey_Results.xlsx"</span><span class="p">,</span> <span class="n">sheet</span> <span class="o">=</span> <span class="s2">"Sheet1"</span><span class="p">,</span> <span class="n">skip</span> <span class="o">=</span> <span class="m">2</span><span class="p">)</span>

<span class="n">head</span><span class="p">(</span><span class="n">survey</span><span class="p">)</span>
<span class="c1">##   Observation Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10
## 1           1  1 -1  1  0  1  1  1  0  0   0
## 2           2  1 -1  2 -2  1  1  0  0  0   1
## 3           3  0  0  3 -1 -1  0 -1  0  1   0
## 4           4  0  0  3  0  1  1 -1  0  1   1
## 5           5  0 -1  2 -1 -1 -1 -1 -1 -1  -1
</span><span class="err">##</span> <span class="m">6</span>           <span class="m">6</span>  <span class="m">2</span>  <span class="m">1</span>  <span class="m">2</span> <span class="m">-1</span>  <span class="m">1</span>  <span class="m">0</span>  <span class="m">1</span>  <span class="m">0</span>  <span class="m">1</span>   <span class="m">1</span></code></pre></figure>

<p><br /></p>

<h2 id="visualization">Visualizing Bivariate Relationships</h2>
<p>A correlation is a single-number measure of the relationship between two variables. Although a very useful measure, it can be hard to image exactly what the association is between two variables based on this single statistic. In contrast, a scatterplot of two variables provides a vivid illustration of the relationship between two variables. In short, a scatterplot can convey much more information than a single correlation coefficient. For instance, the following scatter plot illustrates just how strongly rounds played and events played are associated in a positive fashion.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">qplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">Events</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">Rounds</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">golf</span><span class="p">)</span> <span class="o">+</span>
        <span class="n">geom_smooth</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s2">"lm"</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="n">FALSE</span><span class="p">)</span> <span class="o">+</span>
        <span class="n">ggtitle</span><span class="p">(</span><span class="s2">"Fig. A: Strong Positive Association"</span><span class="p">)</span></code></pre></figure>

<p><img src="/public/images/analytics/correlation/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /></p>

<p>Contrast this to the following two plots which shows as driving accuracy increases the distance of the player’s drive tends to decrease (Fig. B) but this association is far weaker than we saw above due to greater variance around the trend line. In addition we can easily see that as a player’s age increases their greens in regulation percentage does not appear to change (Fig. C).</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">gridExtra</span><span class="p">)</span>

<span class="n">p1</span> <span class="o">&lt;-</span> <span class="n">qplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="sb">`Driving Accuracy`</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="sb">`Yards/Drive`</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">golf</span><span class="p">)</span> <span class="o">+</span>
        <span class="n">geom_smooth</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s2">"lm"</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="n">FALSE</span><span class="p">)</span> <span class="o">+</span>
        <span class="n">ggtitle</span><span class="p">(</span><span class="s2">"Fig. B: Moderate Negative Association"</span><span class="p">)</span>

<span class="n">p2</span> <span class="o">&lt;-</span> <span class="n">qplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">Age</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="sb">`Greens in Regulation`</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">golf</span><span class="p">)</span> <span class="o">+</span>
        <span class="n">geom_smooth</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s2">"lm"</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="n">FALSE</span><span class="p">)</span> <span class="o">+</span>
        <span class="n">ggtitle</span><span class="p">(</span><span class="s2">"Fig. C: Weak/No Association"</span><span class="p">)</span>

<span class="n">grid.arrange</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">2</span><span class="p">)</span></code></pre></figure>

<p><img src="/public/images/analytics/correlation/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /></p>

<p>In addition, scatter plots illustrate the linearity of the relationship, which can influence how you approach assessing correlations (i.e. data transformation, using a parametric vs non-parametric test, removing outliers). <a href="https://en.wikipedia.org/wiki/Frank_Anscombe">Francis Anscombe</a> illustrated this in 1973<sup id="fnref:anscombe"><a href="#fn:anscombe" class="footnote">1</a></sup> when he constructed four data sets that have the same mean, variance, and correlation; however, there are significant differences in the variable relationships. Using the <code class="highlighter-rouge">anscombe</code> data, which R has as a built in data set, the plots below demonstrate the importance of graphing data rather than just relying on correlation coefficients. Each x-y combination in the plot below has a correlation of .82 (strong positive) but there are definitely differences in the association between these variables.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">gridExtra</span><span class="p">)</span>
<span class="n">library</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>

<span class="n">p1</span> <span class="o">&lt;-</span> <span class="n">qplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y1</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">anscombe</span><span class="p">)</span>
<span class="n">p2</span> <span class="o">&lt;-</span> <span class="n">qplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y2</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">anscombe</span><span class="p">)</span>
<span class="n">p3</span> <span class="o">&lt;-</span> <span class="n">qplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x3</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y3</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">anscombe</span><span class="p">)</span>
<span class="n">p4</span> <span class="o">&lt;-</span> <span class="n">qplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x4</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y4</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">anscombe</span><span class="p">)</span>

<span class="n">grid.arrange</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">p3</span><span class="p">,</span> <span class="n">p4</span><span class="p">,</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">2</span><span class="p">,</span> 
             <span class="n">top</span> <span class="o">=</span> <span class="n">textGrob</span><span class="p">(</span><span class="s2">"Anscombe's Quartet"</span><span class="p">))</span></code></pre></figure>

<p><img src="/public/images/analytics/correlation/unnamed-chunk-6-1.png" style="display: block; margin: auto;" /></p>

<p>Visualization can also give you a quick approach to assessing multiple relationships. We can produce scatter plot matrices multiple ways to visualize and compare relationships across the entire data set we are analyzing. With base R plotting we can use the <code class="highlighter-rouge">pairs()</code> function. Lets look at the first 10 variables of the golf data set (minus the player name variable). You can instantly see those variables that are strongly associated (i.e. Events, Rounds, Cuts Made), not associated (i.e. Rank, Age, Events), nonlinearly associated (i.e. Rank, Top 10s), or categorical in nature (Wins).</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">pairs</span><span class="p">(</span><span class="n">golf</span><span class="p">[,</span> <span class="n">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">3</span><span class="o">:</span><span class="m">10</span><span class="p">)])</span></code></pre></figure>

<p><img src="/public/images/analytics/correlation/unnamed-chunk-8-1.png" style="display: block; margin: auto;" /></p>

<p>There are multiple ways to produce scatter plot matrices such as these.  Additional means includes the <a href="https://cran.r-project.org/web/packages/corrgram/index.html">corrgram</a> and <a href="https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html">corrplot</a> packages. Note that multiple options exist with both these visualizations (i.e. formatting, correlation method applied, illustrating significance and confidence intervals, etc.) so they are worth exploring.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">corrgram</span><span class="p">)</span>

<span class="n">par</span><span class="p">(</span><span class="n">bg</span> <span class="o">=</span> <span class="s2">"#fdfdfd"</span><span class="p">)</span>
<span class="n">corrgram</span><span class="p">(</span><span class="n">golf</span><span class="p">[,</span> <span class="n">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">3</span><span class="o">:</span><span class="m">10</span><span class="p">)],</span> <span class="n">lower.panel</span> <span class="o">=</span> <span class="n">panel.shade</span><span class="p">,</span> <span class="n">upper.panel</span> <span class="o">=</span> <span class="n">panel.pts</span><span class="p">)</span></code></pre></figure>

<p><img src="/public/images/analytics/correlation/unnamed-chunk-10-1.png" style="display: block; margin: auto;" /></p>

<p>For <code class="highlighter-rouge">corrplot</code> you must first compute the correlation matrix and then feed that information into the graphic function.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">corrplot</span><span class="p">)</span>

<span class="n">cor_matrix</span> <span class="o">&lt;-</span> <span class="n">cor</span><span class="p">(</span><span class="n">golf</span><span class="p">[,</span> <span class="n">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">3</span><span class="o">:</span><span class="m">10</span><span class="p">)],</span> <span class="n">use</span> <span class="o">=</span> <span class="s1">'complete.obs'</span><span class="p">)</span>
<span class="n">corrplot.mixed</span><span class="p">(</span><span class="n">cor_matrix</span><span class="p">,</span> <span class="n">lower</span> <span class="o">=</span> <span class="s2">"circle"</span><span class="p">,</span> <span class="n">upper</span> <span class="o">=</span> <span class="s2">"number"</span><span class="p">,</span> <span class="n">tl.pos</span> <span class="o">=</span> <span class="s2">"lt"</span><span class="p">,</span> <span class="n">diag</span> <span class="o">=</span> <span class="s2">"u"</span><span class="p">)</span></code></pre></figure>

<p><img src="/public/images/analytics/correlation/unnamed-chunk-12-1.png" style="display: block; margin: auto;" /></p>

<p>Once you’ve visualized the data and understand the associations that appear to be present and their attributes (strength, outliers, linearity) you can begin assessing the statistical relationship by applying the appropriate correlation method.</p>

<p><a href="#top">Go to top</a></p>

<p><br /></p>

<h2 id="pearson">Pearson’s Correlation</h2>
<p>The Pearson correlation is so widely used that when most people refer to correlation they are referring to the Pearson approach. The Pearson product-moment correlation coefficient measures the strength of the linear relationship between two variables and is represented by <em>r</em> when referring to a sample or ρ when referring to the population. Considering we most often deal with samples I’ll use <em>r</em> unless otherwise noted.</p>

<p>Unfortunately, the assumptions for Pearson’s correlation are often overlooked. These assumptions include:</p>

<ul>
  <li>Level of measurement: The variables should be continuous. If one or both of the variables are ordinal in measurement, then a <a href="#spearman">Spearman rank correlation</a> should be conducted.</li>
  <li>Linear relationship: The variables need to be linearly related. If they are not, the data could be transformed (i.e. logarithmic transformation) or a non-parametric approach such as the  <a href="#spearman">Spearman’s</a> or <a href="#kendall">Kendall’s</a> rank correlation tests could be used.</li>
  <li>Homoscedasticity: If the variance between the two variables is not constant then <em>r</em> will not provide a good measure of association.</li>
  <li>Bivariate Normality: Technically, Pearson’s $r$ does not require normality when the sample size is fairly large; however, when the variables consist of high levels of skewness or contain significant outliers it is recommended to use <a href="#spearman">Spearman’s rank correlation</a> or, at a minimum, compare Pearson’s and Spearman’s coefficients.</li>
</ul>

<p>R provides multiple functions to analyze correlations.  To calculate the correlation between two variables we use <code class="highlighter-rouge">cor()</code>.  When using <code class="highlighter-rouge">cor()</code> there are two arguments (other than the variables) that need to be considered.  The first is <code class="highlighter-rouge">use =</code> which allows us to decide how to handle missing data. The default is <code class="highlighter-rouge">use = everything</code> but if there is missing data in your data set this will cause the output to be <code class="highlighter-rouge">NA</code> unless we explicitly state to only use complete observations with <code class="highlighter-rouge">use = complete.obs</code>. The second argument is <code class="highlighter-rouge">method =</code> which allows us to specify if we want to use “pearson”, “kendall”, or “spearman”. Pearson is the default method so we do not need to specify for that option.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># If we don't filter out NAs we get NA in return
</span><span class="n">cor</span><span class="p">(</span><span class="n">golf</span><span class="o">$</span><span class="n">Age</span><span class="p">,</span> <span class="n">golf</span><span class="o">$</span><span class="sb">`Yards/Drive`</span><span class="p">)</span>
<span class="c1">## [1] NA
</span>
<span class="c1"># Filter NAs to get correlation for complete observations
</span><span class="n">cor</span><span class="p">(</span><span class="n">golf</span><span class="o">$</span><span class="n">Age</span><span class="p">,</span> <span class="n">golf</span><span class="o">$</span><span class="sb">`Yards/Drive`</span><span class="p">,</span> <span class="n">use</span> <span class="o">=</span> <span class="s1">'complete.obs'</span><span class="p">)</span>
<span class="c1">## [1] -0.3960891
</span>
<span class="c1"># We can also get the correlation matrix for multiple variables but we need
# to exclude any non-numeric values
</span><span class="n">cor</span><span class="p">(</span><span class="n">golf</span><span class="p">[,</span> <span class="n">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">3</span><span class="o">:</span><span class="m">10</span><span class="p">)],</span> <span class="n">use</span> <span class="o">=</span> <span class="s1">'complete.obs'</span><span class="p">)</span>
<span class="c1">##                   Rank        Age      Events      Rounds  Cuts Made
## Rank         1.0000000  0.2178987 -0.25336860 -0.39896409 -0.6340634
## Age          0.2178987  1.0000000 -0.11910802 -0.14056653 -0.1950816
## Events      -0.2533686 -0.1191080  1.00000000  0.96635795  0.7614576
## Rounds      -0.3989641 -0.1405665  0.96635795  1.00000000  0.8913155
## Cuts Made   -0.6340634 -0.1950816  0.76145761  0.89131554  1.0000000
## Top 10s     -0.8033446 -0.2052073  0.17710952  0.30790212  0.5255005
## Wins        -0.5765412 -0.1753386  0.04591368  0.12215216  0.2460359
## Earnings    -0.8585013 -0.2175656  0.15208235  0.29048622  0.5289126
## Yards/Drive -0.3008188 -0.3960891 -0.02052854  0.03470326  0.1465976
##                Top 10s        Wins   Earnings Yards/Drive
## Rank        -0.8033446 -0.57654121 -0.8585013 -0.30081875
## Age         -0.2052073 -0.17533858 -0.2175656 -0.39608914
## Events       0.1771095  0.04591368  0.1520823 -0.02052854
## Rounds       0.3079021  0.12215216  0.2904862  0.03470326
## Cuts Made    0.5255005  0.24603589  0.5289126  0.14659757
## Top 10s      1.0000000  0.49398282  0.8957970  0.19397586
## Wins         0.4939828  1.00000000  0.7313615  0.21563889
## Earnings     0.8957970  0.73136149  1.0000000  0.25041021
</span><span class="err">##</span> <span class="n">Yards</span><span class="o">/</span><span class="n">Drive</span>  <span class="m">0.1939759</span>  <span class="m">0.21563889</span>  <span class="m">0.2504102</span>  <span class="m">1.00000000</span></code></pre></figure>

<p>Unfortunately <code class="highlighter-rouge">cor()</code> only provides the <em>r</em> coefficient(s) and does not test for significance nor provide confidence intervals.  To get these parameters for a simple two variable analysis I use <code class="highlighter-rouge">cor.test()</code>.  In our example we see that the <em>p</em>-value is significant and the 95% confidence interval confirms this as the range does not contain zero. This suggests the correlation between age and yards per drive is <em>r</em> = -0.396 with 95% confidence of being between -0.27 and -0.51.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">cor.test</span><span class="p">(</span><span class="n">golf</span><span class="o">$</span><span class="n">Age</span><span class="p">,</span> <span class="n">golf</span><span class="o">$</span><span class="sb">`Yards/Drive`</span><span class="p">,</span> <span class="n">use</span> <span class="o">=</span> <span class="s1">'complete.obs'</span><span class="p">)</span>
<span class="c1">## 
## 	Pearson's product-moment correlation
## 
## data:  golf$Age and golf$`Yards/Drive`
## t = -5.8355, df = 183, p-value = 2.394e-08
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.5111490 -0.2670825
## sample estimates:
##        cor 
</span><span class="err">##</span> <span class="m">-0.3960891</span></code></pre></figure>

<p>We can also get the correlation matrix and the <em>p</em>-values across all variables by using the <code class="highlighter-rouge">rcorr()</code> function in the <a href="https://cran.r-project.org/package=Hmisc">Hmisc</a> package. This function will provide the correlation matrix, number of pairwise observations used, and the <em>p</em>-values. Note that <code class="highlighter-rouge">rcorr()</code> does not provide confidence intervals like <code class="highlighter-rouge">cor.test()</code>.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">Hmisc</span><span class="p">)</span>
<span class="n">rcorr</span><span class="p">(</span><span class="n">as.matrix</span><span class="p">(</span><span class="n">golf</span><span class="p">[,</span> <span class="n">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">3</span><span class="o">:</span><span class="m">9</span><span class="p">)]))</span>
<span class="c1">##            Rank   Age Events Rounds Cuts Made Top 10s  Wins Earnings
## Rank       1.00  0.21  -0.23  -0.38     -0.63   -0.80 -0.58    -0.86
## Age        0.21  1.00  -0.09  -0.12     -0.17   -0.20 -0.17    -0.21
## Events    -0.23 -0.09   1.00   0.97      0.75    0.16  0.04     0.14
## Rounds    -0.38 -0.12   0.97   1.00      0.88    0.29  0.12     0.28
## Cuts Made -0.63 -0.17   0.75   0.88      1.00    0.52  0.25     0.53
## Top 10s   -0.80 -0.20   0.16   0.29      0.52    1.00  0.50     0.89
## Wins      -0.58 -0.17   0.04   0.12      0.25    0.50  1.00     0.73
## Earnings  -0.86 -0.21   0.14   0.28      0.53    0.89  0.73     1.00
## 
## n
##           Rank Age Events Rounds Cuts Made Top 10s Wins Earnings
## Rank       200 188    200    200       200     200  200      200
## Age        188 188    188    188       188     188  188      188
## Events     200 188    200    200       200     200  200      200
## Rounds     200 188    200    200       200     200  200      200
## Cuts Made  200 188    200    200       200     200  200      200
## Top 10s    200 188    200    200       200     200  200      200
## Wins       200 188    200    200       200     200  200      200
## Earnings   200 188    200    200       200     200  200      200
## 
## P
##           Rank   Age    Events Rounds Cuts Made Top 10s Wins   Earnings
## Rank             0.0045 0.0011 0.0000 0.0000    0.0000  0.0000 0.0000  
## Age       0.0045        0.1978 0.1084 0.0164    0.0056  0.0197 0.0041  
## Events    0.0011 0.1978        0.0000 0.0000    0.0238  0.5953 0.0499  
## Rounds    0.0000 0.1084 0.0000        0.0000    0.0000  0.0953 0.0000  
## Cuts Made 0.0000 0.0164 0.0000 0.0000           0.0000  0.0003 0.0000  
## Top 10s   0.0000 0.0056 0.0238 0.0000 0.0000            0.0000 0.0000  
## Wins      0.0000 0.0197 0.5953 0.0953 0.0003    0.0000         0.0000  
</span><span class="err">##</span> <span class="n">Earnings</span>  <span class="m">0.0000</span> <span class="m">0.0041</span> <span class="m">0.0499</span> <span class="m">0.0000</span> <span class="m">0.0000</span>    <span class="m">0.0000</span>  <span class="m">0.0000</span></code></pre></figure>

<p><a href="#top">Go to top</a></p>

<p><br /></p>

<h2 id="spearman">Spearman’s Rank Correlation</h2>
<p>The Spearman rank correlation, represented by ρ, is a non-parametric test that measures the degree of association between two variables based on using a monotonic function. The Spearman approach does not assume any assumptions about the distribution of the data and is the appropriate correlation analysis when the variables are measured on an ordinal scale.  Consequently, common questions that a Spearman correlation answers includes: Is there a statistically significant relationship between the age of a golf player and the number of wins (0, 1, 2)? Is there a statistically significant relationship between participant responses to two Likert scaled questions on a survey?</p>

<p>The assumptions for Spearman’s correlation include:</p>

<ul>
  <li>Level of measurement: The normal assumption is that one or both of the variables are ordinal in measurement; however, Spearman’s is also appropriate to use if both variables are continuous but are heavily skewed or contain sizable outliers.</li>
  <li>Montonically related: A linear relationship is not necessary, the only requirement is that one variable is montonically related to the other variable.</li>
</ul>

<p>To assess correlations with Spearman’s rank we can use the same functions introduced for the <a href="#pearson">Pearson correlations</a> and simply change the correlation method. To illustrate, we’ll assess results from our artificial survey data in which the questions are answered on a 5 point Likert scale (Never: -2, Rarely: -1, Sometimes: 0, Often: 1, All the time: 2):</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1">##   Observation Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10
## 1           1  1 -1  1  0  1  1  1  0  0   0
## 2           2  1 -1  2 -2  1  1  0  0  0   1
## 3           3  0  0  3 -1 -1  0 -1  0  1   0
## 4           4  0  0  3  0  1  1 -1  0  1   1
## 5           5  0 -1  2 -1 -1 -1 -1 -1 -1  -1
</span><span class="err">##</span> <span class="m">6</span>           <span class="m">6</span>  <span class="m">2</span>  <span class="m">1</span>  <span class="m">2</span> <span class="m">-1</span>  <span class="m">1</span>  <span class="m">0</span>  <span class="m">1</span>  <span class="m">0</span>  <span class="m">1</span>   <span class="m">1</span></code></pre></figure>

<p>To assess the correlation between any two questions or create a correlation matrix across all questions we can use the <code class="highlighter-rouge">cor()</code>, <code class="highlighter-rouge">cor.test()</code>, and <code class="highlighter-rouge">rcorr()</code> (<a href="https://cran.r-project.org/package=Hmisc">Hmisc</a> package) functions and simply specify <code class="highlighter-rouge">method = 'spearman'</code>:</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># correlation between any two questions
</span><span class="n">cor</span><span class="p">(</span><span class="n">survey_data</span><span class="o">$</span><span class="n">Q1</span><span class="p">,</span> <span class="n">survey_data</span><span class="o">$</span><span class="n">Q2</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s1">'spearman'</span><span class="p">)</span>
<span class="c1">## [1] 0.3414006
</span>
<span class="c1"># assessing p-value
</span><span class="n">cor.test</span><span class="p">(</span><span class="n">survey_data</span><span class="o">$</span><span class="n">Q1</span><span class="p">,</span> <span class="n">survey_data</span><span class="o">$</span><span class="n">Q2</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s1">'spearman'</span><span class="p">)</span>
<span class="c1">## 
## 	Spearman's rank correlation rho
## 
## data:  survey_data$Q1 and survey_data$Q2
## S = 3266.7, p-value = 0.06016
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.3414006
</span>
<span class="c1"># Correlation matrix and p-values across all questions
</span><span class="n">rcorr</span><span class="p">(</span><span class="n">as.matrix</span><span class="p">(</span><span class="n">survey_data</span><span class="p">[,</span> <span class="m">-1</span><span class="p">]),</span> <span class="n">type</span> <span class="o">=</span> <span class="s1">'spearman'</span><span class="p">)</span>
<span class="c1">##        Q1    Q2    Q3    Q4    Q5   Q6    Q7    Q8    Q9   Q10
## Q1   1.00  0.34 -0.36 -0.09  0.31 0.31  0.24  0.30  0.25  0.35
## Q2   0.34  1.00  0.11 -0.22  0.04 0.01  0.21  0.59  0.32  0.14
## Q3  -0.36  0.11  1.00  0.13 -0.27 0.02 -0.12 -0.22 -0.16 -0.01
## Q4  -0.09 -0.22  0.13  1.00  0.23 0.17  0.17 -0.36 -0.13 -0.25
## Q5   0.31  0.04 -0.27  0.23  1.00 0.58  0.36  0.28  0.36  0.42
## Q6   0.31  0.01  0.02  0.17  0.58 1.00  0.33  0.31  0.33  0.63
## Q7   0.24  0.21 -0.12  0.17  0.36 0.33  1.00  0.27  0.24  0.12
## Q8   0.30  0.59 -0.22 -0.36  0.28 0.31  0.27  1.00  0.47  0.37
## Q9   0.25  0.32 -0.16 -0.13  0.36 0.33  0.24  0.47  1.00  0.39
## Q10  0.35  0.14 -0.01 -0.25  0.42 0.63  0.12  0.37  0.39  1.00
## 
## n
##     Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10
## Q1  31 31 30 31 31 31 31 31 31  31
## Q2  31 31 30 31 31 31 31 31 31  31
## Q3  30 30 30 30 30 30 30 30 30  30
## Q4  31 31 30 31 31 31 31 31 31  31
## Q5  31 31 30 31 31 31 31 31 31  31
## Q6  31 31 30 31 31 31 31 31 31  31
## Q7  31 31 30 31 31 31 31 31 31  31
## Q8  31 31 30 31 31 31 31 31 31  31
## Q9  31 31 30 31 31 31 31 31 31  31
## Q10 31 31 30 31 31 31 31 31 31  31
## 
## P
##     Q1     Q2     Q3     Q4     Q5     Q6     Q7     Q8     Q9     Q10   
## Q1         0.0602 0.0498 0.6406 0.0877 0.0871 0.1923 0.1044 0.1837 0.0535
## Q2  0.0602        0.5630 0.2353 0.8327 0.9364 0.2553 0.0004 0.0800 0.4424
## Q3  0.0498 0.5630        0.4853 0.1418 0.9129 0.5375 0.2514 0.4129 0.9585
## Q4  0.6406 0.2353 0.4853        0.2117 0.3700 0.3473 0.0450 0.4890 0.1813
## Q5  0.0877 0.8327 0.1418 0.2117        0.0007 0.0489 0.1343 0.0444 0.0175
## Q6  0.0871 0.9364 0.9129 0.3700 0.0007        0.0671 0.0860 0.0669 0.0002
## Q7  0.1923 0.2553 0.5375 0.3473 0.0489 0.0671        0.1410 0.1895 0.5218
## Q8  0.1044 0.0004 0.2514 0.0450 0.1343 0.0860 0.1410        0.0070 0.0423
## Q9  0.1837 0.0800 0.4129 0.4890 0.0444 0.0669 0.1895 0.0070        0.0293
</span><span class="err">##</span> <span class="n">Q10</span> <span class="m">0.0535</span> <span class="m">0.4424</span> <span class="m">0.9585</span> <span class="m">0.1813</span> <span class="m">0.0175</span> <span class="m">0.0002</span> <span class="m">0.5218</span> <span class="m">0.0423</span> <span class="m">0.0293</span></code></pre></figure>

<p><a href="#top">Go to top</a></p>

<p><br /></p>

<h2 id="kendall">Kendall’s tau</h2>
<p>Like Spearman’s rank correlation, Kendall’s tau is a non-parametric rank correlation that assesses statistical associations based on the ranks of the data. Therefore, the relevant questions that Kendall’s tau answers and the assumptions required are the same as discussed in the <a href="#spearman">Spearman’s Rank Correlation section</a>. The benefits of Kendall’s tau over Spearman’s is it is less sensitive to error and the <em>p</em>-values are more accurate with smaller sample sizes. However, in most of the situations, the interpretations of Kendall’s tau and Spearman’s rank correlation coefficient are very similar and thus invariably lead to the same inferences.</p>

<p>Similar to Spearman and Pearson, we apply the same functions and simply adjust the method type to calculate Kendall’s tau.  Using the same survey data as in the <a href="#spearman">Spearman example</a>, we can compute the correlations using <code class="highlighter-rouge">cor()</code> and <code class="highlighter-rouge">cor.test()</code>; however, <code class="highlighter-rouge">rcorr()</code> from the <a href="https://cran.r-project.org/package=Hmisc">Hmisc</a> package (illustrated in the <a href="#spearman">Spearman</a> and <a href="#pearson">Pearson</a> examples) does not compute Kendall’s tau.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># correlation between any two questions
</span><span class="n">cor</span><span class="p">(</span><span class="n">survey_data</span><span class="o">$</span><span class="n">Q1</span><span class="p">,</span> <span class="n">survey_data</span><span class="o">$</span><span class="n">Q2</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s1">'kendall'</span><span class="p">)</span>
<span class="c1">## [1] 0.3231124
</span>
<span class="c1"># assessing p-value
</span><span class="n">cor.test</span><span class="p">(</span><span class="n">survey_data</span><span class="o">$</span><span class="n">Q1</span><span class="p">,</span> <span class="n">survey_data</span><span class="o">$</span><span class="n">Q2</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s1">'kendall'</span><span class="p">)</span>
<span class="c1">## 
## 	Kendall's rank correlation tau
## 
## data:  survey_data$Q1 and survey_data$Q2
## z = 1.9325, p-value = 0.0533
## alternative hypothesis: true tau is not equal to 0
## sample estimates:
##       tau 
</span><span class="err">##</span> <span class="m">0.3231124</span></code></pre></figure>

<p><a href="#top">Go to top</a></p>

<p><br /></p>

<h2 id="partial">Partial Correlation</h2>
<p>Partial correlation is a measure of the strength and direction of association between two continuous variables while controlling for the effect of one or more other continuous variables (also known as ‘covariates’ or ‘control’ variables). Hence, it is used to find out the strength of the <strong>unique</strong> portion of association and answers questions such as: Is there a statistically significant relationship between driving accuracy and greens in regulation while controlling for driving distance?</p>

<p>Partial correlation can be performed with Pearson, Spearman, or Kendall’s correlation.  Consequently, the assumptions required must align with the assumptions previously outlined above for each of these correlation approaches. The functions I rely on to analyze partial correlations are from the <a href="https://cran.r-project.org/web/packages/ppcor/index.html">ppcor</a><sup id="fnref:semi"><a href="#fn:semi" class="footnote">2</a></sup> package. To illustrate, let’s go back to the golf data I’ve been using throughout this tutorial. We may be interested in assessing the relationship between driving distance and getting to the green in regulation. A simple correlation test suggests that there is no statistically significant relationship between the two. This may seem a bit paradoxical because you would think players who can drive the ball further off the tee box are more likely to get to the green in less strokes. However, as we saw in the visualization section, those players who drive the ball further are less accurate so this could also be influencing their ability to get to the green in regulation.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">cor.test</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">golf</span><span class="o">$</span><span class="sb">`Yards/Drive`</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">golf</span><span class="o">$</span><span class="sb">`Greens in Regulation`</span><span class="p">,</span> 
         <span class="n">use</span> <span class="o">=</span> <span class="s2">"complete.obs"</span><span class="p">)</span>
<span class="c1">## 
## 	Pearson's product-moment correlation
## 
## data:  golf$`Yards/Drive` and golf$`Greens in Regulation`
## t = 1.2591, df = 195, p-value = 0.2095
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.05063086  0.22674963
## sample estimates:
##        cor 
</span><span class="err">##</span> <span class="m">0.08980047</span></code></pre></figure>

<p>If we want to identify the unique measure of the relationship between yards per drive and greens in regulation then we need to control for driving accuracy; this is known as a <strong>first-order partial correlation</strong>.  We can do this by applying the <code class="highlighter-rouge">pcor.test()</code> function to assess the partial correlation between two specific variables controlling for a third; or we can use <code class="highlighter-rouge">pcor()</code> which provides the same information but for all variables assessed. The results illustrate that when we control for driving accuracy, the relationship between yards per drive and greens in regulation is significant.  The simple correlation suggested an <em>r</em> = 0.09 (<em>p</em>-value = 0.21); however, after controlling for driving accuracy the first-order correlation between yards per drive and greens in regulation is <em>r</em> = 0.40 (<em>p</em>-value &lt; 0.01). This makes sense as it suggests that when we hold driving accuracy constant, the length of drive is associated positively with getting to the green in regulation.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">ppcor</span><span class="p">)</span>

<span class="c1"># pcor() and pcor.test() do not accept missing values so you must filter them
# out prior to the function
</span><span class="n">golf_complete</span> <span class="o">&lt;-</span> <span class="n">na.omit</span><span class="p">(</span><span class="n">golf</span><span class="p">)</span>

<span class="c1"># assess partial correlation between x and y while controling for z
# use the argument method = `kendall` or method = `spearman` for non-parametric
# partial correlations
</span><span class="n">pcor.test</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">golf_complete</span><span class="o">$</span><span class="sb">`Yards/Drive`</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">golf_complete</span><span class="o">$</span><span class="sb">`Greens in Regulation`</span><span class="p">,</span> 
          <span class="n">z</span> <span class="o">=</span> <span class="n">golf_complete</span><span class="o">$</span><span class="sb">`Driving Accuracy`</span><span class="p">)</span>
<span class="c1">##    estimate      p.value statistic   n gp  Method
</span><span class="err">##</span> <span class="m">1</span> <span class="m">0.3962423</span> <span class="m">3.048395e-07</span>  <span class="m">5.355616</span> <span class="m">157</span>  <span class="m">1</span> <span class="n">pearson</span></code></pre></figure>

<p>What if we want to control for the effects of two (<em>second-order partial correlation</em>), three (<em>third-order partial correlation</em>), or more variables at the same time? For instance, what if we wanted to assess the correlation between yards per drive and greens in regulation while controlling for driving accuracy and age; then we just include all the control variables of concern (driving accuracy and age) in the <code class="highlighter-rouge">z</code> variable for <code class="highlighter-rouge">pcor.test()</code>. As we can see below, controlling for age appears to have very little impact on the relationship between yards per drive and greens in regulation.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># partial correlation
</span><span class="n">pcor.test</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">golf_complete</span><span class="o">$</span><span class="sb">`Yards/Drive`</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">golf_complete</span><span class="o">$</span><span class="sb">`Greens in Regulation`</span><span class="p">,</span> 
          <span class="n">z</span> <span class="o">=</span> <span class="n">golf_complete</span><span class="p">[,</span> <span class="n">c</span><span class="p">(</span><span class="s2">"Driving Accuracy"</span><span class="p">,</span> <span class="s2">"Age"</span><span class="p">)])</span>
<span class="c1">##    estimate      p.value statistic   n gp  Method
</span><span class="err">##</span> <span class="m">1</span> <span class="m">0.3802898</span> <span class="m">1.056049e-06</span>  <span class="m">5.086053</span> <span class="m">157</span>  <span class="m">2</span> <span class="n">pearson</span></code></pre></figure>

<p><a href="#top">Go to top</a></p>

<p><br /></p>

<h2 id="additional-resources">Additional Resources</h2>

<ul>
  <li><a href="http://www.amazon.com/Correlation-Parametric-Nonparametric-Quantitative-Applications/dp/0761922288">Correlation: Parametric and Nonparametric Measures</a></li>
  <li><a href="http://www.amazon.com/Fundamental-Statistics-Behavioral-Sciences-Howell/dp/1285076915">Fundamental Statistics for the Behavioral Sciences</a></li>
  <li><a href="http://www.amazon.com/Discovering-Statistics-Using-Andy-Field/dp/1446200469">Discovering Statistics Using R</a></li>
  <li><a href="http://www.jstor.org/stable/2346598">On the Effects of Non-normality on the Distribution of the Sample Product-Moment Correlation Coefficient</a></li>
</ul>

<p><a href="#top">Go to top</a></p>

<p><br /></p>

<div class="footnotes">
  <ol>
    <li id="fn:anscombe">
      <p>Anscombe, F. J. (1973). “Graphs in Statistical Analysis”. <em>American Statistician,</em> 27 (1): 17–21. <a href="https://www.jstor.org/stable/2682899?seq=1#page_scan_tab_contents">JSTOR 2682899</a> <a href="#fnref:anscombe" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:semi">
      <p>The <code class="highlighter-rouge">ppcor</code> package also performs semi-partial correlations which I do not cover in this tutorial. <a href="#fnref:semi" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">

      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
        <center>
          <li>
            <a href="https://github.com/bradleyboehmke">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>
            </a>
            &nbsp;
            <a href="http://www.twitter.com/bradleyboehmke">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>
            </a>
            &nbsp;
            <a href="https://www.linkedin.com/in/brad-boehmke-ph-d-9b0a257">
              <span class="icon  icon--linkedin">
                <svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"  width="25" height="25" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="#828282" d="M13.632 13.635h-2.37V9.922c0-.886-.018-2.025-1.234-2.025-1.235 0-1.424.964-1.424 1.96v3.778h-2.37V6H8.51V7.04h.03c.318-.6 1.092-1.233 2.247-1.233 2.4 0 2.845 1.58 2.845 3.637v4.188zM3.558 4.955c-.762 0-1.376-.617-1.376-1.377 0-.758.614-1.375 1.376-1.375.76 0 1.376.617 1.376 1.375 0 .76-.617 1.377-1.376 1.377zm1.188 8.68H2.37V6h2.376v7.635zM14.816 0H1.18C.528 0 0 .516 0 1.153v13.694C0 15.484.528 16 1.18 16h13.635c.652 0 1.185-.516 1.185-1.153V1.153C16 .516 15.467 0 14.815 0z" fill-rule="nonzero"/>
                </svg>
              </span>
            </a>
          </li>

        </ul>
        </center>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text"></p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
