<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Bradley Boehmke</title>
    <meta name="description" content="">

    <link rel="stylesheet" href="http://bradleyboehmke.github.io//css/main.css">
    <link rel="canonical" href="http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//tutorials/scraping_data_tabular_excel">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="http://bradleyboehmke.github.io/">Bradley Boehmke</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="http://bradleyboehmke.github.io//about/">About</a>
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="http://bradleyboehmke.github.io//categoryview/">Archive</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="http://bradleyboehmke.github.io//cv/">CV</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="http://bradleyboehmke.github.io//tutorials/">Tutorials</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="http://bradleyboehmke.github.io//tutorials/scraping_with_apis_DSCOE.Rmd">Scraping Data with APIs</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <article class="post-content">
    <p><a href="index">R Vocab Topics</a> » <a href="data_inputs_outputs">Importing, Scraping, and exporting data</a> » <a href="scraping_data">Scraping data</a> » Importing tabular and Excel files stored online</p>

<p><br /></p>

<p>The most basic form of getting data from online is to import tabular (i.e. .txt, .csv) or Excel files that are being hosted online. This is often not considered <em>web scraping</em><sup><a href="#fn1" id="ref1">1</a></sup>; however, I think its a good place to start introducing the user to interacting with the web for obtaining data. Importing tabular data is especially common for the many types of government data available online.  A quick perusal of <a href="https://www.data.gov/">Data.gov</a> illustrates nearly 188,510 examples. In fact, we can provide our first example of importing online tabular data by downloading the Data.gov CSV file that lists all the federal agencies that supply data to Data.gov.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># the url for the online CSV
</span><span class="n">url</span> <span class="o">&lt;-</span> <span class="s2">"https://www.data.gov/media/federal-agency-participation.csv"</span>

<span class="c1"># use read.csv to import
</span><span class="n">data_gov</span> <span class="o">&lt;-</span> <span class="n">read.csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stringsAsFactors</span> <span class="o">=</span> <span class="n">FALSE</span><span class="p">)</span>

<span class="c1"># for brevity I only display first 6 rows
</span><span class="n">data_gov</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">6</span><span class="p">,</span><span class="n">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">3</span><span class="o">:</span><span class="m">4</span><span class="p">)]</span>
<span class="c1">##                                      Agency.Name Datasets Last.Entry
## 1           Commodity Futures Trading Commission        3 01/12/2014
## 2           Consumer Financial Protection Bureau        2 09/26/2015
## 3           Consumer Financial Protection Bureau        2 09/26/2015
## 4 Corporation for National and Community Service        3 01/12/2014
## 5 Court Services and Offender Supervision Agency        1 01/12/2014
</span><span class="err">##</span> <span class="m">6</span>                      <span class="n">Department</span> <span class="n">of</span> <span class="n">Agriculture</span>      <span class="m">698</span> <span class="m">12</span><span class="o">/</span><span class="m">01</span><span class="o">/</span><span class="m">2015</span></code></pre></figure>

<p>Downloading Excel spreadsheets hosted online can be performed just as easily.  Recall that there is not a base R function for importing Excel data; however, several packages exist to handle this capability.  One package that works smoothly with pulling Excel data from urls is <a href="https://cran.r-project.org/web/packages/gdata/index.html"><code class="highlighter-rouge">gdata</code></a>.  With <code class="highlighter-rouge">gdata</code> we can use <code class="highlighter-rouge">read.xls()</code> to download this <a href="http://catalog.data.gov/dataset/fair-market-rents-for-the-section-8-housing-assistance-payments-program">Fair Market Rents for Section 8 Housing</a> Excel file from the given url.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">gdata</span><span class="p">)</span>

<span class="c1"># the url for the online Excel file
</span><span class="n">url</span> <span class="o">&lt;-</span> <span class="s2">"http://www.huduser.org/portal/datasets/fmr/fmr2015f/FY2015F_4050_Final.xls"</span>

<span class="c1"># use read.xls to import
</span><span class="n">rents</span> <span class="o">&lt;-</span> <span class="n">read.xls</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="n">rents</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">6</span><span class="p">,</span> <span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">]</span>
<span class="c1">##    fips2000  fips2010 fmr2 fmr0 fmr1 fmr3 fmr4 county State CouSub
## 1 100199999 100199999  788  628  663 1084 1288      1     1  99999
## 2 100399999 100399999  762  494  643 1123 1318      3     1  99999
## 3 100599999 100599999  670  492  495  834  895      5     1  99999
## 4 100799999 100799999  773  545  652 1015 1142      7     1  99999
## 5 100999999 100999999  773  545  652 1015 1142      9     1  99999
</span><span class="err">##</span> <span class="m">6</span> <span class="m">101199999</span> <span class="m">101199999</span>  <span class="m">599</span>  <span class="m">481</span>  <span class="m">505</span>  <span class="m">791</span> <span class="m">1061</span>     <span class="m">11</span>     <span class="m">1</span>  <span class="m">99999</span></code></pre></figure>

<p>Note that many of the arguments covered in the <a href="http://bradleyboehmke.github.io/tutorials/importing_data#excel">Importing Data tutorial</a> (i.e. specifying sheets to read from, skipping lines) also apply to <code class="highlighter-rouge">read.xls()</code>. In addition, <code class="highlighter-rouge">gdata</code> provides some useful functions (<code class="highlighter-rouge">sheetCount()</code> and <code class="highlighter-rouge">sheetNames()</code>) for identifying if multiple sheets exist prior to downloading.</p>

<p>Another common form of file storage is using zip files.  For instance, the <a href="http://www.bls.gov/home.htm">Bureau of Labor Statistics</a> (BLS) stores their <a href="http://www.bls.gov/cex/pumdhome.htm">public-use microdata</a> for the <a href="http://www.bls.gov/cex/home.htm">Consumer Expenditure Survey</a> in .zip files.  We can use <code class="highlighter-rouge">download.file()</code> to download the file to your working directory and then work with this data as desired.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">url</span> <span class="o">&lt;-</span> <span class="s2">"http://www.bls.gov/cex/pumd/data/comma/diary14.zip"</span>

<span class="c1"># download .zip file and unzip contents
</span><span class="n">download.file</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s2">"dataset.zip"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"wb"</span><span class="p">)</span> 
<span class="n">unzip</span> <span class="p">(</span><span class="s2">"dataset.zip"</span><span class="p">,</span> <span class="n">exdir</span> <span class="o">=</span> <span class="s2">"./"</span><span class="p">)</span>

<span class="c1"># assess the files contained in the .zip file which
# unzips as a folder named "diary14"
</span><span class="n">list.files</span><span class="p">(</span><span class="s2">"diary14"</span><span class="p">)</span>
<span class="c1">##  [1] "dtbd141.csv" "dtbd142.csv" "dtbd143.csv" "dtbd144.csv" "dtid141.csv"
##  [6] "dtid142.csv" "dtid143.csv" "dtid144.csv" "expd141.csv" "expd142.csv"
## [11] "expd143.csv" "expd144.csv" "fmld141.csv" "fmld142.csv" "fmld143.csv"
## [16] "fmld144.csv" "memd141.csv" "memd142.csv" "memd143.csv" "memd144.csv"
</span>
<span class="c1"># alternatively, if we know the file we want prior to unzipping
# we can extract the file without unzipping using unz():
</span><span class="n">zip_data</span> <span class="o">&lt;-</span> <span class="n">read.csv</span><span class="p">(</span><span class="n">unz</span><span class="p">(</span><span class="s2">"dataset.zip"</span><span class="p">,</span> <span class="s2">"diary14/expd141.csv"</span><span class="p">))</span>
<span class="n">zip_data</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">,</span> <span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">]</span>
<span class="c1">##     NEWID ALLOC COST GIFT PUB_FLAG    UCC EXPNSQDY EXPN_QDY EXPNWKDY   EXPN_KDY
## 1 2825371     0 6.26    2        2 190112        1        D        3        D
## 2 2825371     0 1.20    2        2 190322        1        D        3        D
## 3 2825381     0 0.98    2        2  20510        3        D        2        D
## 4 2825381     0 0.98    2        2  20510        3        D        2        D
</span><span class="err">##</span> <span class="m">5</span> <span class="m">2825381</span>     <span class="m">0</span> <span class="m">2.50</span>    <span class="m">2</span>        <span class="m">2</span>  <span class="m">20510</span>        <span class="m">3</span>        <span class="n">D</span>        <span class="m">2</span>        <span class="n">D</span></code></pre></figure>

<p>The .zip archive file format is meant to compress files and are typically used on files of significant size.  For instance, the Consumer Expenditure Survey data we downloaded in the previous example is over 10MB.  Obviously there may be times in which we want to get specific data in the .zip file to analyze but not always permanently store the entire .zip file contents. In these instances we can use the following <a href="http://stackoverflow.com/questions/3053833/using-r-to-download-zipped-data-file-extract-and-import-data">process</a> proposed by <a href="https://twitter.com/eddelbuettel">Dirk Eddelbuettel</a> to temporarily download the .zip file, extract the desired data, and then discard the .zip file.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># Create a temp. file name
</span><span class="n">temp</span> <span class="o">&lt;-</span> <span class="n">tempfile</span><span class="p">()</span>

<span class="c1"># Use download.file() to fetch the file into the temp. file
</span><span class="n">download.file</span><span class="p">(</span><span class="s2">"http://www.bls.gov/cex/pumd/data/comma/diary14.zip"</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>

<span class="c1"># Use unz() to extract the target file from temp. file
</span><span class="n">zip_data2</span> <span class="o">&lt;-</span> <span class="n">read.csv</span><span class="p">(</span><span class="n">unz</span><span class="p">(</span><span class="n">temp</span><span class="p">,</span> <span class="s2">"diary14/expd141.csv"</span><span class="p">))</span>

<span class="c1"># Remove the temp file via unlink()
</span><span class="n">unlink</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>

<span class="n">zip_data2</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">,</span> <span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">]</span>
<span class="c1">##     NEWID ALLOC COST GIFT PUB_FLAG    UCC EXPNSQDY EXPN_QDY EXPNWKDY   EXPN_KDY
## 1 2825371     0 6.26    2        2 190112        1        D        3        D
## 2 2825371     0 1.20    2        2 190322        1        D        3        D
## 3 2825381     0 0.98    2        2  20510        3        D        2        D
## 4 2825381     0 0.98    2        2  20510        3        D        2        D
</span><span class="err">##</span> <span class="m">5</span> <span class="m">2825381</span>     <span class="m">0</span> <span class="m">2.50</span>    <span class="m">2</span>        <span class="m">2</span>  <span class="m">20510</span>        <span class="m">3</span>        <span class="n">D</span>        <span class="m">2</span>        <span class="n">D</span></code></pre></figure>

<p>One last common scenario I’ll cover when importing spreadsheet data from online is when we identify multiple data sets that we’d like to download but are not centrally stored in a .zip format or the like. As a simple example lets look at the <a href="http://www.bls.gov/data/#prices">average consumer price data</a> from the BLS. The BLS holds multiple data sets for different types of commodities within one <a href="http://download.bls.gov/pub/time.series/ap/">url</a>; however, there are separate links for each individual data set.  More complicated cases of this will have the links to tabular data sets scattered throughout a webpage<sup><a href="#fn2" id="ref2">2</a></sup>. The <a href="https://cran.r-project.org/web/packages/XML/index.html"><code class="highlighter-rouge">XML</code></a> package provides the useful <code class="highlighter-rouge">getHTMLLinks()</code> function to identify these links.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">XML</span><span class="p">)</span>

<span class="c1"># url hosting multiple links to data sets
</span><span class="n">url</span> <span class="o">&lt;-</span> <span class="s2">"http://download.bls.gov/pub/time.series/ap/"</span>

<span class="c1"># identify the links available
</span><span class="n">links</span> <span class="o">&lt;-</span> <span class="n">getHTMLLinks</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="n">links</span>
<span class="c1">##  [1] "/pub/time.series/"                           
##  [2] "/pub/time.series/ap/ap.area"                 
##  [3] "/pub/time.series/ap/ap.contacts"             
##  [4] "/pub/time.series/ap/ap.data.0.Current"       
##  [5] "/pub/time.series/ap/ap.data.1.HouseholdFuels"
##  [6] "/pub/time.series/ap/ap.data.2.Gasoline"      
##  [7] "/pub/time.series/ap/ap.data.3.Food"          
##  [8] "/pub/time.series/ap/ap.footnote"             
##  [9] "/pub/time.series/ap/ap.item"                 
## [10] "/pub/time.series/ap/ap.period"               
## [11] "/pub/time.series/ap/ap.series"               
</span><span class="err">##</span> <span class="p">[</span><span class="m">12</span><span class="p">]</span> <span class="s2">"/pub/time.series/ap/ap.txt"</span></code></pre></figure>

<p>This allows us to assess which files exist that may be of interest.  In this case the links that we are primarily interested in are the ones that contain “data” in their name (links 4-7 listed above).  We can use the <a href="https://cran.r-project.org/web/packages/stringr/index.html"><code class="highlighter-rouge">stringr</code></a> package to extract these desired links which we will use to download the data.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">stringr</span><span class="p">)</span>

<span class="c1"># extract names for desired links and paste to url
</span><span class="n">links_data</span> <span class="o">&lt;-</span> <span class="n">links</span><span class="p">[</span><span class="n">str_detect</span><span class="p">(</span><span class="n">links</span><span class="p">,</span> <span class="s2">"data"</span><span class="p">)]</span>

<span class="c1"># paste url to data links to have full url for data sets
# use str_sub and regexpr to paste links at appropriate 
# starting point
</span><span class="n">filenames</span> <span class="o">&lt;-</span> <span class="n">paste0</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">str_sub</span><span class="p">(</span><span class="n">links_data</span><span class="p">,</span> <span class="n">start</span> <span class="o">=</span> <span class="n">regexpr</span><span class="p">(</span><span class="s2">"ap.data"</span><span class="p">,</span> <span class="n">links_data</span><span class="p">)))</span>

<span class="n">filenames</span>
<span class="c1">## [1] "http://download.bls.gov/pub/time.series/ap/ap.data.0.Current"       
## [2] "http://download.bls.gov/pub/time.series/ap/ap.data.1.HouseholdFuels"
## [3] "http://download.bls.gov/pub/time.series/ap/ap.data.2.Gasoline"      
</span><span class="err">##</span> <span class="p">[</span><span class="m">4</span><span class="p">]</span> <span class="s2">"http://download.bls.gov/pub/time.series/ap/ap.data.3.Food"</span></code></pre></figure>

<p>We can now proceed to develop a simple <code class="highlighter-rouge">for</code> loop function to download each data set. We store the results in a list which contains 4 items, one item for each data set.  Each list item contains the url in which the data was extracted from and the dataframe containing the downloaded data.  We’re now ready to analyze these data sets as necessary.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># create empty list to dump data into
</span><span class="n">data_ls</span> <span class="o">&lt;-</span> <span class="n">list</span><span class="p">()</span>

<span class="k">for</span><span class="p">(</span><span class="n">i</span> <span class="k">in</span> <span class="m">1</span><span class="o">:</span><span class="n">length</span><span class="p">(</span><span class="n">filenames</span><span class="p">)){</span>
        <span class="n">url</span> <span class="o">&lt;-</span> <span class="n">filenames</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">data</span> <span class="o">&lt;-</span> <span class="n">read.delim</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="n">data_ls</span><span class="p">[[</span><span class="n">length</span><span class="p">(</span><span class="n">data_ls</span><span class="p">)</span> <span class="o">+</span> <span class="m">1</span><span class="p">]]</span> <span class="o">&lt;-</span> <span class="n">list</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">filenames</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">str</span><span class="p">(</span><span class="n">data_ls</span><span class="p">)</span>
<span class="c1">## List of 4
##  $ :List of 2
##   ..$ url : chr "http://download.bls.gov/pub/time.series/ap/ap.data.0.Current"
##   ..$ data:'data.frame':	144712 obs. of  5 variables:
##   .. ..$ series_id     : Factor w/ 878 levels "APU0000701111    ",..: 1 1 1 1 1 1 1 1 1 1 ...
##   .. ..$ year          : int [1:144712] 1995 1995 1995 1995 1995 1995 1995 1995 1995 1995 ...
##   .. ..$ period        : Factor w/ 12 levels "M01","M02","M03",..: 1 2 3 4 5 6 7 8 9 10 ...
##   .. ..$ value         : num [1:144712] 0.238 0.242 0.242 0.236 0.244 0.244 0.248 0.255 0.256 0.254 ...
##   .. ..$ footnote_codes: logi [1:144712] NA NA NA NA NA NA ...
##  $ :List of 2
##   ..$ url : chr "http://download.bls.gov/pub/time.series/ap/ap.data.1.HouseholdFuels"
##   ..$ data:'data.frame':	90339 obs. of  5 variables:
##   .. ..$ series_id     : Factor w/ 343 levels "APU000072511     ",..: 1 1 1 1 1 1 1 1 1 1 ...
##   .. ..$ year          : int [1:90339] 1978 1978 1979 1979 1979 1979 1979 1979 1979 1979 ...
##   .. ..$ period        : Factor w/ 12 levels "M01","M02","M03",..: 11 12 1 2 3 4 5 6 7 8 ...
##   .. ..$ value         : num [1:90339] 0.533 0.545 0.555 0.577 0.605 0.627 0.656 0.709 0.752 0.8 ...
##   .. ..$ footnote_codes: logi [1:90339] NA NA NA NA NA NA ...
##  $ :List of 2
##   ..$ url : chr "http://download.bls.gov/pub/time.series/ap/ap.data.2.Gasoline"
##   ..$ data:'data.frame':	69357 obs. of  5 variables:
##   .. ..$ series_id     : Factor w/ 341 levels "APU000074712     ",..: 1 1 1 1 1 1 1 1 1 1 ...
##   .. ..$ year          : int [1:69357] 1973 1973 1973 1974 1974 1974 1974 1974 1974 1974 ...
##   .. ..$ period        : Factor w/ 12 levels "M01","M02","M03",..: 10 11 12 1 2 3 4 5 6 7 ...
##   .. ..$ value         : num [1:69357] 0.402 0.418 0.437 0.465 0.491 0.528 0.537 0.55 0.556 0.558 ...
##   .. ..$ footnote_codes: logi [1:69357] NA NA NA NA NA NA ...
##  $ :List of 2
##   ..$ url : chr "http://download.bls.gov/pub/time.series/ap/ap.data.3.Food"
##   ..$ data:'data.frame':	122302 obs. of  5 variables:
##   .. ..$ series_id     : Factor w/ 648 levels "APU0000701111    ",..: 1 1 1 1 1 1 1 1 1 1 ...
##   .. ..$ year          : int [1:122302] 1980 1980 1980 1980 1980 1980 1980 1980 1980 1980 ...
##   .. ..$ period        : Factor w/ 12 levels "M01","M02","M03",..: 1 2 3 4 5 6 7 8 9 10 ...
##   .. ..$ value         : num [1:122302] 0.203 0.205 0.211 0.206 0.207 0.21 0.214 0.215 0.214 0.212 ...
</span><span class="err">##</span>   <span class="err">..</span> <span class="err">..</span><span class="o">$</span> <span class="n">footnote_codes</span><span class="o">:</span> <span class="n">logi</span> <span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">122302</span><span class="p">]</span> <span class="n">NA</span> <span class="n">NA</span> <span class="n">NA</span> <span class="n">NA</span> <span class="n">NA</span> <span class="n">NA</span> <span class="k">...</span></code></pre></figure>

<p><small><a href="#">Go to top</a></small></p>

<p><br /></p>
<p class="footnote" style="line-height:0.75">
<sup id="fn1">1. In <a href="http://www.amazon.com/Automated-Data-Collection-Practical-Scraping/dp/111883481X/ref=pd_sim_14_1?ie=UTF8&amp;dpID=51Tm7FHxWBL&amp;dpSrc=sims&amp;preST=_AC_UL160_SR108%2C160_&amp;refRID=1VJ1GQEY0VCPZW7VKANX">Automated Data Collection with R</a> Munzert et al. state that "[t]he first way to get data from the web is almost too banal to be considered here and actually not a case of web scraping in the narrower sense."<a href="#ref1" title="Jump back to footnote 1 in the text.">"&#8617;"</a><sup>

<p class="footnote" style="line-height:0.75">
<sup id="fn2">2. An example is provided in <a href="http://www.amazon.com/Automated-Data-Collection-Practical-Scraping/dp/111883481X/ref=pd_sim_14_1?ie=UTF8&amp;dpID=51Tm7FHxWBL&amp;dpSrc=sims&amp;preST=_AC_UL160_SR108%2C160_&amp;refRID=1VJ1GQEY0VCPZW7VKANX">Automated Data Collection with R</a> in which they use a similar approach to extract desired CSV files scattered throughout the <a href="http://www.elections.state.md.us/elections/2012/election_data/index.html">Maryland State Board of Elections website</a>.<a href="#ref2" title="Jump back to footnote 2 in the text.">"&#8617;"</a><sup>

</sup></sup></p></sup></sup></p>

  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">

      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
        <center>
          <li>
            <a href="https://github.com/bradleyboehmke">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>
            </a>
            &nbsp;
            <a href="http://www.twitter.com/bradleyboehmke">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>
            </a>
            &nbsp;
            <a href="https://www.linkedin.com/in/brad-boehmke-ph-d-9b0a257">
              <span class="icon  icon--linkedin">
                <svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"  width="25" height="25" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="#828282" d="M13.632 13.635h-2.37V9.922c0-.886-.018-2.025-1.234-2.025-1.235 0-1.424.964-1.424 1.96v3.778h-2.37V6H8.51V7.04h.03c.318-.6 1.092-1.233 2.247-1.233 2.4 0 2.845 1.58 2.845 3.637v4.188zM3.558 4.955c-.762 0-1.376-.617-1.376-1.377 0-.758.614-1.375 1.376-1.375.76 0 1.376.617 1.376 1.375 0 .76-.617 1.377-1.376 1.377zm1.188 8.68H2.37V6h2.376v7.635zM14.816 0H1.18C.528 0 0 .516 0 1.153v13.694C0 15.484.528 16 1.18 16h13.635c.652 0 1.185-.516 1.185-1.153V1.153C16 .516 15.467 0 14.815 0z" fill-rule="nonzero"/>
                </svg>
              </span>
            </a>
          </li>

        </ul>
        </center>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text"></p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
