<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bradley Boehmke</title>
    <description></description>
    <link>http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//</link>
    <atom:link href="http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Fri, 20 May 2016 19:37:08 -0400</pubDate>
    <lastBuildDate>Fri, 20 May 2016 19:37:08 -0400</lastBuildDate>
    <generator>Jekyll v3.0.1</generator>
    
      <item>
        <title>Understanding the Unemployment Rate</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://bradleyboehmke.github.io/2016/05/understanding-the-unemployment-rate.html&quot;&gt;&lt;img src=&quot;http://premiercredco.com/wp-content/uploads/2013/08/UNEMPLOYMENT-500x359.png&quot; alt=&quot;The Rise and Fall of American Growth&quot; style=&quot;float:left; margin: 5px 5px -5px 0px; width: 17%; height: 17%;&quot; /&gt;&lt;/a&gt;
Last week the Bureau of Labor Statistics (BLS) released the most recent &lt;a href=&quot;http://www.bls.gov/news.release/pdf/empsit.pdf&quot;&gt;unemployment statistics for April&lt;/a&gt;. No surprises in the umployment rate were experienced with the rate holding steady at about 5% over the past eight months and down from 5.4% in April of 2015.  Each month the BLS reports these figures and each month the media spends a fair amount of time debating the relevance of the changes experienced and what these changes may indicate about our economy. It’s amazing how such a &lt;em&gt;“simple”&lt;/em&gt; statistic can cause so much national debate and can be a central actor used by decision-makers to guide future policy decisions. However, coming up with this statistic is far from &lt;em&gt;“simple”&lt;/em&gt;.&lt;sup&gt;&lt;a href=&quot;#fn1&quot; id=&quot;ref1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; Moreover, few American’s understand just what makes up the components of this macro-economic indicator. This post, hopefully, will help shed some light on this latter issue.
&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;measuring-the-unemployed&quot;&gt;Measuring the Unemployed&lt;/h2&gt;
&lt;p&gt;How well an economy uses its resources is a major aspect of economic performance; and one of the most important resources is people. Consequently, keeping people employed is a major concern for policymakers and the unemployment rate provides understanding regarding this in addition to providing an indication of labor market conditions. For instance, low unemployment rates reflect job availability and the potential for wage growth whereas high unemployment rates signal economic hardship for individuals who need to earn a living and seek work.  To provide these insights the unemployment rate measures the percentage of people “wanting” to work who do not have jobs. More technically, it is the percentage of the unemployed in the civilian labor force.&lt;/p&gt;

&lt;p&gt;To measure the unemployed, among &lt;a href=&quot;http://www.bls.gov/cps/cpsaz.htm&quot;&gt;other statistics&lt;/a&gt;, the BLS conducts the Current Population Survey (CPS). The CPS surveys 60,000 households across the U.S., translating to approximately 110,000 individuals each month. The sample is selected to best represent the U.S. population by demographics (i.e. age, race, sex, vocation) and geography (i.e. region, state, urban, rural). Households included in the sample are on a 16 month rotation in which they are interviewed for 4 consecutive months, removed from the sample for 8 months, and then re-interviewed for 4 additional months before being removed from the sample permenantly.  The households being surveyed are on a staggered rotation so that every month 25% of the households in the sample are changed; meaning that from month-to-month 75% of the households surveyed remain the same and year-to-year 50% of the households surveyed remain the same. This means the the month-to-month and year-to-year changes can be considered quite reliable.&lt;/p&gt;

&lt;p&gt;The objective of the CPS is to categorize each adult in the household into one of three buckets - employed, unemployed, or not in the labor force. This is done through a series of &lt;a href=&quot;http://www.bls.gov/cps/cps_htgm.htm#unemployed&quot;&gt;questions&lt;/a&gt; asked either in-person or over the phone. These questions cover personal characteristics (i.e. demographics) and then covers a series of questions that will determine the persons’ categorization. So rather than the person stating whether they are employed or not, the answers to the questions will determine which category they fall into.  And it are these categories that I want to clarify but to do so, I want to start by outlining the big picture - what constitutes the “adult” population and the civilian labor force - and then I’ll discuss what determines the three categories.&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;http://bradleyboehmke.github.io/figure/source/understanding-the-unemployment-rate/2016-05-08-understanding-the-unemployment-rate/unemployment1.png&quot; /&gt;
&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;adult-population&quot;&gt;Adult Population&lt;/h2&gt;
&lt;p&gt;The CPS is targeted towards adults but exactly who does this cover? Well, it targets individuals age 16 and over with no upper age limit. As a general rule, the FLSA sets 14 years of age as the minimum age for employment but limits the number of hours worked by minors under the age of 16. So the CPS and unemployment rate are meant to measure those individuals who are not restricted to only a limited amount of work due to age. However, the CPS also excludes a group referred to as “institutional”” - those living in mental and health institutions (approximately 500,000&lt;sup&gt;&lt;a href=&quot;#fn2&quot; id=&quot;ref2&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;), active-duty armed forces (approximately 1.3 million&lt;sup&gt;&lt;a href=&quot;#fn3&quot; id=&quot;ref3&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;), and those incarcerated (approximately 2.2 million&lt;sup&gt;&lt;a href=&quot;#fn4&quot; id=&quot;ref4&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;).&lt;/p&gt;

&lt;p&gt;So, of the 323.5 million people in the U.S., we take the 257 million individuals that are age 16+,  exclude the 4 million individuals classified as “institutional” and this makes up the adult population of concern - also called the civilian noninstitutional population.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;not-in-labor-force&quot;&gt;Not in Labor Force&lt;/h2&gt;
&lt;p&gt;From the civilian noninstitutional population, the next objective is to identify the number of people actively engaged in the labor force. The reason for this is we want to identify those people that are employed or unemployed who are actively “wanting” to work. Therefore, we need to &lt;em&gt;exclude&lt;/em&gt; persons who are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;retired&lt;/li&gt;
  &lt;li&gt;students&lt;/li&gt;
  &lt;li&gt;those taking care of children or other family members&lt;/li&gt;
  &lt;li&gt;others who are neither working nor seeking work&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In April, we had about 37% of the civilian noninstitutional population not actively engaged in the labor force, taking us back to 1978 levels.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://bradleyboehmke.github.io/figure/source/understanding-the-unemployment-rate/2016-05-08-understanding-the-unemployment-rate/participation.png&quot; title=&quot;Labor Participation Rate&quot; alt=&quot;Labor Participation Rate&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;However, its important to keep in mind that individuals in this category are not the same.  On one hand you have individuals that are retired, full-time students, or stay at home mom’s that have no desire to currently be engaged in the labor force.  However, there are individuals who desire to work but do not meet the technical definition of being actively engaged in the labor force. This includes:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Marginally attached workers:&lt;/strong&gt; these individuals want and are available for work and have looked for a job sometime in the prior 12 months. However, they are not counted as unemployed because they have not &lt;em&gt;actively&lt;/em&gt; searched for work in the past 4 weeks. This may be due to family complications, limited transportation, lack of identified jobs of interest, etc.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Discouraged workers:&lt;/strong&gt; these individuals are a subset of marginally attached workers who are not currently looking for work because they believe no job is available in their specialty area, face some type of discrimmination, or lack necessary education or experiences. Consequently, these folks want to work but have given up looking for employment.&lt;/p&gt;

&lt;p&gt;The number of persons who were &lt;em&gt;marginally attached to the labor force&lt;/em&gt; or &lt;em&gt;discouraged&lt;/em&gt; increased sharply during the recent recession, rising to 2.1 million in the first quarter of 2009. Its important to understand when individuals move from the labor force category into one of these categories it impacts the unemployment rate because they are being reclassified as &lt;em&gt;not in the labor force&lt;/em&gt; and, therefore, not included in the unemployment rate calculation. However, despite some people arguing that the unemployment rate is much &lt;a href=&quot;http://www.factcheck.org/2016/02/trump-wildly-inflates-unemployment/&quot;&gt;higher&lt;/a&gt; because these individuals are excluded, and despite the fact that this category does increase sizably during recessions, “typically fewer than 1 in 10 people not in the labor force reported that they want a job.”&lt;sup&gt;&lt;a href=&quot;#fn5&quot; id=&quot;ref5&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;So now that we’ve identified the individuals excluded from the labor force, we now have the remaining civilian labor force population identified from which we want to determine persons as employed or unemployed.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;employed&quot;&gt;Employed&lt;/h2&gt;
&lt;p&gt;Individuals in the civilian labor force are considered employed if they did any work at all for pay or profit during the survey reference week.&lt;sup&gt;&lt;a href=&quot;#fn6&quot; id=&quot;ref6&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; This includes all part-time and temporary work, as well as regular full-time, year-round employment; an individual could do as little as 1 hour of paid work and they will be categorized as employed. Also, individuals who perform 15+ hours of unpaid work for a family business or farm are also categorized as employed. Lastly, Individuals are counted as employed if they have a job at which they did not work during the survey week, whether they were paid or not, but have a specific job to which they will return. This includes individuals that are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On vacation&lt;/li&gt;
  &lt;li&gt;Ill&lt;/li&gt;
  &lt;li&gt;Experiencing child care problems&lt;/li&gt;
  &lt;li&gt;On maternity or paternity leave&lt;/li&gt;
  &lt;li&gt;Taking care of some other family or personal obligation&lt;/li&gt;
  &lt;li&gt;Involved in a labor dispute&lt;/li&gt;
  &lt;li&gt;Prevented from working by bad weather&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;unemployed&quot;&gt;Unemployed&lt;/h2&gt;
&lt;p&gt;And finally, the individuals that remain can be classified as unemployed. These are the individuals that do not have a job but have actively looked for work in the prior 4 weeks and are currently available for work. To be considered as &lt;em&gt;actively&lt;/em&gt; looking for work, individuals must perform one of the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reaching out to individuals or organizations for work:
    &lt;ul&gt;
      &lt;li&gt;An employer directly or having a job interview&lt;/li&gt;
      &lt;li&gt;A public or private employment agency&lt;/li&gt;
      &lt;li&gt;Friends or relatives&lt;/li&gt;
      &lt;li&gt;A school or university employment center&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Submitting resumes or filling out applications&lt;/li&gt;
  &lt;li&gt;Placing or answering job advertisements&lt;/li&gt;
  &lt;li&gt;Checking union or professional registers&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This obviously excludes individuals who are only passively looking for work by merely reading job advertisements or attending job training programs. To be considered as &lt;em&gt;available&lt;/em&gt; for work, individuals be able to go to work during the survey reference week given a job was offered barring only temporary illness (i.e. an individual is offered a job but can’t start until next week because of they have the flu).&lt;/p&gt;

&lt;p&gt;Therefore, the unemployment rate includes people who have quit their jobs to look for other employment, workers whose temporary jobs have ended, individuals looking for their first job, and experienced workers looking for jobs after an absence from the labor force (i.e. stay-at-home parents who return to the labor force after their children have entered school).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://bradleyboehmke.github.io/figure/source/understanding-the-unemployment-rate/2016-05-08-understanding-the-unemployment-rate/unemployment.png&quot; title=&quot;Unemployment Rate&quot; alt=&quot;Unemployment Rate&quot; style=&quot;display: block; margin: auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;wrap-up&quot;&gt;Wrap-up&lt;/h2&gt;
&lt;p&gt;Hopefully this clarifies (for some at least) just what makes up the components of the unemployment rate so that in the future, when the monthly unemployment rates are released and the media discussions ensue, you can have a more thorough understanding regarding the information hidden in the statistic.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#top&quot;&gt;Go to top&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn1&quot;&gt;1. You can find the comprehensive documentation on the technical methodologies employed to collect data and compute the unemployment rate &lt;a href=&quot;http://www.bls.gov/cps/documentation.htm#concepts&quot;&gt;here&lt;/a&gt;. &lt;a href=&quot;#ref1&quot; title=&quot;Jump back to footnote 1 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;


&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn2&quot;&gt;2. In 2009 the National Council on Disability identified &lt;a href=&quot;https://www.ncd.gov/publications/2012/Sept192012/Institutions&quot;&gt;469,123 people receiving services while living in institutions&lt;/a&gt;. &lt;a href=&quot;#ref2&quot; title=&quot;Jump back to footnote 2 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;


&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn3&quot;&gt;3. Even some of the 811,000 reserve personnel would be excluded as the CPS excludes all full-time armed forces personnel and some of the reserve personnel are full-time. &lt;a href=&quot;#ref3&quot; title=&quot;Jump back to footnote 3 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;


&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn4&quot;&gt;4. &lt;a href=&quot;http://www.prisonpolicy.org/reports/pie2016.html&quot;&gt;Prison Policy Initiative&lt;/a&gt; identified 0.2 million in federal prisons, 1.4 million in state prisons, and 0.6 million in local jails. This excludes the 34,000 youth that are locked up. &lt;a href=&quot;#ref4&quot; title=&quot;Jump back to footnote 4 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;


&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn5&quot;&gt;5. In April only 5% of the non-labor force reported they want a job and the &lt;a href=&quot;http://www.bls.gov/cps/cps_htgm.htm#nilf&quot;&gt;BLS reported&lt;/a&gt; that since 1990, the average has been less than 10%.&lt;a href=&quot;#ref5&quot; title=&quot;Jump back to footnote 5 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;


&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn6&quot;&gt;6. The survey reference week is usually the week that includes the 12th of the month. &lt;a href=&quot;#ref6&quot; title=&quot;Jump back to footnote 6 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;


&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 09 May 2016 00:00:00 -0400</pubDate>
        <link>http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2016/05/understanding-the-unemployment-rate.html</link>
        <guid isPermaLink="true">http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2016/05/understanding-the-unemployment-rate.html</guid>
        
        <category>unemployment</category>
        
        
        <category>economics</category>
        
      </item>
    
      <item>
        <title>The Rise and Fall of American Growth</title>
        <description>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css&quot; /&gt;

&lt;style type=&quot;text/css&quot;&gt; 
&lt;!-- 
.hangingindent {
  padding-left: 60px ;
  padding-right: 20px ;
  text-indent: -32px ;
}
--&gt; 
&lt;/style&gt;

&lt;p&gt;&lt;a href=&quot;http://bradleyboehmke.github.io/2016/04/the-rise-and-fall-of-american-growth.html&quot;&gt;&lt;img src=&quot;http://t2.gstatic.com/images?q=tbn:ANd9GcR-hfDlu6WgA7G-gs4eBiqU-XYBpr6RIt8mud9_OwjE_GnTmAQk&quot; alt=&quot;The Rise and Fall of American Growth&quot; style=&quot;float:left; margin: 0px 5px -5px 0px; width: 17%; height: 17%;&quot; /&gt;&lt;/a&gt;
Americans believe “in the green light, the orgastic future that year by year recedes before us. It eludes us then, but that’s no matter — tomorrow we will run faster, stretch out our arms farther…So we beat on, boats against the current, borne back ceaselessly into the past.”&lt;sup&gt;&lt;a href=&quot;#fn1&quot; id=&quot;ref1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; Like Gatsby, American’s never lose their optimism for an ever-brighter future; and our vehicle of choice to get to this destination is technology. But should we expect technology to move us to a future that transcends our past?&lt;/p&gt;

&lt;blockquote style=&quot;text-align:right;&quot;&gt; 
&lt;p&gt;&lt;em&gt;&quot;We wanted flying cars, instead we got 140 characters.&quot;&lt;/em&gt;&lt;/p&gt; ― Peter Thiel 
&lt;/blockquote&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Most recently techno-optimists are embracing big data, artificial intelligence (AI), and the internet of things (IoT) to fundamentally change our way of life and take economic productivity to heights never before reached. One of the &lt;a href=&quot;http://www.ft.com/intl/cms/s/2/ef24be04-be8d-11e5-9fdb-87b8d15baec2.html#axzz46g12XSLM&quot;&gt;four key issues&lt;/a&gt; discussed at this year’s &lt;a href=&quot;https://www.weforum.org/events/world-economic-forum-annual-meeting-2016/&quot;&gt;World Economic Forum&lt;/a&gt; was “economy-changing technologies”.  These “economy-changing technologies” will bring us &lt;a href=&quot;http://www.rand.org/news/press/2014/01/06.html&quot;&gt;reduced crashes, energy consumption and pollution via autonomous vehicles&lt;/a&gt;; &lt;a href=&quot;http://www.brookings.edu/~/media/Research/Files/Papers/2012/9/04%20education%20technology%20west/04%20education%20technology%20west.pdf&quot;&gt;real-time evaluations and feedback for more targeted education&lt;/a&gt;; &lt;a href=&quot;http://www.pharmatalents.es/assets/files/Big_Data_Revolution.pdf&quot;&gt;greater information sharing and more accurate diagnosis capability for improved healthcare&lt;/a&gt;; &lt;a href=&quot;http://www.forbes.com/sites/louiscolumbus/2015/07/13/ten-ways-big-data-is-revolutionizing-supply-chain-management/#56f8b8ff3d38&quot;&gt;optimized supply chains for improved service and corporate bottom-lines&lt;/a&gt;…  In fact, the perceived opportunities for technology to change current processes is endless; the bigger question is just how big of an &lt;strong&gt;impact&lt;/strong&gt; will these changes have on our economy?  According to &lt;a href=&quot;http://www.economics.northwestern.edu/people/directory/robert-gordon.html&quot;&gt;Robert Gordon&lt;/a&gt; in his recent book &lt;a href=&quot;http://www.amazon.com/The-Rise-Fall-American-Growth/dp/0691147728&quot;&gt;The Rise and Fall of American Growth&lt;/a&gt;, the information and communications technology (ICT) revolution is a “green light” that, like Gatsby, “presents itself as an orgastic future that year by year recedes before us.” Moreover, his forecast for the ICT revolution’s impact on our economy is even more somber.  What follows is a synopsis of Gordon’s main points.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tldr&quot;&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;If you’re short on time here are the big take-aways:&lt;/p&gt;

&lt;p class=&quot;hangingindent&quot;&gt;&lt;a href=&quot;#special&quot; style=&quot;color:black&quot;&gt;&amp;#9312;&lt;/a&gt;  
The special century of 1870-1970 experienced the most remarkable economic growth. No other 100-year period in world history has brought comparable progress and Gordon suggests that this special century should be our baseline for what real transformation looks like.
&lt;/p&gt;

&lt;p class=&quot;hangingindent&quot;&gt;&lt;a href=&quot;#industrial&quot; style=&quot;color:black&quot;&gt;&amp;#9313;&lt;/a&gt; 
Gordon argues that although the ICT revolution has given us pretty cool stuff, this stuff is creating only marginal rather than fundamental improvements in our lives and businesses&#39; productivity.
&lt;/p&gt;

&lt;p class=&quot;hangingindent&quot;&gt;&lt;a href=&quot;#forecast&quot; style=&quot;color:black&quot;&gt;&amp;#9314;&lt;/a&gt; 
Gordon argues that four headwinds (income inequality, education, demography, and government debt) will cause near-term growth in business productivity and personal living standards to be in line with the abysmal rates we&#39;ve experienced during the past decade rather than the fundamental forward leaps that techno-optimists predict and America experienced during the special century.
&lt;/p&gt;

&lt;p class=&quot;hangingindent&quot;&gt;&lt;a href=&quot;#final&quot; style=&quot;color:black&quot;&gt;&amp;#9315;&lt;/a&gt; 
Although I&#39;m hesitant of long-term macro predictions, and the policy recommendations would&#39;ve been better excluded, the book provides a fantastically detailed account of the history and economics of American life from 1870-present.  Definitely worth reading.
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;special&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-special-century&quot;&gt;① The Special Century&lt;/h2&gt;
&lt;p&gt;Throughout the first half of his 700 page book, Gordon argues that the period from 1870 to 1970 was a “special century,” when America was fundamentally changed and the foundations of modern American life were laid.  A central theme of Gordon’s book is that many inventions are one-time-only events subject to a long succession of subsequent incremental improvements.  Truly transformative inventions are ones that impact nearly all individuals and the time period between 1870 and 1920 witnessed the momentum of a unique clustering of “Great Inventions”.  This included electricity, flushing toilets, internal combustion engines, central heating, refrigeration, radio, telephony, clean water, vaccines, antibiotics, etc. These were inventions that offered the opportunity to impact every American in almost every aspect of daily life.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.archives.gov/historical-docs/doc-content/images/edison-patent-light-bulb-m.jpg&quot; alt=&quot;Edison&quot; style=&quot;float:right;&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The integration of these inventions in the early 20&lt;sup&gt;th&lt;/sup&gt; century initiated many of the truly transformative advancements.  Electricity illuminated households and changed the workplace.  Plumbing and running water changed the most basic daily tasks of bathing and washing clothes. The internal combustion engine and automobile created a networked America connected by roads, allowed for mail-order and delivery of consumable goods, rapidly changed farming, and created suburbia as we know it.&lt;/p&gt;

&lt;p&gt;However, during this time more than half of family budgets were devoted to food and clothing and most of the rest to rent or the mortgage, not allowing for the adoption of many inventions that offered new conveniences. Through a combination of improved consumer credit options, increased wages&lt;sup&gt;&lt;a href=&quot;#fn2&quot; id=&quot;ref2&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, accumulated savings due to WWII rationing, and two-income families with women entering the workforce unleashed a fury of consumer consumption, adoption, and improvements of these inventions. This led to a significant growth rate in the standard of living, labor productivity, and total factor productivity (TFP)&lt;sup&gt;&lt;a href=&quot;#fn3&quot; id=&quot;ref3&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Gordon’s historical recount also illustrates the important fact that GDP does not always capture the true extent of improvements. Many of the most important gains in the standard of living during this time period, primarily from 1870-1940, are not captured by GDP suggesting that the growth rate of real GDP during this time is substantially understated.&lt;sup&gt;&lt;a href=&quot;#fn4&quot; id=&quot;ref4&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Regardless, Gordon argues no other 100-year period in world history has brought comparable progress and Gordon suggests that this special century should be our baseline for what real transformation looks like.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;industrial&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-information-and-communications-technology-revolution&quot;&gt;The Information and Communications Technology Revolution&lt;/h2&gt;
&lt;p&gt;So how does the ICT revolution compare? Gordon argues that although ICT has been revolutionary, it has been somewhat isolated and marginal in its influence. Genuinely major innovations normally bring about fundamental changes in personal lives and business practices. Gordon argues that although ICT caused big changes to business practices in the mid-1990s to the early 2000s, not much has happened since. In essence, what wide-sweeping productivity improvements could be gained by digitizing business processes was captured in the late 1990s when most businesses fully adopted the use of computers, an internet presence, and digitally networked components.  Since then, what improvements have been made to ICT technology has only had marginal, if any, improvements to business productivity.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;http://bradleyboehmke.github.io/figure/source/the-rise-and-fall-of-american-growth/2016-04-22-the-rise-and-fall-of-american-growth/TFP.png&quot; alt=&quot;Total Factor Productivity&quot; width=&quot;90%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Some are quick to mention the likes of Google, Netflix, Apple, Facebook and other major tech companies.  Granted, a whole new ICT industry has taken root in our economy but Gordon reminds us that the tech sector is only but a fraction of the total economy. In fact, total spending on all electronic communications, computer devices, internet and telephone services, and entertainment (which has been heavily influenced by ICT) only accounts for about 7% of the economy.&lt;sup&gt;&lt;a href=&quot;#fn5&quot; id=&quot;ref5&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; That leaves the other 93% of the economy that has not been nearly as affected by the ICT Revolution.&lt;/p&gt;

&lt;p&gt;As for the impact of ICT on personal lives, Gordon argues these have been, primarily, all marginal improvements to our daily activities.  Cars are becoming safer and more digitized but these are only marginal improvements whereas the invention of the car was a one time, fundamental change to how we commuted.  Even the idea of driverless cars, although would allow the driver more freedom in what they do as they commute, this would only be a marginal change in our lives. It may eliminate taxi cab drivers but does this create a fundamental change in American lives, Gordon argues it would not.  Computers, TVs, radios (i.e. podcasts &amp;amp; Sirius) are all examples of where the ICT revolution continues to advance capabilities (i.e. faster bandwidth, greater computing power, better image quality) but all these advancements provide only marginal rather than fundamental changes in our lives.&lt;/p&gt;

&lt;p&gt;In addition, Gordon argues that additional constraints have become present during the ICT revolution that are influencing America’s growth.  This includes a reduction in total labor force participation among the “prime-age”, increasing college costs and debt, declining business dynamism which reduces new startups and job mobility, and the decay of the middle class.&lt;/p&gt;

&lt;p&gt;The net result Gordon argues, is that the ICT revolution has given us pretty cool stuff but this stuff is creating only marginal rather than fundamental improvements in our lives and businesses’ productivity.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;forecast&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;gordons-forecast-of-americas-growth&quot;&gt;Gordon’s Forecast of America’s Growth&lt;/h2&gt;
&lt;p&gt;So what should we expect over the next 25 years? Gordon provides his predictions for the primary indicators of productivity and standards of living.  In a nutshell they are grim with the expectation that our growth rates will be more in line with the past 10 years, which has experienced some of the worst growth rates in the 20&lt;sup&gt;th&lt;/sup&gt; and 21&lt;sup&gt;st&lt;/sup&gt; centuries.&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;http://bradleyboehmke.github.io/figure/source/the-rise-and-fall-of-american-growth/2016-04-22-the-rise-and-fall-of-american-growth/gordon_forcast.png&quot; alt=&quot;Gordon Forecast&quot; width=&quot;90%&quot; /&gt;
&lt;/center&gt;

&lt;p&gt;Although, Gordon predicts productivity growth rates to be positive, his argument focuses on four “headwinds” that he believes will make standard of living for the majority of American’s to be stagnant.&lt;/p&gt;

&lt;p&gt;First among the headwinds is income inequality.  Since 1970 fundamental changes in share of income has resulted with the top 1% experiencing a substantially higher growth while the growth for the remaining 99% has plateaued. If this trend continues then what growth in corporate profits due to the mild productivity increases that may come will go disproportionately to the select few versus the majority of Americans.&lt;/p&gt;

&lt;p&gt;The second headwind discussed is education. America’s decreasing performance in educational rankings and graduation rates will likely have a negative impact on business productivity growth rates compared to the special century, as education attainment has been &lt;a href=&quot;http://www.amazon.com/The-Race-between-Education-Technology/dp/0674035305&quot;&gt;positively linked to productivity&lt;/a&gt;. Moreover, the decreasing affordability of college and increasing student debt will continue to hinder growth in the standard of living as smaller percentages of future income will be disposable.&lt;/p&gt;

&lt;p&gt;The third headwind presented is demography. With the labor participation rate decreasing, primarily from baby boomer retirees but also from a decrease in men and women in the 25-55 age group, which will result in a reduction in hours per person and therefore a result in the average output per person.&lt;/p&gt;

&lt;p&gt;The final headwind posited by Gordon is the ratio of government debt to GDP. In 2015 the debt-to-GDP ratio was 74% according to the &lt;a href=&quot;https://www.cbo.gov/publication/51129&quot;&gt;CBO&lt;/a&gt; and Gordon predicts this to increase to 125% by 2038. In addition, he cites the dwindling resources for Medicare and Social Security and the increasing aging of the baby boomer generation.  Together these are certain to increase tax rates for all Americans and/or reduce future transfer payments which will also reduce the standard of living growth rates.&lt;/p&gt;

&lt;p&gt;Various other factors are presented, all of which help to support his claim that in the near future we should expect the growth of business productivity and personal living standards to be in line with the abysmal rates we’ve experienced during the past decade rather than the fundamental forward leaps that techno-optimists predict and America experienced during the special century. So although we may continue to try run faster and stretch out our arms further, we will likely continue to “beat against the current, borne back ceaselessly into the past.”&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;final&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;my-final-take&quot;&gt;My Final Take&lt;/h2&gt;
&lt;p&gt;If for no other reason, this book is worth purchasing for the detailed economic and historical assessment and portrayal of American life from 1870-present. Specifically, the vivid details provided of orginary life in America during 1870-1940 was fantastic. The economic details are also overwhelmingly detailed.  At the least, this is a great historic account of post-civil war America - both from a macro and micro perspective.&lt;/p&gt;

&lt;p&gt;Although I think Gordon provided a fairly good argument for his predictions, I am typically hesitant in such large scale forecasts. Moreover, his policy recommendations in his postscript were lacking of details and analysis and would’ve been just as well omitted.&lt;/p&gt;

&lt;p&gt;Although I’ve become a little skeptical of the big data and AI hype, I’m not as quick to say that it may not eventually create fundamental changes. Early in the book Gordon discussed how certain technologies were developed in the late 1800s (electricity, telephony, internal combustion engine) but it took time to understand and implement the vehicle to diffuse this technology throughout America.  Personnally, I think we are early on in the invention period of many computer technologies and, who knows, maybe in a decade we’ll finally find a revolutionary vehicle to diffuse the technology to create fundamental changes in our economy.&lt;/p&gt;

&lt;p&gt;But I think Gordon provides important insights and at least directs us to first look and understand the history of America’s economy, and to treat this as a baseline to measure future growth against. At the end of the day this book is definitely worth reading.&lt;sup&gt;&lt;a href=&quot;#fn6&quot; id=&quot;ref6&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn1&quot;&gt;1. F. Scott Fitzgerald&#39;s actual quote from the concluding chapter of The Great Gatsby reads &lt;em&gt;&quot;Gatsby believed in the green light, the orgastic future that year by year recedes before us. It eluded us then, but that’s no matter — tomorrow we will run faster, stretch out our arms farther... And then one fine morning- So we beat on, boats against the current, borne back ceaselessly into the past.&quot;&lt;/em&gt; &lt;a href=&quot;#ref1&quot; title=&quot;Jump back to footnote 1 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;


&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn2&quot;&gt;2. Increased wages came from 4 factors: 1) employers such as Henry Ford realizing that increased wages reduced employment turnover and increased morale which lead to greater productivity, 2) Fair Labor Standards Act of 1938, 3) labor unions, and 4) high levels of government employment during WWII offered premium wages. &lt;a href=&quot;#ref2&quot; title=&quot;Jump back to footnote 2 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;


&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn3&quot;&gt;3. In economics, total-factor productivity (TFP), also called multi-factor productivity, is a variable which accounts for effects in total output growth relative to the growth in traditionally measured inputs of labor and capital. It is widely considered the best measure of innovation and technological change. &lt;a href=&quot;#ref3&quot; title=&quot;Jump back to footnote 3 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;


&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn4&quot;&gt;4. Examples include the brightness and safety of electric light compared to the inconvenience, danger, and dimness of karosene and whale oil lamps, the variety of food available due to the invention of processed food, the removal of horse manure and uring from city streets, the increased flexibility brought by personal automobiles, etc. &lt;a href=&quot;#ref4&quot; title=&quot;Jump back to footnote 4 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;


&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn5&quot;&gt;5. Freakonomics &lt;a href=&quot;http://freakonomics.com/podcast/american-growth/&quot;&gt;podcast interview&lt;/a&gt; between Gordon and Steven Dubner. &lt;a href=&quot;#ref5&quot; title=&quot;Jump back to footnote 5 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;


&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn6&quot;&gt;6. If you&#39;d like to read more reviews regarding Gordon&#39;s book you can find reviews written by &lt;a href=&quot;https://www.foreignaffairs.com/reviews/review-essay/2016-02-15/innovation-over&quot;&gt;Tyler Cowen&lt;/a&gt;, &lt;a href=&quot;http://www.nytimes.com/2016/01/31/books/review/the-powers-that-were.html?_r=0&quot;&gt;Paul Krugman&lt;/a&gt;, &lt;a href=&quot;http://www.economist.com/news/books-and-arts/21685437-why-economic-growth-soared-america-early-20th-century-and-why-it-wont-be&quot;&gt;The Economist&lt;/a&gt;, &lt;a href=&quot;http://www.huffingtonpost.com/martin-ford/is-american-economic-grow_b_9096698.html&quot;&gt;The Huffington Post&lt;/a&gt;, and &lt;a href=&quot;http://freakonomics.com/podcast/american-growth/&quot;&gt;Freakonomics&lt;/a&gt;. &lt;a href=&quot;#ref6&quot; title=&quot;Jump back to footnote 6 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;

&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 25 Apr 2016 08:25:45 -0400</pubDate>
        <link>http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2016/04/the-rise-and-fall-of-american-growth.html</link>
        <guid isPermaLink="true">http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2016/04/the-rise-and-fall-of-american-growth.html</guid>
        
        <category>book-review</category>
        
        
        <category>literature</category>
        
        <category>economics</category>
        
      </item>
    
      <item>
        <title>Bayesian networks for modeling policy impacts to support costs</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://bradleyboehmke.github.io//2016/04/bayesian-networks-for-modeling-policy-impacts-to-support-costs.html&quot;&gt;&lt;img src=&quot;http://bradleyboehmke.github.io/figure/source/bayesian-networks-for-modeling-policy-impacts-to-support-costs/2016-04-13-bayesian-networks-for-modeling-policy-impacts-to-support-costs/screen_shot.png&quot; alt=&quot;JCAP article&quot; style=&quot;float:left; margin: 0px 5px -5px 0px; width: 19%; height: 19%;&quot; /&gt;&lt;/a&gt;
Whether its industry or government agencies indirect/support activities tend to get the short end of the stick with regards to analytic rigor.  Much of my &lt;a href=&quot;https://www.researchgate.net/publication/284179123_Grabbing_the_Air_Force_by_the_Tail_Applying_Strategic_Cost_Analytics_to_Understand_and_Manage_Indirect_Cost_Behavior&quot;&gt;dissertation&lt;/a&gt; research focused on injecting more analytic rigor to better understand the economics of, and policy impacts, to these activities.  This was one of my papers that assessed the potential application of bayesian networks to provide decision support.
&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Current constraints in the fiscal environment are forcing the Air Force, and its sister services, to assess force reduction considerations. With significant force reduction comes the need to model and assess the potential impact that these changes may have on support resources. Previous research has remained heavily focused on a ratio approach for linking the tooth and tail ends of the Air Force cost spectrum and, although recent research has augmented this literature stream by providing more statistical rigor behind tooth-to-tail relationships, an adequate decision support tool has yet to be explored to aid decision-makers. The authors of this research directly address this concern by introducing a systematic approach to perform tooth-to-tail policy impact analysis. First, multivariate linear regression is applied to identify relationships between the tooth and tail. Then, a novel decision support system with Bayesian networks is introduced to model the tooth-to-tail cost consequences while capturing the uncertainty that often comes with such policy considerations. Through scenario analysis, the authors illustrate how a Bayesian network can provide decision-makers with (i) the ability to model uncertainty in the decision environment, (ii) a visual illustration of cause-and-effect impacts, and (iii) the ability to perform multi-directional reasoning in light of new information available to decision-makers.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.tandfonline.com/eprint/qRxnNT6Mc5ufiV6AaDq6/full&quot;&gt;&lt;img src=&quot;http://bradleyboehmke.github.io/figure/source/bayesian-networks-for-modeling-policy-impacts-to-support-costs/2016-04-13-bayesian-networks-for-modeling-policy-impacts-to-support-costs/screen_shot.png&quot; alt=&quot;Final Graphic&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Wed, 13 Apr 2016 08:25:45 -0400</pubDate>
        <link>http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2016/04/bayesian-networks-for-modeling-policy-impacts-to-support-costs.html</link>
        <guid isPermaLink="true">http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2016/04/bayesian-networks-for-modeling-policy-impacts-to-support-costs.html</guid>
        
        <category>bayesian-networks</category>
        
        <category>econometrics</category>
        
        <category>business-analytics</category>
        
        
        <category>business</category>
        
        <category>economics</category>
        
      </item>
    
      <item>
        <title>Data Wrangling with R!</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://bradleyboehmke.github.io/2016/03/data-wrangling-with-r.html&quot;&gt;&lt;img src=&quot;/public/images/DataWranglingCover.jpg&quot; alt=&quot;Data Wrangling with R&quot; style=&quot;float:left; margin: 5px 10px 5px 5px; width: 19%; height: 19%;&quot; /&gt;&lt;/a&gt;
So I decided to write a book. &lt;em&gt;&lt;a href=&quot;https://leanpub.com/datawranglingwithr&quot;&gt;Data Wrangling with R!&lt;/a&gt;&lt;/em&gt; will help you learn the essentials of preprocessing data leveraging the R programming language to easily and quickly turn noisy data into usable pieces of information. Data wrangling, which is also commonly referred to as data munging, transformation, manipulation, janitor work, etc. can be a painstakenly laborious process. In fact, its been stated that up to 80% of data analysis is spent on the process of cleaning and preparing data. However, being a prerequisite to the rest of the data analysis workflow (visualization, analysis, reporting), it’s essential that you become fluent &lt;em&gt;and&lt;/em&gt; efficient in data wrangling techniques.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;This book will guide you through the data wrangling process along with give you a solid foundation of working with data in R. I teach you how to easily wrangle your data, so you can spend more time focused on understanding the content of your data via visualization, analysis, and reporting. By the time you finish reading this book, you will have learned:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How to work with the different types of data such as numerics, characters, regular expressions, factors, and dates&lt;/li&gt;
  &lt;li&gt;The difference between the different data structures and how to create, add additional components to, and how to subset each data structure&lt;/li&gt;
  &lt;li&gt;How to acquire and parse data from locations you may not have been able to access before such as web scraping&lt;/li&gt;
  &lt;li&gt;How to develop your own functions and use loop control structures to reduce code redundancy&lt;/li&gt;
  &lt;li&gt;How to use pipe operators to simplify your code and make it more readable&lt;/li&gt;
  &lt;li&gt;How to reshape the layout of your data, and manipulate, summarize, and join data sets&lt;/li&gt;
  &lt;li&gt;Not only will you learn many base R functions, you’ll also learn how to use some of the latest data wrangling packages such as &lt;code class=&quot;highlighter-rouge&quot;&gt;tidyr&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;dplyr&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;stringr&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;lubridate&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;readr&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;rvest&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;magrittr&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;xlsx&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;readxl&lt;/code&gt; and others.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In essence, you will have the data wrangling toolbox required for modern day data analysis.  I hope you enjoy and please provide any feedback so I can continue modifying and improving future versions.&lt;/p&gt;

&lt;center&gt;
&lt;a href=&quot;https://leanpub.com/datawranglingwithr&quot;&gt;&lt;img src=&quot;/public/images/DataWranglingCover.jpg&quot; alt=&quot;Data Wrangling with R&quot; align=&quot;center&quot; vspace=&quot;5&quot; hspace=&quot;20&quot; height=&quot;35%&quot; width=&quot;35%&quot; /&gt;&lt;/a&gt;
&lt;/center&gt;

</description>
        <pubDate>Sun, 13 Mar 2016 10:34:23 -0400</pubDate>
        <link>http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2016/03/data-wrangling-with-r.html</link>
        <guid isPermaLink="true">http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2016/03/data-wrangling-with-r.html</guid>
        
        <category>r</category>
        
        <category>data-wrangling</category>
        
        
        <category>programming</category>
        
      </item>
    
      <item>
        <title>Just Another Open-Source Software Debate</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://bradleyboehmke.github.io/2016/02/just-another-open-source-software-debate.html&quot;&gt;&lt;img src=&quot;http://bradleyboehmke.github.io/figure/source/just-another-open-source-software-debate/2016-02-17-just-another-open-source-software-debate/ORMSToday_article.png&quot; alt=&quot;ORMS Today article&quot; style=&quot;float:left; margin: 0px 5px -5px 0px; width: 19%; height: 19%;&quot; /&gt;&lt;/a&gt;
A recent opinion &lt;a href=&quot;https://www.dropbox.com/s/ej229r8oypj46le/Original%20Article%20by%20PKB.pdf?dl=0&quot;&gt;article&lt;/a&gt; in &lt;a href=&quot;https://www.informs.org/ORMS-Today&quot;&gt;ORMS Today&lt;/a&gt; asked if open-source statistical software is really free. The authors’ employment of &lt;em&gt;truth&lt;/em&gt; and sketch of &lt;em&gt;hidden costs&lt;/em&gt; suggest their answer is no. In a sense, I agree. Economic thinking acknowledges there is no free lunch. However, when it comes to the relative risks and merits of software, much remains to be discussed. Despite their titular assertion, the authors did not present “the true cost of ‘free’ statistical software.” Rather, they provided an alternative conceptualization of costs, particularly those of the R programming software. In response, a co-author and I presented a critique of that conceptualization and rebut their seven main claims. Taking a post-modern turn, we leave any notions of truth to the consumer.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;I recommend that you read the &lt;a href=&quot;https://www.dropbox.com/s/ej229r8oypj46le/Original%20Article%20by%20PKB.pdf?dl=0&quot;&gt;original article&lt;/a&gt; first prior to our &lt;a href=&quot;https://www.dropbox.com/s/xgy0uwyh67zovhb/Published%20Version.pdf?dl=0&quot;&gt;rebuttal article&lt;/a&gt;. Enjoy!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.dropbox.com/s/xgy0uwyh67zovhb/Published%20Version.pdf?dl=0&quot;&gt;&lt;img src=&quot;http://bradleyboehmke.github.io/figure/source/just-another-open-source-software-debate/2016-02-17-just-another-open-source-software-debate/ORMSToday_article.png&quot; alt=&quot;Final Graphic&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 17 Feb 2016 17:31:04 -0500</pubDate>
        <link>http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2016/02/just-another-open-source-software-debate.html</link>
        <guid isPermaLink="true">http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2016/02/just-another-open-source-software-debate.html</guid>
        
        <category>r</category>
        
        
        <category>programming</category>
        
      </item>
    
      <item>
        <title>Scraping via APIs</title>
        <description>&lt;style type=&quot;text/css&quot;&gt; 
&lt;!-- 
.hangingindent {
  padding-left: 80px ;
  padding-right: 80px ;
  text-indent: -32px ;
}
--&gt; 
&lt;/style&gt;

&lt;p&gt;&lt;a href=&quot;http://bradleyboehmke.github.io/2016/01/scraping-via-apis.html&quot;&gt;&lt;img src=&quot;https://d15n4q3o4x3svq.cloudfront.net/assets/tutorials/curl/api-a397cc184c5622fb5130af1b7baf149d.png&quot; alt=&quot;Scraping with APIs&quot; style=&quot;float:left; margin:-5px 0px -5px -10px; width: 19%; height: 19%;&quot; /&gt;&lt;/a&gt;
In the epic poem &lt;em&gt;Rime of the Ancient Mariner&lt;/em&gt;, Samuel Taylor Coleridge states, “Water, water, everywhere, nor any a drop to drink.” Indeed, some would say the same about data. Data appear to be &lt;a href=&quot;http://www.technologyreview.com/view/530371/big-data-creating-the-power-to-move-heaven-and-earth/&quot;&gt;everywhere&lt;/a&gt; yet only a &lt;a href=&quot;https://gigaom.com/2013/03/10/the-big-data-world-is-operating-at-1-percent/&quot;&gt;fraction are analyzed&lt;/a&gt;. There are several &lt;a href=&quot;http://www.mckinsey.com/insights/business_technology/big_data_the_next_frontier_for_innovation&quot;&gt;arguments&lt;/a&gt; as to why but one that has reached the concern of the &lt;a href=&quot;https://www.whitehouse.gov/sites/default/files/omb/assets/memoranda_2010/m10-06.pdf&quot;&gt;White House&lt;/a&gt; is data accessibility.  However, this is rapidly changing as growth in technology and resources are quickly opening the doors of many data vaults to the masses. We, the public minions, now have access to a wide range of data; from social, financial, government, and ecommerce data to geospatial, search engine, and even ant data. We just need to know how to &lt;em&gt;get&lt;/em&gt; it. Enter APIs.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tldr&quot;&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;Here’s what you should get out of this post:&lt;/p&gt;

&lt;p class=&quot;hangingindent&quot;&gt;&lt;span style=&quot;font-size: 20pt&quot;&gt;&lt;a href=&quot;#what_api&quot; style=&quot;color:black&quot;&gt;&amp;#9312;&lt;/a&gt;&lt;/span&gt;  What&#39;s an API? Just another way to communicate from R to a web-based database for a consistent data retrieval process.&lt;/p&gt;

&lt;p class=&quot;hangingindent&quot;&gt;&lt;span style=&quot;font-size: 20pt&quot;&gt;&lt;a href=&quot;#needs_api&quot; style=&quot;color:black&quot;&gt;&amp;#9313;&lt;/a&gt;&lt;/span&gt;   Prereqs? You&#39;ll need some metadata on the data you want (gotta know a little something about what you&#39;re trying to pull). And depending on the API you&#39;ll typically need a key (aka token) or OAuth.&lt;/p&gt;

&lt;p class=&quot;hangingindent&quot;&gt;&lt;span style=&quot;font-size: 20pt&quot;&gt;&lt;a href=&quot;#existing_api&quot; style=&quot;color:black&quot;&gt;&amp;#9314;&lt;/a&gt;&lt;/span&gt; There&#39;s probably an &lt;strike&gt;app&lt;/strike&gt; package for that. There&#39;s a slew of existing R API packages already built to access databases. I quickly cover 3 packages to give you a taste for how they typically work.&lt;/p&gt;

&lt;p class=&quot;hangingindent&quot;&gt;&lt;span style=&quot;font-size: 20pt&quot;&gt;&lt;a href=&quot;#httr_api&quot; style=&quot;color:black&quot;&gt;&amp;#9315;&lt;/a&gt;&lt;/span&gt; What if the API that you want data from does not yet have an R package developed for it? Use the `httr` package. I demonstrate how to use `httr` to request API data...both with and without OAuth. &lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;what_api&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;whats-an-api&quot;&gt;① What’s an API?&lt;/h2&gt;
&lt;p&gt;An &lt;a href=&quot;https://en.wikipedia.org/wiki/Application_programming_interface&quot;&gt;application-programming interface (API)&lt;/a&gt; in a nutshell is a method of communication between software programs.  APIs allow programs to interact and use each other’s functions by acting as a middle man. Why is this useful? Lets say you want to pull weather data from the &lt;a href=&quot;http://www.ncdc.noaa.gov/cdo-web/webservices&quot;&gt;NOAA&lt;/a&gt;.  You have a few options:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;You could query the data and download the spreadsheet or manually cut-n-paste the desired data and then import into R. Doesn’t get you any coolness points.&lt;/li&gt;
  &lt;li&gt;You could use some webscraping techniques previously covered &lt;a href=&quot;http://bradleyboehmke.github.io/2015/12/scraping-tabular-and-excel-files-stored-online.html&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;http://bradleyboehmke.github.io/2015/12/scraping-html-text.html&quot;&gt;here&lt;/a&gt;, and &lt;a href=&quot;http://bradleyboehmke.github.io/2015/12/scraping-html-tables.html&quot;&gt;here&lt;/a&gt; to parse the desired data. Golf clap. The downfall of this strategy is if NOAA changes their website structure down the road your code will need to be adjusted.&lt;/li&gt;
  &lt;li&gt;Or, you can use the &lt;a href=&quot;https://ropensci.org/tutorials/rnoaa_tutorial.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rnoaa&lt;/code&gt;&lt;/a&gt; package which allows you to send specific instructions to the NOAA API via R, the API will then perform the action requested and return the desired information. The benefit of this strategy is if the NOAA changes its website structure it won’t impact the API data retreival structure which means no impact to your code. Standing ovation!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Consequently, APIs provide consistency in data retrieval processes which can be essential for recurring analyses. Luckily, the use of APIs by organizations that collect data are &lt;a href=&quot;http://www.programmableweb.com/api-research&quot;&gt;growing exponentially&lt;/a&gt;. This is great for you and I as more and more data continues to be at our finger tips.&lt;/p&gt;

&lt;p&gt;So what do you need to get started?&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;needs_api&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;prereqs&quot;&gt;② Prereqs?&lt;/h2&gt;
&lt;p&gt;Each API is unique; however, there are a few fundamental pieces of information you’ll need to work with an API.  First, the reason you’re using an API is to request specific types of data from a specific data set from a specific organization. You at least need to know a little something about each one of these:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The URL for the organization and data you are pulling. Most pre-built API packages already have this connection established but when using &lt;code&gt;httr&lt;/code&gt; you&#39;ll need to specify.&lt;/li&gt;
  &lt;li&gt;The data set you are trying to pull from. Most organizations have numerous data sets to peruse so you need to make yourself familiar with the names of the available data sets.&lt;/li&gt;
  &lt;li&gt;The data content. You&#39;ll need to specify the specific data variables you want the API to retrieve so you&#39;ll need to be familiar with, or have access to, the data library.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In addition to these key components you will also, typically, need to provide a form of identification and/or authorization.  This is done via:&lt;/p&gt;

&lt;ol start=&quot;4&quot;&gt;
  &lt;li&gt;API key (aka token). A key is used to identify the user along with track and control how the API is being used (guard against malicious use). A key is often obtained by supplying basic information (i.e. name, email) to the organization and in return they give you a multi-digit key.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://oauth.net/&quot;&gt;OAuth&lt;/a&gt;. OAuth is an authorization framework that provides credentials as proof for access to certain information. Multiple forms of credentials exist and OAuth can actually be a fairly confusing topic; however, the &lt;code&gt;httr&lt;/code&gt; package has simplified this greatly which we demonstrate &lt;a href=&quot;#httr_api&quot;&gt;later&lt;/a&gt; in this post.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Rather than dwell on these components, they’ll likely become clearer as we progress through examples. So, let’s move on to the fun stuff.&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;existing_api&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;existing-api-packages&quot;&gt;③ Existing API Packages&lt;/h2&gt;
&lt;p&gt;Like everything else you do in R, when looking to work with an API your first question should be “Is there a package for that?” R has an extensive list of packages in which API data feeds have been hooked into R. You can find a slew of them scattered throughout the &lt;a href=&quot;https://cran.r-project.org/web/views/WebTechnologies.html&quot;&gt;CRAN Task View: Web Technologies and Services&lt;/a&gt; web page, on the &lt;a href=&quot;https://ropensci.org/packages/&quot;&gt;rOpenSci&lt;/a&gt; web page, and some more &lt;a href=&quot;http://stats.stackexchange.com/questions/12670/data-apis-feeds-available-as-packages-in-r&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To give you a taste for how these packages typically work, I’ll quickly cover three packages:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#blsAPI&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;blsAPI&lt;/code&gt;&lt;/a&gt; for pulling U.S. Bureau of Labor Statistics data&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#rnoaa&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rnoaa&lt;/code&gt;&lt;/a&gt; for pulling NOAA climate data&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#rtimes&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rtimes&lt;/code&gt;&lt;/a&gt; for pulling data from multiple APIs offered by the New York Times&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;blsAPI&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;blsapi&quot;&gt;blsAPI&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&quot;https://cran.r-project.org/web/packages/blsAPI/index.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;blsAPI&lt;/code&gt;&lt;/a&gt; allows users to request data for one or multiple series through the U.S. Bureau of Labor Statistics API. To use the &lt;code class=&quot;highlighter-rouge&quot;&gt;blsAPI&lt;/code&gt; app you only need knowledge on the data; no key or OAuth are required. I lllustrate by pulling &lt;a href=&quot;http://www.bls.gov/mls/mlsover.htm&quot;&gt;Mass Layoff Statistics&lt;/a&gt; data but you will find all the available data sets and their series code information &lt;a href=&quot;http://www.bls.gov/help/hlpforma.htm&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The key information you will be concerned about is contained in the series identifier.  For the Mass Layoff data the the series ID code  is MLUMS00NN0001003. Each component of this series code has meaning and can be adjusted to get specific Mass Layoff data.  The BLS provides this &lt;a href=&quot;http://www.bls.gov/help/hlpforma.htm#ML&quot;&gt;breakdown&lt;/a&gt; for what each component means along with the available list of codes for this data set.  For instance, the &lt;strong&gt;S00&lt;/strong&gt; (MLUM&lt;strong&gt;S00&lt;/strong&gt;NN0001003) component represents the &lt;a href=&quot;http://download.bls.gov/pub/time.series/ml/ml.srd&quot;&gt;division/state&lt;/a&gt;. S00 will pull for all states but I could change to D30 to pull data for the Midwest or S39 to pull for Ohio. The &lt;strong&gt;N0001&lt;/strong&gt; (MLUMS00N&lt;strong&gt;N0001&lt;/strong&gt;003) component represents the &lt;a href=&quot;http://download.bls.gov/pub/time.series/ml/ml.irc&quot;&gt;industry/demographics&lt;/a&gt;. N0001 pulls data for all industries but I could change to N0008 to pull data for the food industry or C00A2 for all persons age 30-44.&lt;/p&gt;

&lt;p&gt;I simply call the series identifier in the &lt;code class=&quot;highlighter-rouge&quot;&gt;blsAPI()&lt;/code&gt; function which pulls the JSON data object.  We can then use the &lt;code class=&quot;highlighter-rouge&quot;&gt;fromJSON()&lt;/code&gt; function from the &lt;code class=&quot;highlighter-rouge&quot;&gt;rjson&lt;/code&gt; package to convert to an R data object (a list in this case). You can see that the raw data pull provides a list of 4 items.  The first three provide some metadata info (status, response time, and message if applicable). The data we are concerned about is in the 4th (Results$series$data) list item which contains 31 observations.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rjson&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blsAPI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# supply series identifier to pull data (initial pull is in JSON data)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layoffs_json&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blsAPI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;MLUMS00NN0001003&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 

&lt;span class=&quot;c1&quot;&gt;# convert from JSON into R object
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layoffs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fromJSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layoffs_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                   

&lt;span class=&quot;n&quot;&gt;List&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chr&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;REQUEST_SUCCEEDED&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;responseTime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;38&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Results&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;List&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;series&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;List&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;List&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seriesID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chr&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;MLUMS00NN0001003&quot;&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;List&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;31&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;List&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chr&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;2013&quot;&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;period&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chr&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;M05&quot;&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;periodName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chr&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;May&quot;&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chr&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;1383&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;One of the inconveniences of an API is we do not get to specify how the data we receive is formatted. This is a minor price to pay considering all the other benefits APIs provide. Once we understand the received data format we can typically re-format using a little subsetting and looping.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# create empty data frame to fill  
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layoff_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# extract data of interest from each nested year-month list  
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_along&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layoffs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layoffs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]][&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;layoff_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layoff_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layoff_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   year period periodName value
## 1 2013    M05        May  1383
## 2 2013    M04      April  1174
## 3 2013    M03      March  1132
## 4 2013    M02   February   960
## 5 2013    M01    January  1528
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2012&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;M13&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;Annual&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;17080&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;blsAPI&lt;/code&gt; also allows you to pull multiple data series and has optional arguments (i.e. start year, end year, etc.). You can see other options at &lt;code class=&quot;highlighter-rouge&quot;&gt;help(package = blsAPI)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;rnoaa&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;rnoaa&quot;&gt;rnoaa&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&quot;https://ropensci.org/tutorials/rnoaa_tutorial.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rnoaa&lt;/code&gt;&lt;/a&gt; package allows users to request climate data from multiple data sets through the &lt;a href=&quot;http://www.ncdc.noaa.gov/cdo-web/webservices/v2&quot;&gt;National Climatic Data Center API&lt;/a&gt;. Unlike &lt;code class=&quot;highlighter-rouge&quot;&gt;blsAPI&lt;/code&gt;, the &lt;code class=&quot;highlighter-rouge&quot;&gt;rnoaa&lt;/code&gt; app requires you to have an API key.  To request a key go &lt;a href=&quot;http://www.ncdc.noaa.gov/cdo-web/token&quot;&gt;here&lt;/a&gt; and provide your email; a key will immediately be emailed to you.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;vXTdwNoAVx...&quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;truncated&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;With the key in hand, we can begin pulling data.  The NOAA provides a comprehensive &lt;a href=&quot;http://www.ncdc.noaa.gov/homr/reports&quot;&gt;metadata library&lt;/a&gt; to familiarize yourself with the data available. Let’s start by pulling all the available NOAA climate stations near my residence. I live in Montgomery county Ohio so we can find all the stations in this county by inserting the &lt;a href=&quot;http://www.census.gov/geo/reference/codes/cou.html&quot;&gt;FIPS code&lt;/a&gt;. Furthermore, I’m interested in stations that provide data for the &lt;a href=&quot;https://www.ncdc.noaa.gov/oa/climate/ghcn-daily/&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GHCND&lt;/code&gt; data set&lt;/a&gt; which contains records on numerous daily variables such as “maximum and minimum temperature, total daily precipitation, snowfall, and snow depth; however, about two thirds of the stations report precipitation only.” See &lt;code class=&quot;highlighter-rouge&quot;&gt;?ncdc_stations&lt;/code&gt; for other data sets available via &lt;code class=&quot;highlighter-rouge&quot;&gt;rnoaa&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnoaa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;stations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ncdc_stations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasetid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;GHCND&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
              &lt;span class=&quot;n&quot;&gt;locationid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;FIPS:39113&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;stations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## Source: local data frame [23 x 9]
## 
##    elevation    mindate    maxdate latitude
##        (dbl)      (chr)      (chr)    (dbl)
## 1      294.1 2009-02-09 2014-06-25  39.6314
## 2      251.8 2009-03-01 2016-01-16  39.6807
## 3      295.7 2009-03-25 2012-09-08  39.6252
## 4      298.1 2009-08-24 2012-07-20  39.8070
## 5      304.5 2010-04-02 2016-01-12  39.6949
## 6      283.5 2012-07-01 2016-01-16  39.7373
## 7      301.4 2012-07-29 2016-01-16  39.8795
## 8      317.3 2012-09-08 2016-01-12  39.8329
## 9      298.1 2012-09-07 2016-01-15  39.6247
## 10     250.5 2012-09-11 2016-01-08  39.7180
## ..       ...        ...        ...      ...
## Variables not shown: name (chr), datacoverage (dbl), id (chr),
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;elevationUnit&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longitude&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;So we see that several stations are available from which to pull data. To actually pull data from one of these stations we need the station ID.  The station I want to pull data from is the Dayton International Airport station.  We can see that this station provides data from 1948-present and I can get the station ID as illustrated.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dplyr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;stations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;DAYTON INTERNATIONAL AIRPORT, OH US&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mindate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## Source: local data frame [1 x 3]
## 
##      mindate    maxdate                id
##        (chr)      (chr)             (chr)
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1948-01-01&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2016-01-15&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GHCND&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;USW00093815&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To pull all available GHCND data from this station we’ll use &lt;code class=&quot;highlighter-rouge&quot;&gt;ncdc()&lt;/code&gt;.  We simply supply the data to pull, the start and end dates (&lt;code class=&quot;highlighter-rouge&quot;&gt;ncdc&lt;/code&gt; restricts you to a one year limit), station ID, and your key. We can see that this station provides a full range of data types.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;climate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ncdc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasetid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;GHCND&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
            &lt;span class=&quot;n&quot;&gt;startdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2015-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
            &lt;span class=&quot;n&quot;&gt;enddate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2016-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
            &lt;span class=&quot;n&quot;&gt;stationid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;GHCND:USW00093815&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;climate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## Source: local data frame [25 x 8]
## 
##                   date datatype           station value  fl_m  fl_q
##                  (chr)    (chr)             (chr) (int) (chr) (chr)
## 1  2015-01-01T00:00:00     AWND GHCND:USW00093815    72            
## 2  2015-01-01T00:00:00     PRCP GHCND:USW00093815     0            
## 3  2015-01-01T00:00:00     SNOW GHCND:USW00093815     0            
## 4  2015-01-01T00:00:00     SNWD GHCND:USW00093815     0            
## 5  2015-01-01T00:00:00     TAVG GHCND:USW00093815   -38     H      
## 6  2015-01-01T00:00:00     TMAX GHCND:USW00093815    28            
## 7  2015-01-01T00:00:00     TMIN GHCND:USW00093815   -71            
## 8  2015-01-01T00:00:00     WDF2 GHCND:USW00093815   240            
## 9  2015-01-01T00:00:00     WDF5 GHCND:USW00093815   240            
## 10 2015-01-01T00:00:00     WSF2 GHCND:USW00093815   130            
## ..                 ...      ...               ...   ...   ...   ...
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variables&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fl_so&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fl_t&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Since we recently had some snow here let’s pull data on snow fall for 2015. We adjust the limit argument (by default &lt;code class=&quot;highlighter-rouge&quot;&gt;ncdc&lt;/code&gt; limits results to 25) and identify the data type we want.  By sorting we see what days experienced the greatest snowfall (don’t worry, the results are reported in mm!).&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;snow&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ncdc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasetid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;GHCND&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
            &lt;span class=&quot;n&quot;&gt;startdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2015-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
            &lt;span class=&quot;n&quot;&gt;enddate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2015-12-31&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
            &lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;stationid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;GHCND:USW00093815&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;datatypeid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;SNOW&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;snow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;arrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## Source: local data frame [365 x 8]
## 
##                   date datatype           station value  fl_m  fl_q
##                  (chr)    (chr)             (chr) (int) (chr) (chr)
## 1  2015-03-01T00:00:00     SNOW GHCND:USW00093815   114            
## 2  2015-02-21T00:00:00     SNOW GHCND:USW00093815   109            
## 3  2015-01-25T00:00:00     SNOW GHCND:USW00093815    71            
## 4  2015-01-06T00:00:00     SNOW GHCND:USW00093815    66            
## 5  2015-02-16T00:00:00     SNOW GHCND:USW00093815    30            
## 6  2015-02-18T00:00:00     SNOW GHCND:USW00093815    25            
## 7  2015-02-14T00:00:00     SNOW GHCND:USW00093815    23            
## 8  2015-01-26T00:00:00     SNOW GHCND:USW00093815    20            
## 9  2015-02-04T00:00:00     SNOW GHCND:USW00093815    20            
## 10 2015-02-12T00:00:00     SNOW GHCND:USW00093815    20            
## ..                 ...      ...               ...   ...   ...   ...
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variables&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fl_so&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fl_t&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This is just an intro to &lt;code class=&quot;highlighter-rouge&quot;&gt;rnoaa&lt;/code&gt; as the package offers a slew of data sets to pull from and functions to apply.  It even offers built in plotting functions. Use &lt;code class=&quot;highlighter-rouge&quot;&gt;help(package = &quot;rnoaa&quot;)&lt;/code&gt; to see all that &lt;code class=&quot;highlighter-rouge&quot;&gt;rnoaa&lt;/code&gt; has to offer.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;rtimes&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;rtimes&quot;&gt;rtimes&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&quot;https://cran.r-project.org/web/packages/rtimes/index.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rtimes&lt;/code&gt;&lt;/a&gt; package provides an interface to Congress, Campaign Finance, Article Search, and Geographic APIs offered by the New York Times. The data libraries and documentation for the several APIs available can be found &lt;a href=&quot;http://developer.nytimes.com/docs/&quot;&gt;here&lt;/a&gt;. To use the Times’ API you’ll need to get an API key &lt;a href=&quot;http://developer.nytimes.com/apps/register&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;article_key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;4f23572d8...&quot;&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# truncated
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfinance_key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;ee0b7cef...&quot;&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# truncated
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;congress_key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;57b3e8a3...&quot;&lt;/span&gt;     &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;truncated&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Lets start by searching NY Times articles. With the presendential elections upon us, we can illustrate by searching the least controversial candidate…Donald Trump. We can see that there are 4,566 article hits for the term “Trump”. We can get more information on a particular article by subsetting.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rtimes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# article search for the term &#39;Trump&#39;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;articles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as_search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Trump&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                 &lt;span class=&quot;n&quot;&gt;begin_date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;20150101&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                 &lt;span class=&quot;n&quot;&gt;end_date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;20160101&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;article_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# summary
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;articles&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;meta&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   hits time offset
## 1 4565   28      0
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# pull info on 3rd article
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;articles&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [[1]]
## &amp;lt;NYTimes article&amp;gt;Donald Trump’s Strongest Supporters: A Certain Kind of Democrat
##   Type: News
##   Published: 2015-12-31T00:00:00Z
##   Word count: 1469
##   URL: http://www.nytimes.com/2015/12/31/upshot/donald-trumps-strongest-supporters-a-certain-kind-of-democrat.html
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;Snippet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;survey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;he&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;also&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;excels&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;among&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;turnout&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;voters&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;among&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;less&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;affluent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;less&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;educated&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;so&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;question&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Will&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;they&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;show&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;up&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vote&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We can use the campaign finance API and functions to gain some insight into Trumps compaign income and expenditures. The only special data you need is the &lt;a href=&quot;http://www.fec.gov/finance/disclosure/candcmte_info.shtml?tabIndex=2&quot;&gt;FEC ID&lt;/a&gt; for the candidate of interest.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;trump&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cf_candidate_details&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;campaign_cycle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2016&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                     &lt;span class=&quot;n&quot;&gt;fec_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;P80001571&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cfinance_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# pull summary data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trump&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;meta&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##          id            name party
## 1 P80001571 TRUMP, DONALD J   REP
##                                             fec_uri
## 1 http://docquery.fec.gov/cgi-bin/fecimg/?P80001571
##                    committee  mailing_address mailing_city
## 1 /committees/C00580100.json 725 FIFTH AVENUE     NEW YORK
##   mailing_state mailing_zip status total_receipts
## 1            NY       10022      O     1902410.45
##   total_from_individuals total_from_pacs total_contributions
## 1               92249.33               0            96298.97
##   candidate_loans total_disbursements begin_cash  end_cash
## 1      1804747.23          1414674.29          0 487736.16
##   total_refunds debts_owed date_coverage_from date_coverage_to
## 1             0 1804747.23         2015-04-02       2015-06-30
##   independent_expenditures coordinated_expenditures
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;                &lt;span class=&quot;m&quot;&gt;1644396.8&lt;/span&gt;                        &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rtimes&lt;/code&gt; also allows us to gain some insight into what our locally elected officials are up to with the Congress API. First, I can get some informaton on my Senator and then use that information to see if he’s supporting my interest. For instance, I can pull the most recent bills that he is co-sponsoring.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# pull info on OH senator
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;senator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cg_memberbystatedistrict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chamber&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;senate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                    &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;OH&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                    &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;congress_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;senator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;meta&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##        id           name               role gender party
## 1 B000944 Sherrod  Brown Senator, 1st Class      M     D
##   times_topics_url      twitter_id       youtube_id seniority
## 1                  SenSherrodBrown SherrodBrownOhio         9
##   next_election
## 1          2018
##                                                                               api_url
## 1 http://api.nytimes.com/svc/politics/v3/us/legislative/congress/members/B000944.json
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# use member ID to pull recent bill sponsorship
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bills&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cg_billscosponsor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memberid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;B000944&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                           &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;cosponsored&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                           &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;congress_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bills&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## Source: local data frame [6 x 11]
## 
##   congress    number
##      (chr)     (chr)
## 1      114    S.2098
## 2      114    S.2096
## 3      114    S.2100
## 4      114    S.2090
## 5      114 S.RES.267
## 6      114 S.RES.269
## Variables not shown: bill_uri (chr), title (chr), cosponsored_date
##   (chr), sponsor_id (chr), introduced_date (chr), cosponsors (chr),
##   committees (chr), latest_major_action_date (chr),
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;latest_major_action&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;It looks like the most recent bill Sherrod is co-sponsoring is S.2098 - Student Right to Know Before You Go Act.  Maybe I’ll do a NY Times article search with &lt;code class=&quot;highlighter-rouge&quot;&gt;as_search()&lt;/code&gt; to find out more about this bill…an exercise for another time.&lt;/p&gt;

&lt;p&gt;So this gives you some flavor of how these API packages work.  You typically need to know the data sets and variables requested along with an API key. But once you get these basics its pretty straight forward on requesting the data.  Your next question may be, what if the API that I want to get data from does not yet have an R package developed for it?&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;httr_api&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;httr-for-all-things-else&quot;&gt;④ httr for All Things Else&lt;/h2&gt;
&lt;p&gt;Although numerous R API packages are available, and cover a wide range of data, you may eventually run into a situation where you want to leverage an organization’s API but an R package does not exist. Enter &lt;a href=&quot;https://cran.r-project.org/web/packages/httr/index.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt;&lt;/a&gt;.  &lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt; was developed by Hadley Wickham to easily work with web APIs. It offers multiple functions (i.e. &lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD()&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;POST()&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;PATCH()&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;PUT()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;DELETE()&lt;/code&gt;); however, the function we are most concerned with today is &lt;code class=&quot;highlighter-rouge&quot;&gt;Get()&lt;/code&gt;. We use the &lt;code class=&quot;highlighter-rouge&quot;&gt;Get()&lt;/code&gt; function to access an API, provide it some request parameters, and receive an output.&lt;/p&gt;

&lt;p&gt;To give you a taste for how the &lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt; package works, I’ll quickly cover how to use it for a basic key-only API and an OAuth-required API:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#key_only&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Key-only API&lt;/code&gt;&lt;/a&gt; is illustrated by pulling U.S. Department of Education data available on &lt;a href=&quot;https://api.data.gov/docs/&quot;&gt;data.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#oauth&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;OAuth-required API&lt;/code&gt;&lt;/a&gt; is illustrated by pulling tweets from my personal Twitter feed&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;key_only&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;key-only-api&quot;&gt;Key-only API&lt;/h3&gt;
&lt;p&gt;To demonstrate how to use the &lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt; package for accessing a key-only API, I’ll illustrate with the &lt;a href=&quot;https://api.data.gov/docs/ed/&quot;&gt;College Scorecard API&lt;/a&gt; provided by the Department of Education. First, you’ll need to &lt;a href=&quot;https://api.data.gov/signup/&quot;&gt;request your API key&lt;/a&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;edu_key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;fd783wmS3Z...&quot;&lt;/span&gt;     &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;truncated&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We can now proceed to use &lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt; to request data from the API with the &lt;code class=&quot;highlighter-rouge&quot;&gt;GET()&lt;/code&gt; function.  I went to North Dakota State University (NDSU) for my undergrad so I’m interested in pulling some data for this school. I can use the provided &lt;a href=&quot;https://collegescorecard.ed.gov/data/documentation/&quot;&gt;data library&lt;/a&gt; and &lt;a href=&quot;https://github.com/18F/open-data-maker/blob/api-docs/API.md&quot;&gt;query explanation&lt;/a&gt; to determine the parameters required.  In this example, the &lt;code class=&quot;highlighter-rouge&quot;&gt;URL&lt;/code&gt; includes the primary path (“https://api.data.gov/ed/collegescorecard/”), the API version (“v1”), and the endpoint (“schools”). The question mark (“?”) at the end of the URL is included to begin the list of query parameters, which only includes my API key and the school of interest.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;httr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;URL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;https://api.data.gov/ed/collegescorecard/v1/schools?&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# import all available data for NDSU
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndsu_req&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;api_key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edu_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                  &lt;span class=&quot;n&quot;&gt;school.name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;North Dakota State University&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This request provides me with every piece of information collected by the U.S. Department of Education for NDSU. To retrieve the contents of this request I use the &lt;code class=&quot;highlighter-rouge&quot;&gt;content()&lt;/code&gt; function which will output the data as an R object (a list in this case).  The data is segmented into two main components: &lt;em&gt;metadata&lt;/em&gt; and &lt;em&gt;results&lt;/em&gt;. I’m primarily interested in the results.&lt;/p&gt;

&lt;p&gt;The results branch of this list provides information on lat-long location, school identifier codes, some basic info on the school (city, number of branches, school website, accreditor, etc.), and then student data for the years 1997-2013.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ndsu_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndsu_req&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndsu_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot;metadata&quot; &quot;results&quot;
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndsu_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##  [1] &quot;2008&quot;     &quot;2009&quot;     &quot;2006&quot;     &quot;ope6_id&quot;  &quot;2007&quot;     &quot;2004&quot;    
##  [7] &quot;2013&quot;     &quot;2005&quot;     &quot;location&quot; &quot;2002&quot;     &quot;2003&quot;     &quot;id&quot;      
## [13] &quot;1996&quot;     &quot;1997&quot;     &quot;school&quot;   &quot;1998&quot;     &quot;2012&quot;     &quot;2011&quot;    
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;19&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;2010&quot;&lt;/span&gt;     &lt;span class=&quot;s2&quot;&gt;&quot;ope8_id&quot;&lt;/span&gt;  &lt;span class=&quot;s2&quot;&gt;&quot;1999&quot;&lt;/span&gt;     &lt;span class=&quot;s2&quot;&gt;&quot;2001&quot;&lt;/span&gt;     &lt;span class=&quot;s2&quot;&gt;&quot;2000&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To see what kind of student data categories are offered we can assess a single year. You can see that available data includes earnings, academics, student info/demographics, admissions, costs, etc. With such a large data set, which includes many embedded lists, sometimes the easiest way to learn the data structure is to peruse names at different levels.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# student data categories available by year
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndsu_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`2013`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot;earnings&quot;   &quot;academics&quot;  &quot;student&quot;    &quot;admissions&quot; &quot;repayment&quot; 
## [6] &quot;aid&quot;        &quot;cost&quot;       &quot;completion&quot;
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# cost categories available by year
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndsu_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`2013`&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot;title_iv&quot;      &quot;avg_net_price&quot; &quot;attendance&quot;    &quot;tuition&quot;      
## [5] &quot;net_price&quot;
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Avg net price cost categories available by year
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndsu_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`2013`&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_net_price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot;other_academic_year&quot; &quot;overall&quot;             &quot;program_year&quot;       
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;public&quot;&lt;/span&gt;              &lt;span class=&quot;s2&quot;&gt;&quot;private&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;So if I’m interested in comparing the rise in cost versus the rise in student debt I can simply pull this data once I’ve identified its location and naming structure.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;magrittr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# subset list for annual student data only
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndsu_yr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ndsu_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as.character&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1996&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2013&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# extract median debt data for each year
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndsu_yr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;median_debt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;completers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;overall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##    1997    1998    1999    2000    2001    2002    2003    2004 
## 13388.0 13856.0 14500.0 15125.0 15507.0 15639.0 16251.0 16642.5 
##    2005    2006    2007    2008    2009    2010    2011    2012 
## 17125.0 17125.0 17125.0 17250.0 19125.0 21500.0 23000.0 24954.5 
##    2013 
## 25050.0
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# extract net price for each year
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndsu_yr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;sapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_net_price&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;overall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##  2009  2010  2011  2012  2013 
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;13474&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;12989&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;13808&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15113&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;14404&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Quite simple isn’t it…at least once you’ve learned how the query requests are formatted for a particular API.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;oauth&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;oauth-required-api&quot;&gt;OAuth-required API&lt;/h3&gt;
&lt;p&gt;At the outset I mentioned how OAuth is an authorization framework that provides credentials as proof for access. Many APIs are open to the public and only require an API key; however, some APIs require authorization to account data (think personal Facebook &amp;amp; Twitter accounts). To access these accounts we must provide proper credentials and OAuth authentication allows us to do this. This post is not meant to explain the details of OAuth (for that see &lt;a href=&quot;http://hueniverse.com/2007/09/05/explaining-oauth/&quot;&gt;this&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/OAuth&quot;&gt;this&lt;/a&gt;, and &lt;a href=&quot;http://hueniverse.com/oauth/&quot;&gt;this&lt;/a&gt;) but, rather, how to use &lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt; in times when OAuth is required.&lt;/p&gt;

&lt;p&gt;I’ll demonstrate by accessing the Twitter API using my Twitter account. The first thing we need to do is identify the OAuth endpoints used to request access and authorization. To do this we can use &lt;code class=&quot;highlighter-rouge&quot;&gt;oauth_endpoint()&lt;/code&gt; which typically requires a &lt;em&gt;request&lt;/em&gt; URL, &lt;em&gt;authorization&lt;/em&gt; URL, and &lt;em&gt;access&lt;/em&gt; URL. &lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt; also included some baked-in endpoints to include LinkedIn, Twitter, Vimeo, Google, Facebook, and GitHub. We can see the Twitter endpoints using the following:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;twitter_endpts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oauth_endpoints&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;twitter&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;twitter_endpts&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## &amp;lt;oauth_endpoint&amp;gt;
##  request:   https://api.twitter.com/oauth/request_token
##  authorize: https://api.twitter.com/oauth/authenticate
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;access&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;://&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;api.twitter.com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oauth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;access_token&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Next, I register my application at &lt;a href=&quot;https://apps.twitter.com/&quot;&gt;https://apps.twitter.com/&lt;/a&gt;.  One thing to note is during the registration process, it will ask you for the &lt;em&gt;callback url&lt;/em&gt;; be sure to use “http://127.0.0.1:1410”. Once registered, Twitter will provide you with keys and access tokens. The two we are concerned about are the API key and API Secret.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;twitter_key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;BZgukbCol...&quot;&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# truncated
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;twitter_secret&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;YpB8Xy...&quot;&lt;/span&gt;   &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;truncated&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We can then bundle the consumer key and secret into one object with &lt;code class=&quot;highlighter-rouge&quot;&gt;oauth_app()&lt;/code&gt;. The first argument, &lt;code class=&quot;highlighter-rouge&quot;&gt;appname&lt;/code&gt; is simply used as a local identifier; it does not need to match the name you gave the Twitter app you developed at https://apps.twitter.com/.&lt;/p&gt;

&lt;p&gt;We are now ready to ask for access credentials. Since Twitter uses OAuth 1.0 we use &lt;code class=&quot;highlighter-rouge&quot;&gt;oauth1.0_token()&lt;/code&gt; function and incorporate the endpoints identified and the &lt;code class=&quot;highlighter-rouge&quot;&gt;oauth_app&lt;/code&gt; object we previously named &lt;code class=&quot;highlighter-rouge&quot;&gt;twitter_app&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;twitter_token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oauth1.0_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endpoint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;twitter_endpts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;twitter_app&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Waiting&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;authentication&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;browser...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Press&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Esc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ctrl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;abort&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Authentication&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;complete.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Once authentication is complete we can now use the API. I can pull all the tweets that show up on my personal timeline using the &lt;code class=&quot;highlighter-rouge&quot;&gt;GET()&lt;/code&gt; function and the access cridentials I stored in &lt;code class=&quot;highlighter-rouge&quot;&gt;twitter_token&lt;/code&gt;.  I then use &lt;code class=&quot;highlighter-rouge&quot;&gt;content()&lt;/code&gt; to convert to a list and I can start to analyze the data.&lt;/p&gt;

&lt;p&gt;In this case each tweet is saved as an individual list item and a full range of data are provided for each tweet (i.e. id, text, user, geo location, favorite count, etc). For instance, we can see that the first tweet was by &lt;a href=&quot;http://fivethirtyeight.com/&quot;&gt;FiveThirtyEight&lt;/a&gt; concerning American politics and, at the time of this analysis, has been favorited by 3 people.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# request Twitter data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;req&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://api.twitter.com/1.1/statuses/home_timeline.json&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;twitter_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# convert to R object
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;req&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# available data for first tweet on my timeline
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;created_at&quot;&lt;/span&gt;                    &lt;span class=&quot;s2&quot;&gt;&quot;id&quot;&lt;/span&gt;                           
 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;id_str&quot;&lt;/span&gt;                        &lt;span class=&quot;s2&quot;&gt;&quot;text&quot;&lt;/span&gt;                         
 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;source&quot;&lt;/span&gt;                        &lt;span class=&quot;s2&quot;&gt;&quot;truncated&quot;&lt;/span&gt;                    
 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;in_reply_to_status_id&quot;&lt;/span&gt;         &lt;span class=&quot;s2&quot;&gt;&quot;in_reply_to_status_id_str&quot;&lt;/span&gt;    
 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;in_reply_to_user_id&quot;&lt;/span&gt;           &lt;span class=&quot;s2&quot;&gt;&quot;in_reply_to_user_id_str&quot;&lt;/span&gt;      
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;in_reply_to_screen_name&quot;&lt;/span&gt;       &lt;span class=&quot;s2&quot;&gt;&quot;user&quot;&lt;/span&gt;                         
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;geo&quot;&lt;/span&gt;                           &lt;span class=&quot;s2&quot;&gt;&quot;coordinates&quot;&lt;/span&gt;                  
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;place&quot;&lt;/span&gt;                         &lt;span class=&quot;s2&quot;&gt;&quot;contributors&quot;&lt;/span&gt;                 
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;is_quote_status&quot;&lt;/span&gt;               &lt;span class=&quot;s2&quot;&gt;&quot;retweet_count&quot;&lt;/span&gt;                
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;19&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;favorite_count&quot;&lt;/span&gt;                &lt;span class=&quot;s2&quot;&gt;&quot;entities&quot;&lt;/span&gt;                     
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;extended_entities&quot;&lt;/span&gt;             &lt;span class=&quot;s2&quot;&gt;&quot;favorited&quot;&lt;/span&gt;                    
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;retweeted&quot;&lt;/span&gt;                     &lt;span class=&quot;s2&quot;&gt;&quot;possibly_sensitive&quot;&lt;/span&gt;           
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;possibly_sensitive_appealable&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;lang&quot;&lt;/span&gt; 

&lt;span class=&quot;c1&quot;&gt;# further analysis of first tweet on my timeline
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;FiveThirtyEight&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;\U0001f3a7 A History Of Data In American Politics (Part 1): William Jennings Bryan to Barack Obama https://t.co/oCKzrXuRHf  https://t.co/6CvKKToxoH&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tweets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;favorite_count&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This provides a fairly simple example of incorporating OAuth authorization. The &lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt; provides several examples of accessing common social network APIs that require OAuth. I recommend you go through several of these examples to get familiar with using OAuth authorization; see them at &lt;code class=&quot;highlighter-rouge&quot;&gt;demo(package = &quot;httr&quot;)&lt;/code&gt;. The most difficult aspect of creating your own connections with APIs is gaining an understanding of the API and the arguments they leverage.  This obviously requires time and energy devoted to digging into the API documentation and data library. Next its just a matter of trial and error (likely more the latter than the former) to learn how to translate these arguments into &lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt; function calls to pull the data of interest.&lt;/p&gt;

&lt;p&gt;Also, note that &lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt; provides several other useful functions not covered here for communicating with APIs (i.e. &lt;code class=&quot;highlighter-rouge&quot;&gt;POST()&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;BROWSE()&lt;/code&gt;). For more on these other &lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt; capabilities see this &lt;a href=&quot;https://cran.r-project.org/web/packages/httr/vignettes/quickstart.html&quot;&gt;quickstart vignette&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;As the growth in publicly available data continues, APIs appear to be the preferred medium for access. This will require analysts to become more familiar with interacting with APIs and the prerequisites they often require. R API packages are being developed quickly and should be your first search when looking to request data via an API. As illustrated, these packages tend to be very easy to work with. However, when you want to leverage an organization’s API that has not been integrated into an R package, the &lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt; package provides a convenient way to request data.&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Edit: 2016-01-20&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Thanks to &lt;a href=&quot;https://twitter.com/patrickhausmann&quot;&gt;Patrick Hausmann&lt;/a&gt; for providing the following comment; you may find it useful as I certainly did. “If you run the &lt;code class=&quot;highlighter-rouge&quot;&gt;httr&lt;/code&gt; authentication inside a function you are always prompted for a response. You can surpress this by setting the &lt;code class=&quot;highlighter-rouge&quot;&gt;httr_oauth_cache&lt;/code&gt; option to TRUE (see also &lt;a href=&quot;http://stackoverflow.com/q/28221405&quot;&gt;http://stackoverflow.com/q/28221405&lt;/a&gt;).”&lt;/p&gt;

</description>
        <pubDate>Mon, 18 Jan 2016 11:04:27 -0500</pubDate>
        <link>http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2016/01/scraping-via-apis.html</link>
        <guid isPermaLink="true">http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2016/01/scraping-via-apis.html</guid>
        
        <category>r</category>
        
        <category>httr</category>
        
        <category>web-scraping</category>
        
        
        <category>programming</category>
        
      </item>
    
      <item>
        <title>Scraping HTML Tables</title>
        <description>&lt;style type=&quot;text/css&quot;&gt; 
&lt;!-- 
        .indented { 
                padding-left: 25pt; 
                padding-right: 50pt; 
                } 
--&gt; 
&lt;/style&gt;

&lt;p&gt;&lt;a href=&quot;http://bradleyboehmke.github.io//2015/12/scraping-html-tables.html&quot;&gt;&lt;img src=&quot;https://analystatlarge.files.wordpress.com/2014/05/result.png&quot; alt=&quot;Scraping HTML Tables&quot; style=&quot;float:left; margin:0px 8px 0px 0px; width: 17%; height: 17%;&quot; /&gt;&lt;/a&gt;
With my previous two blog posts I implicitly started a series that covers common web scraping capabilities offered by R. In my first &lt;a href=&quot;http://bradleyboehmke.github.io//2015/12/scraping-tabular-and-excel-files-stored-online.html&quot;&gt;post&lt;/a&gt; I covered how to import tabular (i.e. .txt, .csv) or Excel files that are hosted online and in my last &lt;a href=&quot;http://bradleyboehmke.github.io//2015/12/scraping-html-text.html&quot;&gt;post&lt;/a&gt; I covered text scraping. In this post I cover how to scrape data from another common structure of data storage on the Web - HTML tables.&lt;!--more--&gt;&lt;/p&gt;

&lt;h2 id=&quot;tldr&quot;&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;Time deficient? Here’s the synopsis. This tutorial reiterates some of the information from my previous text scraping &lt;a href=&quot;http://bradleyboehmke.github.io//2015/12/scraping-html-text.html&quot;&gt;post&lt;/a&gt;; however, I focus solely on scraping data from HTML tables. To demonstrate, I focus on the &lt;a href=&quot;http://www.bls.gov/web/empsit/cesbmart.htm&quot;&gt;BLS employment statistics webpage&lt;/a&gt; and illustrate:&lt;/p&gt;

&lt;p class=&quot;indented&quot;&gt;
        &lt;span style=&quot;font-size: 20pt&quot;&gt;&lt;a href=&quot;#rvest&quot;&gt;&amp;#9312;&lt;/a&gt;&lt;/span&gt; How to use &lt;code&gt;rvest&lt;/code&gt; to extract all tables or only specified ones along with correcting for split heading tables.
        &lt;br /&gt;
        &lt;span style=&quot;font-size: 20pt&quot;&gt;&lt;a href=&quot;#xml&quot;&gt;&amp;#9313;&lt;/a&gt;&lt;/span&gt; Similarly, how to use &lt;code&gt;xml&lt;/code&gt; to extract all or only specified tables along with exhibiting some of its handy arguments such as specifying column names, classes, and skipping rows.
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;rvest&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;scraping-html-tables-with-rvest&quot;&gt;① Scraping HTML Tables with rvest&lt;/h2&gt;
&lt;p&gt;Recall that HTML elements are written with a start tag, an end tag, and with the content in between: &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;tagname&amp;gt;content&amp;lt;/tagname&amp;gt;&lt;/code&gt;. Don’t recall? Then read this &lt;a href=&quot;http://bradleyboehmke.github.io//2015/12/scraping-html-text.html#html_nodes&quot;&gt;HTML element précis&lt;/a&gt; from last week for a primer. HTML tables are contained within &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;table&amp;gt;&lt;/code&gt; tags; therefore, to extract the tables from the &lt;a href=&quot;http://www.bls.gov/web/empsit/cesbmart.htm&quot;&gt;BLS employment statistics webpage&lt;/a&gt; we first use the &lt;code class=&quot;highlighter-rouge&quot;&gt;html_nodes()&lt;/code&gt; function to select the &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;table&amp;gt;&lt;/code&gt; nodes.  In this case we are interested in all table nodes that exist on the webpage. In this example, &lt;code class=&quot;highlighter-rouge&quot;&gt;html_nodes&lt;/code&gt; captures 15 HTML tables. This includes data from the 10 data tables seen on the webpage but also includes data from a few additional tables used to format parts of the page (i.e. table of contents, table of figures, advertisements).&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rvest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;webpage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://www.bls.gov/web/empsit/cesbmart.htm&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tbls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;webpage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;table&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## {xml_nodeset (6)}
## [1] &amp;lt;table id=&quot;main-content-table&quot;&amp;gt;&amp;amp;#13;\n\t&amp;lt;tr&amp;gt;&amp;amp;#13;\n\t\t&amp;lt;td id=&quot;secon ...
## [2] &amp;lt;table id=&quot;Table1&quot; class=&quot;regular&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot; x ...
## [3] &amp;lt;table id=&quot;Table2&quot; class=&quot;regular&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot; x ...
## [4] &amp;lt;table id=&quot;Table3&quot; class=&quot;regular&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot; x ...
## [5] &amp;lt;table id=&quot;Table4&quot; class=&quot;regular&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot; x ...
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Exhibit1&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;regular&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cellspacing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;0&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cellpadding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;0&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Remember that &lt;code class=&quot;highlighter-rouge&quot;&gt;html_nodes()&lt;/code&gt; does not parse the data; rather, it &lt;a href=&quot;http://bradleyboehmke.github.io//2015/12/scraping-html-text.html#scraping_nodes&quot;&gt;acts as a CSS selector&lt;/a&gt;. To parse the HTML table data we use &lt;code class=&quot;highlighter-rouge&quot;&gt;html_table()&lt;/code&gt;, which would create a list containing 15 data frames.  However, rarely do we need to scrape &lt;em&gt;every&lt;/em&gt; HTML table from a page, especially since some HTML tables don’t catch any information we are likely interested in (i.e. table of contents, table of figures, footers).&lt;/p&gt;

&lt;p&gt;More often than not we want to parse specific tables. Lets assume we want to parse the second and third tables on the webpage:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Table 2. Nonfarm employment benchmarks by industry, March 2014 (in thousands) and&lt;/li&gt;
  &lt;li&gt;Table 3. Net birth/death estimates by industry supersector, April – December 2014 (in thousands)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This can be accomplished two ways. First, we can assess the previous &lt;code class=&quot;highlighter-rouge&quot;&gt;tbls&lt;/code&gt; list and try to identify the table(s) of interest. In this example it appears that &lt;code class=&quot;highlighter-rouge&quot;&gt;tbls&lt;/code&gt; list items 3 and 4 correspond with Table 2 and Table 3, respectively. We can then subset the list of table nodes prior to parsing the data with &lt;code class=&quot;highlighter-rouge&quot;&gt;html_table()&lt;/code&gt;. This results in a list of two data frames containing the data of interest.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;tbls_ls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webpage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;table&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## List of 2
##  $ :&#39;data.frame&#39;:	147 obs. of  6 variables:
##   ..$ CES Industry Code : chr [1:147] &quot;Amount&quot; &quot;00-000000&quot; &quot;05-000000&quot; &quot;06-000000&quot; ...
##   ..$ CES Industry Title: chr [1:147] &quot;Percent&quot; &quot;Total nonfarm&quot; &quot;Total private&quot; &quot;Goods-producing&quot; ...
##   ..$ Benchmark         : chr [1:147] NA &quot;137,214&quot; &quot;114,989&quot; &quot;18,675&quot; ...
##   ..$ Estimate          : chr [1:147] NA &quot;137,147&quot; &quot;114,884&quot; &quot;18,558&quot; ...
##   ..$ Differences       : num [1:147] NA 67 105 117 -50 -12 -16 -2.8 -13.2 -13.5 ...
##   ..$ NA                : chr [1:147] NA &quot;(1)&quot; &quot;0.1&quot; &quot;0.6&quot; ...
##  $ :&#39;data.frame&#39;:	11 obs. of  12 variables:
##   ..$ CES Industry Code : chr [1:11] &quot;10-000000&quot; &quot;20-000000&quot; &quot;30-000000&quot; &quot;40-000000&quot; ...
##   ..$ CES Industry Title: chr [1:11] &quot;Mining and logging&quot; &quot;Construction&quot; &quot;Manufacturing&quot; &quot;Trade, transportation, and utilities&quot; ...
##   ..$ Apr               : int [1:11] 2 35 0 21 0 8 81 22 82 12 ...
##   ..$ May               : int [1:11] 2 37 6 24 5 8 22 13 81 6 ...
##   ..$ Jun               : int [1:11] 2 24 4 12 0 4 5 -14 86 6 ...
##   ..$ Jul               : int [1:11] 2 12 -3 7 -1 3 35 7 62 -2 ...
##   ..$ Aug               : int [1:11] 1 12 4 14 3 4 19 21 23 3 ...
##   ..$ Sep               : int [1:11] 1 7 1 9 -1 -1 -12 12 -33 -2 ...
##   ..$ Oct               : int [1:11] 1 12 3 28 6 16 76 35 -17 4 ...
##   ..$ Nov               : int [1:11] 1 -10 2 10 3 3 14 14 -22 1 ...
##   ..$ Dec               : int [1:11] 0 -21 0 4 0 10 -10 -3 4 1 ...
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;   &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CumulativeTotal&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;12&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;108&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;17&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;129&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;55&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;230&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;107&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;266&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;29&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;An alternative approach, which is more explicit, is to use the &lt;a href=&quot;http://bradleyboehmke.github.io//2015/12/scraping-html-text.html#specific_nodes&quot;&gt;element selector process described in the text scraping tutorial&lt;/a&gt; to call the table ID name.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# empty list to add table data to
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls2_ls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# scrape Table 2. Nonfarm employment...
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls2_ls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Table1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webpage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#Table2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;html_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Table 3. Net birth/death...
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls2_ls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Table2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;webpage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#Table3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;html_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls2_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## List of 2
##  $ Table1:&#39;data.frame&#39;:	147 obs. of  6 variables:
##   ..$ CES Industry Code : chr [1:147] &quot;Amount&quot; &quot;00-000000&quot; &quot;05-000000&quot; &quot;06-000000&quot; ...
##   ..$ CES Industry Title: chr [1:147] &quot;Percent&quot; &quot;Total nonfarm&quot; &quot;Total private&quot; &quot;Goods-producing&quot; ...
##   ..$ Benchmark         : chr [1:147] NA &quot;137,214&quot; &quot;114,989&quot; &quot;18,675&quot; ...
##   ..$ Estimate          : chr [1:147] NA &quot;137,147&quot; &quot;114,884&quot; &quot;18,558&quot; ...
##   ..$ Differences       : num [1:147] NA 67 105 117 -50 -12 -16 -2.8 -13.2 -13.5 ...
##   ..$ NA                : chr [1:147] NA &quot;(1)&quot; &quot;0.1&quot; &quot;0.6&quot; ...
##  $ Table2:&#39;data.frame&#39;:	11 obs. of  12 variables:
##   ..$ CES Industry Code : chr [1:11] &quot;10-000000&quot; &quot;20-000000&quot; &quot;30-000000&quot; &quot;40-000000&quot; ...
##   ..$ CES Industry Title: chr [1:11] &quot;Mining and logging&quot; &quot;Construction&quot; &quot;Manufacturing&quot; &quot;Trade, transportation, and utilities&quot; ...
##   ..$ Apr               : int [1:11] 2 35 0 21 0 8 81 22 82 12 ...
##   ..$ May               : int [1:11] 2 37 6 24 5 8 22 13 81 6 ...
##   ..$ Jun               : int [1:11] 2 24 4 12 0 4 5 -14 86 6 ...
##   ..$ Jul               : int [1:11] 2 12 -3 7 -1 3 35 7 62 -2 ...
##   ..$ Aug               : int [1:11] 1 12 4 14 3 4 19 21 23 3 ...
##   ..$ Sep               : int [1:11] 1 7 1 9 -1 -1 -12 12 -33 -2 ...
##   ..$ Oct               : int [1:11] 1 12 3 28 6 16 76 35 -17 4 ...
##   ..$ Nov               : int [1:11] 1 -10 2 10 3 3 14 14 -22 1 ...
##   ..$ Dec               : int [1:11] 0 -21 0 4 0 10 -10 -3 4 1 ...
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;   &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CumulativeTotal&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;12&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;108&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;17&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;129&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;55&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;230&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;107&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;266&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;29&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;One issue to note is when using &lt;code class=&quot;highlighter-rouge&quot;&gt;rvest&lt;/code&gt;’s &lt;code class=&quot;highlighter-rouge&quot;&gt;html_table()&lt;/code&gt; to read a table with split column headings as in &lt;em&gt;Table 2. Nonfarm employment…&lt;/em&gt;.  &lt;code class=&quot;highlighter-rouge&quot;&gt;html_table&lt;/code&gt; will cause split headings to be included and can cause the first row to include parts of the headings.  We can see this with Table 2.  This requires a little clean up.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls2_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   CES Industry Code CES Industry Title Benchmark Estimate Differences   NA
## 1            Amount            Percent      &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;          NA &amp;lt;NA&amp;gt;
## 2         00-000000      Total nonfarm   137,214  137,147          67  (1)
## 3         05-000000      Total private   114,989  114,884         105  0.1
## 4         06-000000    Goods-producing    18,675   18,558         117  0.6
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# remove row 1 that includes part of the headings
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls2_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbls2_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]][&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# rename table headings
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colnames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls2_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;CES_Code&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Ind_Title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Benchmark&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                            &lt;span class=&quot;s2&quot;&gt;&quot;Estimate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Amt_Diff&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Pct_Diff&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls2_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##    CES_Code         Ind_Title Benchmark Estimate Amt_Diff Pct_Diff
## 2 00-000000     Total nonfarm   137,214  137,147       67      (1)
## 3 05-000000     Total private   114,989  114,884      105      0.1
## 4 06-000000   Goods-producing    18,675   18,558      117      0.6
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;07-000000&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Service&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;providing&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;118&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;539&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;118&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;589&lt;/span&gt;      &lt;span class=&quot;m&quot;&gt;-50&lt;/span&gt;      &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;xml&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;scraping-html-tables-with-xml&quot;&gt;② Scraping HTML Tables with XML&lt;/h2&gt;
&lt;p&gt;An alternative to &lt;code class=&quot;highlighter-rouge&quot;&gt;rvest&lt;/code&gt; for table scraping is to use the &lt;a href=&quot;https://cran.r-project.org/web/packages/XML/index.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;XML&lt;/code&gt;&lt;/a&gt; package. The XML package provides a convenient &lt;code class=&quot;highlighter-rouge&quot;&gt;readHTMLTable()&lt;/code&gt; function to extract data from HTML tables in HTML documents.  By passing the URL to &lt;code class=&quot;highlighter-rouge&quot;&gt;readHTMLTable()&lt;/code&gt;, the data in each table is read and stored as a data frame.  In a situation like our running example where multiple tables exists, the data frames will be stored in a list similar to &lt;code class=&quot;highlighter-rouge&quot;&gt;rvest&lt;/code&gt;’s &lt;code class=&quot;highlighter-rouge&quot;&gt;html_table&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;XML&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;http://www.bls.gov/web/empsit/cesbmart.htm&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# read in HTML data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls_xml&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;readHTMLTable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;typeof&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls_xml&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot;list&quot;
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls_xml&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You can see that &lt;code class=&quot;highlighter-rouge&quot;&gt;tbls_xml&lt;/code&gt; captures the same 15 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;table&amp;gt;&lt;/code&gt; nodes that &lt;code class=&quot;highlighter-rouge&quot;&gt;html_nodes&lt;/code&gt; captured. To capture the same tables of interest we previously discussed (&lt;em&gt;Table 2. Nonfarm employment…&lt;/em&gt; and &lt;em&gt;Table 3. Net birth/death…&lt;/em&gt;) we can use a couple approaches. First, we can assess &lt;code class=&quot;highlighter-rouge&quot;&gt;str(tbls_xml)&lt;/code&gt; to identify the tables of interest and perform normal &lt;a href=&quot;http://bradleyboehmke.github.io//tutorials/list#subsetting&quot;&gt;list subsetting&lt;/a&gt;. In our example list items 3 and 4 correspond with our tables of interest.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls_xml&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##          V1                        V2      V3      V4  V5   V6
## 1 00-000000             Total nonfarm 137,214 137,147  67  (1)
## 2 05-000000             Total private 114,989 114,884 105  0.1
## 3 06-000000           Goods-producing  18,675  18,558 117  0.6
## 4 07-000000         Service-providing 118,539 118,589 -50  (1)
## 5 08-000000 Private service-providing  96,314  96,326 -12  (1)
## 6 10-000000        Mining and logging     868     884 -16 -1.8
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbls_xml&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   CES Industry Code CES Industry Title Apr May Jun Jul Aug Sep Oct Nov Dec  CumulativeTotal
## 1         10-000000 Mining and logging   2   2   2   2   1   1   1   1   0                12
## 2         20-000000       Construction  35  37  24  12  12   7  12 -10 -21               108
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;         &lt;span class=&quot;m&quot;&gt;30-000000&lt;/span&gt;      &lt;span class=&quot;n&quot;&gt;Manufacturing&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;-3&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;                &lt;span class=&quot;m&quot;&gt;17&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Second, we can use the &lt;code class=&quot;highlighter-rouge&quot;&gt;which&lt;/code&gt; argument in &lt;code class=&quot;highlighter-rouge&quot;&gt;readHTMLTable()&lt;/code&gt; which restricts the data importing to only those tables specified numerically.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# only parse the 3rd and 4th tables
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emp_ls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;readHTMLTable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;which&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emp_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## List of 2
##  $ Table2:&#39;data.frame&#39;:	145 obs. of  6 variables:
##   ..$ V1: Factor w/ 145 levels &quot;00-000000&quot;,&quot;05-000000&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
##   ..$ V2: Factor w/ 143 levels &quot;Accommodation&quot;,..: 130 131 52 116 102 74 67 73 90 75 ...
##   ..$ V3: Factor w/ 145 levels &quot;1,010.3&quot;,&quot;1,048.3&quot;,..: 40 35 48 37 145 140 109 135 51 65 ...
##   ..$ V4: Factor w/ 145 levels &quot;1,008.4&quot;,&quot;1,052.3&quot;,..: 41 34 48 36 144 142 109 136 66 65 ...
##   ..$ V5: Factor w/ 123 levels &quot;-0.3&quot;,&quot;-0.4&quot;,..: 113 68 71 48 9 19 29 11 12 43 ...
##   ..$ V6: Factor w/ 56 levels &quot;-0.1&quot;,&quot;-0.2&quot;,..: 30 31 36 30 30 16 28 14 29 22 ...
##  $ Table3:&#39;data.frame&#39;:	11 obs. of  12 variables:
##   ..$ CES Industry Code : Factor w/ 11 levels &quot;10-000000&quot;,&quot;20-000000&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
##   ..$ CES Industry Title: Factor w/ 11 levels &quot;263&quot;,&quot;Construction&quot;,..: 8 2 7 11 5 4 10 3 6 9 ...
##   ..$ Apr               : Factor w/ 10 levels &quot;0&quot;,&quot;12&quot;,&quot;2&quot;,&quot;204&quot;,..: 3 7 1 5 1 8 9 6 10 2 ...
##   ..$ May               : Factor w/ 10 levels &quot;129&quot;,&quot;13&quot;,&quot;2&quot;,..: 3 6 8 5 7 9 4 2 10 8 ...
##   ..$ Jun               : Factor w/ 10 levels &quot;-14&quot;,&quot;0&quot;,&quot;12&quot;,..: 5 6 7 3 2 7 8 1 10 9 ...
##   ..$ Jul               : Factor w/ 10 levels &quot;-1&quot;,&quot;-2&quot;,&quot;-3&quot;,..: 6 5 3 10 1 7 8 10 9 2 ...
##   ..$ Aug               : Factor w/ 9 levels &quot;-19&quot;,&quot;1&quot;,&quot;12&quot;,..: 2 3 9 4 8 9 5 6 7 8 ...
##   ..$ Sep               : Factor w/ 9 levels &quot;-1&quot;,&quot;-12&quot;,&quot;-2&quot;,..: 5 8 5 9 1 1 2 6 4 3 ...
##   ..$ Oct               : Factor w/ 10 levels &quot;-17&quot;,&quot;1&quot;,&quot;12&quot;,..: 2 3 6 5 9 4 10 7 1 8 ...
##   ..$ Nov               : Factor w/ 8 levels &quot;-10&quot;,&quot;-15&quot;,&quot;-22&quot;,..: 4 1 7 5 8 8 6 6 3 4 ...
##   ..$ Dec               : Factor w/ 8 levels &quot;-10&quot;,&quot;-21&quot;,&quot;-3&quot;,..: 4 2 4 7 4 6 1 3 7 5 ...
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;   &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CumulativeTotal&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Factor&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;levels&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;107&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;108&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;12&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;9&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The third option involves explicitly naming the tables to parse.  This process uses the &lt;a href=&quot;http://bradleyboehmke.github.io//2015/12/scraping-html-text.html#specific_nodes&quot;&gt;element selector process described in the text scraping tutorial&lt;/a&gt; to call the table by name. We use &lt;code class=&quot;highlighter-rouge&quot;&gt;getNodeSet()&lt;/code&gt; to select the specified tables of interest. However, a key difference here is rather than copying the table ID names you want to copy the XPath.  You can do this with the following: After you’ve highlighted the table element of interest with the element selector, right click the highlighted element in the developer tools window and select Copy XPath. From here we just use &lt;code class=&quot;highlighter-rouge&quot;&gt;readHTMLTable()&lt;/code&gt; to convert to data frames and we have our desired tables.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RCurl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# parse url
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url_parsed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;htmlParse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getURL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;asText&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# select table nodes of interest
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tableNodes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getNodeSet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url_parsed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;//*[@id=&quot;Table2&quot;]&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;//*[@id=&quot;Table3&quot;]&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# convert HTML tables to data frames
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bls_table2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;readHTMLTable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tableNodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bls_table3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;readHTMLTable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tableNodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bls_table2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##          V1                        V2      V3      V4  V5   V6
## 1 00-000000             Total nonfarm 137,214 137,147  67  (1)
## 2 05-000000             Total private 114,989 114,884 105  0.1
## 3 06-000000           Goods-producing  18,675  18,558 117  0.6
## 4 07-000000         Service-providing 118,539 118,589 -50  (1)
## 5 08-000000 Private service-providing  96,314  96,326 -12  (1)
## 6 10-000000        Mining and logging     868     884 -16 -1.8
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bls_table3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   CES Industry Code CES Industry Title Apr May Jun Jul Aug Sep Oct Nov Dec   CumulativeTotal
## 1         10-000000 Mining and logging   2   2   2   2   1   1   1   1   0                12
## 2         20-000000       Construction  35  37  24  12  12   7  12 -10 -21               108
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;         &lt;span class=&quot;m&quot;&gt;30-000000&lt;/span&gt;      &lt;span class=&quot;n&quot;&gt;Manufacturing&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;-3&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;                &lt;span class=&quot;m&quot;&gt;17&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;A few benefits of &lt;code class=&quot;highlighter-rouge&quot;&gt;XML&lt;/code&gt;’s &lt;code class=&quot;highlighter-rouge&quot;&gt;readHTMLTable&lt;/code&gt; that are routinely handy include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We can specify names for the column headings&lt;/li&gt;
  &lt;li&gt;We can specify the classes for each column&lt;/li&gt;
  &lt;li&gt;We can specify rows to skip&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For instance, if you look at &lt;code class=&quot;highlighter-rouge&quot;&gt;bls_table2&lt;/code&gt; above notice that because of the split column headings on &lt;em&gt;Table 2. Nonfarm employment…&lt;/em&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;readHTMLTable&lt;/code&gt; stripped and replaced the headings with generic names because R does not know which variable names should align with each column. We can correct for this with the following:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;bls_table2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;readHTMLTable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tableNodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; 
                            &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;CES_Code&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Ind_Title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Benchmark&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                            &lt;span class=&quot;s2&quot;&gt;&quot;Estimate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Amt_Diff&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Pct_Diff&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bls_table2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##    CES_Code                 Ind_Title Benchmark Estimate Amt_Diff Pct_Diff
## 1 00-000000             Total nonfarm   137,214  137,147       67      (1)
## 2 05-000000             Total private   114,989  114,884      105      0.1
## 3 06-000000           Goods-producing    18,675   18,558      117      0.6
## 4 07-000000         Service-providing   118,539  118,589      -50      (1)
## 5 08-000000 Private service-providing    96,314   96,326      -12      (1)
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10-000000&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;Mining&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;       &lt;span class=&quot;m&quot;&gt;868&lt;/span&gt;      &lt;span class=&quot;m&quot;&gt;884&lt;/span&gt;      &lt;span class=&quot;m&quot;&gt;-16&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;-1.8&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Also, for &lt;code class=&quot;highlighter-rouge&quot;&gt;bls_table3&lt;/code&gt; note that the net birth/death values parsed have been converted to factor levels.  We can use the &lt;code class=&quot;highlighter-rouge&quot;&gt;colClasses&lt;/code&gt; argument to correct this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bls_table3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## &#39;data.frame&#39;:	11 obs. of  12 variables:
##  $ CES Industry Code : Factor w/ 11 levels &quot;10-000000&quot;,&quot;20-000000&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
##  $ CES Industry Title: Factor w/ 11 levels &quot;263&quot;,&quot;Construction&quot;,..: 8 2 7 11 5 4 10 3 6 9 ...
##  $ Apr               : Factor w/ 10 levels &quot;0&quot;,&quot;12&quot;,&quot;2&quot;,&quot;204&quot;,..: 3 7 1 5 1 8 9 6 10 2 ...
##  $ May               : Factor w/ 10 levels &quot;129&quot;,&quot;13&quot;,&quot;2&quot;,..: 3 6 8 5 7 9 4 2 10 8 ...
##  $ Jun               : Factor w/ 10 levels &quot;-14&quot;,&quot;0&quot;,&quot;12&quot;,..: 5 6 7 3 2 7 8 1 10 9 ...
##  $ Jul               : Factor w/ 10 levels &quot;-1&quot;,&quot;-2&quot;,&quot;-3&quot;,..: 6 5 3 10 1 7 8 10 9 2 ...
##  $ Aug               : Factor w/ 9 levels &quot;-19&quot;,&quot;1&quot;,&quot;12&quot;,..: 2 3 9 4 8 9 5 6 7 8 ...
##  $ Sep               : Factor w/ 9 levels &quot;-1&quot;,&quot;-12&quot;,&quot;-2&quot;,..: 5 8 5 9 1 1 2 6 4 3 ...
##  $ Oct               : Factor w/ 10 levels &quot;-17&quot;,&quot;1&quot;,&quot;12&quot;,..: 2 3 6 5 9 4 10 7 1 8 ...
##  $ Nov               : Factor w/ 8 levels &quot;-10&quot;,&quot;-15&quot;,&quot;-22&quot;,..: 4 1 7 5 8 8 6 6 3 4 ...
##  $ Dec               : Factor w/ 8 levels &quot;-10&quot;,&quot;-21&quot;,&quot;-3&quot;,..: 4 2 4 7 4 6 1 3 7 5 ...
##  $ CumulativeTotal   : Factor w/ 10 levels &quot;107&quot;,&quot;108&quot;,&quot;12&quot;,..: 3 2 6 4 5 10 7 1 8 9 ...
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bls_table3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;readHTMLTable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tableNodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; 
                            &lt;span class=&quot;n&quot;&gt;colClasses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;character&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;character&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                           &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;integer&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bls_table3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## &#39;data.frame&#39;:	11 obs. of  12 variables:
##  $ CES Industry Code : Factor w/ 11 levels &quot;10-000000&quot;,&quot;20-000000&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
##  $ CES Industry Title: Factor w/ 11 levels &quot;263&quot;,&quot;Construction&quot;,..: 8 2 7 11 5 4 10 3 6 9 ...
##  $ Apr               : int  2 35 0 21 0 8 81 22 82 12 ...
##  $ May               : int  2 37 6 24 5 8 22 13 81 6 ...
##  $ Jun               : int  2 24 4 12 0 4 5 -14 86 6 ...
##  $ Jul               : int  2 12 -3 7 -1 3 35 7 62 -2 ...
##  $ Aug               : int  1 12 4 14 3 4 19 21 23 3 ...
##  $ Sep               : int  1 7 1 9 -1 -1 -12 12 -33 -2 ...
##  $ Oct               : int  1 12 3 28 6 16 76 35 -17 4 ...
##  $ Nov               : int  1 -10 2 10 3 3 14 14 -22 1 ...
##  $ Dec               : int  0 -21 0 4 0 10 -10 -3 4 1 ...
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CumulativeTotal&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;12&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;108&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;17&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;129&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;55&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;230&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;107&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;266&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;29&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;Between &lt;code class=&quot;highlighter-rouge&quot;&gt;rvest&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;XML&lt;/code&gt;, scraping HTML tables is relatively easy once you get fluent with the syntax and the available options.  This post covers just the basics of both these packages to get you moving forward with scraping tables.&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 21 Dec 2015 00:00:00 -0500</pubDate>
        <link>http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2015/12/scraping-html-tables.html</link>
        <guid isPermaLink="true">http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2015/12/scraping-html-tables.html</guid>
        
        <category>r</category>
        
        <category>rvest</category>
        
        <category>xml</category>
        
        <category>web-scraping</category>
        
        
        <category>programming</category>
        
      </item>
    
      <item>
        <title>Scraping HTML Text</title>
        <description>&lt;style type=&quot;text/css&quot;&gt; 
&lt;!-- 
        .indented { 
                padding-left: 25pt; 
                padding-right: 50pt; 
                } 
--&gt; 
&lt;/style&gt;

&lt;p&gt;&lt;a href=&quot;http://bradleyboehmke.github.io/2015/12/scraping-html-text.html&quot;&gt;&lt;img src=&quot;http://d1u2s20mo6at4b.cloudfront.net/wp-content/uploads/HTML.jpg&quot; alt=&quot;Scraping HTML Text&quot; style=&quot;float:left; margin:2px 8px 0px 0px; width: 17%; height: 17%;&quot; /&gt;&lt;/a&gt;
Vast amount of information exists across the interminable webpages that exist online.  Much of this information are considered “unstructured” texts since they don’t come in a neatly packaged speadsheet. Fortunately, HTML websites are organized documents which means these texts are actually structured within underlying HTML code elements…we just need to figure out how to extract it! This post covers the basics of scraping text from online sources.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tldr&quot;&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;Short on time? Here’s the gist. Throughout this post I illustrate how to use the &lt;code class=&quot;highlighter-rouge&quot;&gt;rvest&lt;/code&gt; package to extract different text components of webpages by dissecting the &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_scraping&quot;&gt;Wikipedia page on web scraping&lt;/a&gt;. As I foray I cover:&lt;/p&gt;

&lt;p class=&quot;indented&quot;&gt;
        &lt;a href=&quot;#html_nodes&quot;&gt;&amp;#9312;&lt;/a&gt; Basic knowledge of HTML element components you&#39;ll need to scrape with rvest
        &lt;br /&gt;
        &lt;a href=&quot;#scraping_nodes&quot;&gt;&amp;#9313;&lt;/a&gt; How to extract text from the common HTML nodes in a webpage
        &lt;br /&gt;
        &lt;a href=&quot;#specific_nodes&quot;&gt;&amp;#9314;&lt;/a&gt; How to extract text from specific HTML nodes of interest
        &lt;br /&gt;
        &lt;a href=&quot;#cleaning&quot;&gt;&amp;#9315;&lt;/a&gt; Some of the common text cleaning that is required post-scraping
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;html_nodes&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;html-nodes&quot;&gt;① HTML Nodes&lt;/h2&gt;
&lt;p&gt;However, its important to first cover one of the basic components of HTML elements as we will leverage this information to pull desired information. I offer only enough insight required to begin scraping; I highly recommend &lt;a href=&quot;http://www.amazon.com/XML-Web-Technologies-Data-Sciences/dp/1461478995&quot;&gt;&lt;em&gt;XML and Web Technologies for Data Sciences with R&lt;/em&gt;&lt;/a&gt; and &lt;a href=&quot;http://www.amazon.com/Automated-Data-Collection-Practical-Scraping/dp/111883481X/ref=pd_sim_14_1?ie=UTF8&amp;amp;dpID=51Tm7FHxWBL&amp;amp;dpSrc=sims&amp;amp;preST=_AC_UL160_SR108%2C160_&amp;amp;refRID=1VJ1GQEY0VCPZW7VKANX&quot;&gt;&lt;em&gt;Automated Data Collection with R&lt;/em&gt;&lt;/a&gt; to learn more about HTML and XML element structures.&lt;/p&gt;

&lt;p&gt;HTML elements are written with a start tag, an end tag, and with the content in between: &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;tagname&amp;gt;content&amp;lt;/tagname&amp;gt;&lt;/code&gt;. The tags which typically contain the textual content we wish to scrape, and the tags we will leverage in the next two sections, include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;h1&amp;gt;&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;h2&amp;gt;&lt;/code&gt;,…,&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;h6&amp;gt;&lt;/code&gt;: Largest heading, second largest heading, etc.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt;: Paragraph elements&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;ul&amp;gt;&lt;/code&gt;: Unordered bulleted list&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;ol&amp;gt;&lt;/code&gt;: Ordered list&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;li&amp;gt;&lt;/code&gt;: Individual List item&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;div&amp;gt;&lt;/code&gt;: Division or section&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;table&amp;gt;&lt;/code&gt;: Table&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, text in paragraph form that you see online is wrapped with the HTML paragraph tag &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt; as in:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;This&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;paragraph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;represents&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typical&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;paragraph&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HTML&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;form&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;It is through these tags that we can start to extract textual components (also referred to as nodes) of HTML webpages.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;scraping_nodes&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;scraping-html-nodes&quot;&gt;② Scraping HTML Nodes&lt;/h2&gt;
&lt;p&gt;To scrape online text we’ll make use of the relatively newer &lt;a href=&quot;https://cran.r-project.org/web/packages/rvest/index.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rvest&lt;/code&gt;&lt;/a&gt; package. &lt;code class=&quot;highlighter-rouge&quot;&gt;rvest&lt;/code&gt; was created by the RStudio team inspired by libraries such as &lt;a href=&quot;http://www.crummy.com/software/BeautifulSoup/&quot;&gt;beautiful soup&lt;/a&gt; which has greatly simplified web scraping. &lt;code class=&quot;highlighter-rouge&quot;&gt;rvest&lt;/code&gt; provides multiple functionalities; however, in this section we will focus only on extracting HTML text with &lt;code class=&quot;highlighter-rouge&quot;&gt;rvest&lt;/code&gt;. Its important to note that &lt;code class=&quot;highlighter-rouge&quot;&gt;rvest&lt;/code&gt; makes use of of the pipe operator (&lt;code class=&quot;highlighter-rouge&quot;&gt;%&amp;gt;%&lt;/code&gt;) developed through the &lt;a href=&quot;https://cran.r-project.org/web/packages/magrittr/index.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;magrittr&lt;/code&gt; package&lt;/a&gt;. If you are not familiar with the functionality of &lt;code class=&quot;highlighter-rouge&quot;&gt;%&amp;gt;%&lt;/code&gt; I recommend you jump to the tutorial on &lt;a href=&quot;#pipe&quot;&gt;Simplifying Your Code with &lt;code class=&quot;highlighter-rouge&quot;&gt;%&amp;gt;%&lt;/code&gt;&lt;/a&gt; so that you have a better understanding of what’s going on with the code.&lt;/p&gt;

&lt;p&gt;To extract text from a webpage of interest, we specify what HTML elements we want to select by using &lt;code class=&quot;highlighter-rouge&quot;&gt;html_nodes()&lt;/code&gt;.  For instance, if we want to scrape the primary heading for the &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_scraping&quot;&gt;Web Scraping Wikipedia webpage&lt;/a&gt; we simply identify the &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;h1&amp;gt;&lt;/code&gt; node as the node we want to select.  &lt;code class=&quot;highlighter-rouge&quot;&gt;html_nodes()&lt;/code&gt; will identify all &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;h1&amp;gt;&lt;/code&gt; nodes on the webpage and return the HTML element.  In our example we see there is only one &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;h1&amp;gt;&lt;/code&gt; node on this webpage.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rvest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://en.wikipedia.org/wiki/Web_scraping&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;h1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## {xml_nodeset (1)}
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;firstHeading&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;firstHeading&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;en&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Web&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scraping&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To extract only the heading text for this &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;h1&amp;gt;&lt;/code&gt; node, and not include all the HTML syntax we use &lt;code class=&quot;highlighter-rouge&quot;&gt;html_text()&lt;/code&gt; which returns the heading text we see at the top of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_scraping&quot;&gt;Web Scraping Wikipedia page&lt;/a&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;h1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Web scraping&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;If we want to identify all the second level headings on the webpage we follow the same process but instead select the &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;h2&amp;gt;&lt;/code&gt; nodes.  In this example we see there are 10 second level headings on the &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_scraping&quot;&gt;Web Scraping Wikipedia page&lt;/a&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;h2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##  [1] &quot;Contents&quot;                             
##  [2] &quot;Techniques[edit]&quot;                     
##  [3] &quot;Legal issues[edit]&quot;                   
##  [4] &quot;Notable tools[edit]&quot;                  
##  [5] &quot;See also[edit]&quot;                       
##  [6] &quot;Technical measures to stop bots[edit]&quot;
##  [7] &quot;Articles[edit]&quot;                       
##  [8] &quot;References[edit]&quot;                     
##  [9] &quot;See also[edit]&quot;                       
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Navigation menu&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Next, we can move on to extracting much of the text on this webpage which is in paragraph form.  We can follow the same process illustrated above but instead we’ll select all &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt;  nodes.  This selects the 17 paragraph elements from the web page; which we can examine by subsetting the list &lt;code class=&quot;highlighter-rouge&quot;&gt;p_nodes&lt;/code&gt; to see the first line of each paragraph along with the HTML syntax. Just as before, to extract the text from these nodes and coerce them to a character string we simply apply &lt;code class=&quot;highlighter-rouge&quot;&gt;html_text()&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p_nodes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;p&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] 17
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## {xml_nodeset (6)}
## [1] &amp;lt;p&amp;gt;&amp;lt;b&amp;gt;Web scraping&amp;lt;/b&amp;gt; (&amp;lt;b&amp;gt;web harvesting&amp;lt;/b&amp;gt; or &amp;lt;b&amp;gt;web data extract ...
## [2] &amp;lt;p&amp;gt;Web scraping is closely related to &amp;lt;a href=&quot;/wiki/Web_indexing&quot; t ...
## [3] &amp;lt;p/&amp;gt;
## [4] &amp;lt;p/&amp;gt;
## [5] &amp;lt;p&amp;gt;Web scraping is the process of automatically collecting informati ...
## [6] &amp;lt;p&amp;gt;Web scraping may be against the &amp;lt;a href=&quot;/wiki/Terms_of_use&quot; titl ...
&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;p_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;p&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;p_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Web scraping (web harvesting or web data extraction) is a computer software technique of extracting information from websites. Usually, such software programs simulate human exploration of the World Wide Web by either implementing low-level Hypertext Transfer Protocol (HTTP), or embedding a fully-fledged web browser, such as Mozilla Firefox.&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Not too bad; however, we may not have captured all the text that we were hoping for.  Since we extracted text for all &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt; nodes, we collected all identified paragraph text; however, this does not capture the text in the bulleted lists.  For example, when you look at the &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_scraping&quot;&gt;Web Scraping Wikipedia page&lt;/a&gt; you will notice a significant amount of text in bulleted list format following the third paragraph under the &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Web_scraping#Techniques&quot;&gt;Techniques&lt;/a&gt;&lt;/strong&gt; heading.  If we look at our data we’ll see that that the text in this list format are not capture between the two paragraphs:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Error in eval(expr, envir, enclos): object &#39;p_text&#39; not found&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Error in eval(expr, envir, enclos): object &#39;p_text&#39; not found&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This is because the text in this list format are contained in &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;ul&amp;gt;&lt;/code&gt; nodes. To capture the text in lists, we can use the same steps as above but we select specific nodes which represent HTML lists components. We can approach extracting list text two ways.&lt;/p&gt;

&lt;p&gt;First, we can pull all list elements (&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;ul&amp;gt;&lt;/code&gt;).  When scraping all &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;ul&amp;gt;&lt;/code&gt; text, the resulting data structure will be a character string vector with each element representing a single list consisting of all list items in that list.  In our running example there are 21 list elements as shown in the example that follows.  You can see the first list scraped is the table of contents and the second list scraped is the list in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_scraping#Techniques&quot;&gt;Techniques&lt;/a&gt; section.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ul_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ul&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ul_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] 21
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ul_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot;\n1 Techniques\n2 Legal issues\n3 Notable tools\n4 See also\n5 Technical measures to stop bots\n6 Articles\n7 References\n8 See also\n&quot;
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# read the first 200 characters of the second list
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ul_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;\nHuman copy-and-paste: Sometimes even the best web-scraping technology cannot replace a human’s manual examination and copy-and-paste, and sometimes this may be the only workable solution when the web&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;An alternative approach is to pull all &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;li&amp;gt;&lt;/code&gt; nodes.  This will pull the text contained in each list item for all the lists.  In our running example there’s 146 list items that we can extract from this Wikipedia page.  The first eight list items are the list of contents we see towards the top of the page. List items 9-17 are the list elements contained in the “&lt;a href=&quot;https://en.wikipedia.org/wiki/Web_scraping#Techniques&quot;&gt;Techniques&lt;/a&gt;” section, list items 18-44 are the items listed under the “&lt;a href=&quot;https://en.wikipedia.org/wiki/Web_scraping#Notable_tools&quot;&gt;Notable Tools&lt;/a&gt;” section, and so on.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;li_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;li&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;li_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] 147
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;li_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot;1 Techniques&quot;                      &quot;2 Legal issues&quot;                   
## [3] &quot;3 Notable tools&quot;                   &quot;4 See also&quot;                       
## [5] &quot;5 Technical measures to stop bots&quot; &quot;6 Articles&quot;                       
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;7 References&quot;&lt;/span&gt;                      &lt;span class=&quot;s2&quot;&gt;&quot;8 See also&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;At this point we may believe we have all the text desired and proceed with joining the paragraph (&lt;code class=&quot;highlighter-rouge&quot;&gt;p_text&lt;/code&gt;) and list (&lt;code class=&quot;highlighter-rouge&quot;&gt;ul_text&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;li_text&lt;/code&gt;) character strings and then perform the desired textual analysis.  However, we may now have captured &lt;em&gt;more&lt;/em&gt; text than we were hoping for.  For example, by scraping all lists we are also capturing the listed links in the left margin of the webpage. If we look at the 104-136 list items that we scraped, we’ll see that these texts correspond to the left margin text.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;li_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;104&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;136&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##  [1] &quot;Main page&quot;           &quot;Contents&quot;            &quot;Featured content&quot;   
##  [4] &quot;Current events&quot;      &quot;Random article&quot;      &quot;Donate to Wikipedia&quot;
##  [7] &quot;Wikipedia store&quot;     &quot;Help&quot;                &quot;About Wikipedia&quot;    
## [10] &quot;Community portal&quot;    &quot;Recent changes&quot;      &quot;Contact page&quot;       
## [13] &quot;What links here&quot;     &quot;Related changes&quot;     &quot;Upload file&quot;        
## [16] &quot;Special pages&quot;       &quot;Permanent link&quot;      &quot;Page information&quot;   
## [19] &quot;Wikidata item&quot;       &quot;Cite this page&quot;      &quot;Create a book&quot;      
## [22] &quot;Download as PDF&quot;     &quot;Printable version&quot;   &quot;Català&quot;             
## [25] &quot;Deutsch&quot;             &quot;Español&quot;             &quot;Français&quot;           
## [28] &quot;Íslenska&quot;            &quot;Italiano&quot;            &quot;Latviešu&quot;           
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;31&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Nederlands&quot;&lt;/span&gt;          &lt;span class=&quot;s2&quot;&gt;&quot;日本語&quot;&lt;/span&gt;              &lt;span class=&quot;s2&quot;&gt;&quot;Српски / srpski&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;If we desire to scrape every piece of text on the webpage than this won’t be of concern.  In fact, if we want to scrape all the text regardless of the content they represent there is an easier approach.  We can capture all the content to include text in paragraph (&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt;), lists (&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;ul&amp;gt;&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;ol&amp;gt;&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;li&amp;gt;&lt;/code&gt;), and even data in tables (&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;table&amp;gt;&lt;/code&gt;) by using &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;div&amp;gt;&lt;/code&gt;.  This is because these other elements are usually a subsidiary of an HTML division or section so pulling all &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;div&amp;gt;&lt;/code&gt; nodes will extract all text contained in that division or section regardless if it is also contained in a paragraph or list.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;all_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;div&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;html_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;specific_nodes&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;scraping-specific-html-nodes&quot;&gt;③ Scraping Specific HTML Nodes&lt;/h2&gt;
&lt;p&gt;However, if we are concerned only with specific content on the webpage then we need to make our HTML node selection process a little more focused.  To do this we, we can use our browser’s developer tools to examine the webpage we are scraping and get more details on specific nodes of interest.  If you are using Chrome or Firefox you can open the developer tools by clicking F12 (Cmd + Opt + I for Mac) or for Safari you would use Command-Option-I. An additional option which is recommended by Hadley Wickham is to use &lt;a href=&quot;http://selectorgadget.com/&quot;&gt;selectorgadget.com&lt;/a&gt;, a Chrome extension, to help identify the web page elements you need&lt;sup&gt;&lt;a href=&quot;#fn1&quot; id=&quot;ref1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Once the developers tools are opened your primary concern is with the element selector. This is located in the top lefthand corner of the developers tools window.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://bradleyboehmke.github.io/figure/source/scraping-html-text/2015-12-30-scraping-html-text/element_selector.jpg&quot; alt=&quot;Element Selector&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Once you’ve selected the element selector you can now scroll over the elements of the webpage which will cause each element you scroll over to be highlighted.  Once you’ve identified the element you want to focus on, select it. This will cause the element to be identified in the developer tools window. For example, if I am only interested in the main body of the Web Scraping content on the Wikipedia page then I would select the element that highlights the entire center component of the webpage.  This highlights the corresponding element &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;div id=&quot;bodyContent&quot; class=&quot;mw-body-content&quot;&amp;gt;&lt;/code&gt; in the developer tools window as the following illustrates.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://bradleyboehmke.github.io/figure/source/scraping-html-text/2015-12-30-scraping-html-text/body_content_selected.png&quot; alt=&quot;Body Content Selected&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I can now use this information to select and scrape all the text from this specific &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;div&amp;gt;&lt;/code&gt; node by calling the ID name (“#mw-content-text”) in &lt;code class=&quot;highlighter-rouge&quot;&gt;html_nodes()&lt;/code&gt;&lt;sup&gt;&lt;a href=&quot;#fn2&quot; id=&quot;ref2&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.  As you can see below, the text that is scraped begins with the first line in the main body of the Web Scraping content and ends with the text in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_scraping#See_also_2&quot;&gt;See Also&lt;/a&gt; section which is the last bit of text directly pertaining to Web Scraping on the webpage. Explicitly, we have pulled the specific text associated with the web content we desire.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;body_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#mw-content-text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;html_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# read the first 207 characters
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;207&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot;Web scraping (web harvesting or web data extraction) is a computer software technique of extracting information from websites. Usually, such software programs simulate human exploration of the World Wide Web&quot;
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# read the last 73 characters
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nchar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-73&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nchar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;See also[edit]\n\nData scraping\nData wrangling\nKnowledge extraction\n\n\n\n\n\n\n\n\n&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Using the developer tools approach allows us to be as specific as we desire.  We can identify the class name for a specific HTML element and scrape the text for only that node rather than all the other elements with similar tags. This allows us to scrape the main body of content as we just illustrated or we can also identify specific headings, paragraphs, lists, and list components if we desire to scrape only these specific pieces of text:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Scraping a specific heading
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#Techniques&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;html_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot;Techniques&quot;
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Scraping a specific paragraph
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#mw-content-text &amp;gt; p:nth-child(20)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;html_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot;In Australia, the Spam Act 2003 outlaws some forms of web harvesting, although this only applies to email addresses.[20][21]&quot;
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Scraping a specific list
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#mw-content-text &amp;gt; div:nth-child(22)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;html_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot;\n\nApache Camel\nArchive.is\nAutomation Anywhere\nConvertigo\ncURL\nData Toolbar\nDiffbot\nFirebug\nGreasemonkey\nHeritrix\nHtmlUnit\nHTTrack\niMacros\nImport.io\nJaxer\nNode.js\nnokogiri\nPhantomJS\nScraperWiki\nScrapy\nSelenium\nSimpleTest\nwatir\nWget\nWireshark\nWSO2 Mashup Server\nYahoo! Query Language (YQL)\n\n&quot;
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Scraping a specific reference list item
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#cite_note-22&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;html_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;^ \&quot;Web Scraping: Everything You Wanted to Know (but were afraid to ask)\&quot;. Distil Networks. 2015-07-22. Retrieved 2015-11-04. &quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;cleaning&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;cleaning-up&quot;&gt;④ Cleaning up&lt;/h2&gt;
&lt;p&gt;With any webscraping activity, especially involving text, there is likely to be some clean-up involved. For example, in the previous example we saw that we can specifically pull the list of &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_scraping#Notable_tools&quot;&gt;&lt;strong&gt;Notable Tools&lt;/strong&gt;&lt;/a&gt;; however, you can see that in between each list item rather than a space there contains one or more &lt;code class=&quot;highlighter-rouge&quot;&gt;\n&lt;/code&gt; which is used in HTML to specify a new line. We can clean this up quickly with a little &lt;a href=&quot;http://bradleyboehmke.github.io/tutorials/string_manipulation&quot;&gt;character string manipulation&lt;/a&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;magrittr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#mw-content-text &amp;gt; div:nth-child(22)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;html_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot;\n\nApache Camel\nArchive.is\nAutomation Anywhere\nConvertigo\ncURL\nData Toolbar\nDiffbot\nFirebug\nGreasemonkey\nHeritrix\nHtmlUnit\nHTTrack\niMacros\nImport.io\nJaxer\nNode.js\nnokogiri\nPhantomJS\nScraperWiki\nScrapy\nSelenium\nSimpleTest\nwatir\nWget\nWireshark\nWSO2 Mashup Server\nYahoo! Query Language (YQL)\n\n&quot;
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scraping_wiki&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#mw-content-text &amp;gt; div:nth-child(22)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;html_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;strsplit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;\n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##  [1] &quot;Apache Camel&quot;                &quot;Archive.is&quot;                 
##  [3] &quot;Automation Anywhere&quot;         &quot;Convertigo&quot;                 
##  [5] &quot;cURL&quot;                        &quot;Data Toolbar&quot;               
##  [7] &quot;Diffbot&quot;                     &quot;Firebug&quot;                    
##  [9] &quot;Greasemonkey&quot;                &quot;Heritrix&quot;                   
## [11] &quot;HtmlUnit&quot;                    &quot;HTTrack&quot;                    
## [13] &quot;iMacros&quot;                     &quot;Import.io&quot;                  
## [15] &quot;Jaxer&quot;                       &quot;Node.js&quot;                    
## [17] &quot;nokogiri&quot;                    &quot;PhantomJS&quot;                  
## [19] &quot;ScraperWiki&quot;                 &quot;Scrapy&quot;                     
## [21] &quot;Selenium&quot;                    &quot;SimpleTest&quot;                 
## [23] &quot;watir&quot;                       &quot;Wget&quot;                       
## [25] &quot;Wireshark&quot;                   &quot;WSO2 Mashup Server&quot;         
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Yahoo! Query Language (YQL)&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Similarly, as we saw in our example above with scraping the main body content (&lt;code class=&quot;highlighter-rouge&quot;&gt;body_text&lt;/code&gt;), there are extra characters (i.e. &lt;code class=&quot;highlighter-rouge&quot;&gt;\n&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt;) in the text that we may not want.  Using a &lt;a href=&quot;http://bradleyboehmke.github.io/tutorials/regex&quot;&gt;little regex&lt;/a&gt; we can clean this up so that our character string consists of only text that we see on the screen and no additional HTML code embedded throughout the text.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stringr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# read the last 700 characters
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nchar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nchar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot; 2010). \&quot;Intellectual Property: Website Terms of Use\&quot;. Issue 26: June 2010. LK Shields Solicitors Update. p. 03. Retrieved 2012-04-19. \n^ National Office for the Information Economy (February 2004). \&quot;Spam Act 2003: An overview for business\&quot; (PDF). Australian Communications Authority. p. 6. Retrieved 2009-03-09. \n^ National Office for the Information Economy (February 2004). \&quot;Spam Act 2003: A practical guide for business\&quot; (PDF). Australian Communications Authority. p. 20. Retrieved 2009-03-09. \n^ \&quot;Web Scraping: Everything You Wanted to Know (but were afraid to ask)\&quot;. Distil Networks. 2015-07-22. Retrieved 2015-11-04. \n\n\nSee also[edit]\n\nData scraping\nData wrangling\nKnowledge extraction\n\n\n\n\n\n\n\n\n&quot;
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# clean up text
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;str_replace_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;\n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replacement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;str_replace_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;[\\^]&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replacement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;str_replace_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;\&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replacement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;str_replace_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;\\s+&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replacement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;str_trim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;side&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;both&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nchar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nchar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;012-04-19. National Office for the Information Economy (February 2004). Spam Act 2003: An overview for business (PDF). Australian Communications Authority. p. 6. Retrieved 2009-03-09. National Office for the Information Economy (February 2004). Spam Act 2003: A practical guide for business (PDF). Australian Communications Authority. p. 20. Retrieved 2009-03-09. Web Scraping: Everything You Wanted to Know (but were afraid to ask) . Distil Networks. 2015-07-22. Retrieved 2015-11-04. See also[edit] Data scraping Data wrangling Knowledge extraction&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping up&lt;/h2&gt;
&lt;p&gt;So there we have it, text scraping in a nutshell.  Although not all encompassing, this post covered the basics of scraping text from HTML documents. Whether you want to scrape text from all common text-containing nodes such as &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;div&amp;gt;&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;ul&amp;gt;&lt;/code&gt; and the like or you want to scrape from a specific node using the specific ID, this post provides you the basic fundamentals of using &lt;code class=&quot;highlighter-rouge&quot;&gt;rvest&lt;/code&gt; to scrape the text you need. Now go forth and scrape!&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn1&quot;&gt;1. You can learn more about selectors at &lt;a href=&quot;http://flukeout.github.io/&quot;&gt;flukeout.github.io&lt;/a&gt;&lt;a href=&quot;#ref1&quot; title=&quot;Jump back to footnote 1 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;

&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn2&quot;&gt;2. You can simply assess the name of the ID in the highlighted element or you can  right click the highlighted element in the developer tools window and select &lt;em&gt;Copy selector&lt;/em&gt;.  You can then paste directly into `html_nodes()` as it will paste the exact ID name that you need for that element.&lt;a href=&quot;#ref2&quot; title=&quot;Jump back to footnote 2 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;


&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 14 Dec 2015 00:00:00 -0500</pubDate>
        <link>http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2015/12/scraping-html-text.html</link>
        <guid isPermaLink="true">http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2015/12/scraping-html-text.html</guid>
        
        <category>r</category>
        
        <category>rvest</category>
        
        <category>web-scraping</category>
        
        
        <category>programming</category>
        
      </item>
    
      <item>
        <title>Scraping Tabular and Excel Files Stored Online</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://bradleyboehmke.github.io/2015/12/scraping-tabular-and-excel-files-stored-online.html&quot;&gt;&lt;img src=&quot;http://www.rcsb.org/pdb/general_information/releases/1504_images/icons/BatchDownloadTool.png&quot; alt=&quot;Importing Online Data&quot; style=&quot;float:left; margin:0px 8px 0px 0px; width: 17%; height: 17%;&quot; /&gt;&lt;/a&gt;
The most basic form of getting data from online is to import tabular (i.e. .txt, .csv) or Excel files that are being hosted online. This is often not considered &lt;em&gt;web scraping&lt;/em&gt;&lt;sup&gt;&lt;a href=&quot;#fn1&quot; id=&quot;ref1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;; however, I think its a good place to start introducing the user to interacting with the web for obtaining data. In this post I cover some of the common approaches applied for importing spreadsheet files via R.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tldr&quot;&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;Not enough time to peruse this whole post? That’s fine; here’s what I cover in a nutshell. Feel free to jump to specific sections.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#csv&quot;&gt;CSV&lt;/a&gt;: Downloading .csv files is no different than importing locally managed .csv files&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#excel&quot;&gt;Excel&lt;/a&gt;: Use &lt;code class=&quot;highlighter-rouge&quot;&gt;gdata&lt;/code&gt; to easily download online Excel files&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#zip&quot;&gt;ZIP&lt;/a&gt;: You can download and extract .zip files in a conventional manner; however, I also provide an efficient approach to temporarily download the .zip file, extract the desired data, and then discard the .zip file.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#multiple&quot;&gt;Multiple files&lt;/a&gt;: Need to download multiple files from a website? Snag the HTML links with &lt;code class=&quot;highlighter-rouge&quot;&gt;XML&lt;/code&gt;, perform a little string manipulation, and download with a &lt;code class=&quot;highlighter-rouge&quot;&gt;for&lt;/code&gt; loop.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;csv&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;csv-files&quot;&gt;CSV Files&lt;/h2&gt;
&lt;p&gt;Hosting tabular-formatted data online is a garden-variety practice for many organizations, especially for the many types of government data available online.  A quick perusal of &lt;a href=&quot;https://www.data.gov/&quot;&gt;Data.gov&lt;/a&gt; illustrates nearly 188,510 examples. In fact, we can provide our first example of importing online tabular data by downloading the Data.gov CSV file that lists all the federal agencies that supply data to Data.gov.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# the url for the online CSV
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;https://www.data.gov/media/federal-agency-participation.csv&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# use read.csv to import
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_gov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stringsAsFactors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# for brevity I only display first 6 rows
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_gov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##                                      Agency.Name Datasets Last.Entry
## 1           Commodity Futures Trading Commission        3 01/12/2014
## 2           Consumer Financial Protection Bureau        2 09/26/2015
## 3           Consumer Financial Protection Bureau        2 09/26/2015
## 4 Corporation for National and Community Service        3 01/12/2014
## 5 Court Services and Offender Supervision Agency        1 01/12/2014
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;                      &lt;span class=&quot;n&quot;&gt;Department&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Agriculture&lt;/span&gt;      &lt;span class=&quot;m&quot;&gt;698&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;01&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2015&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;excel&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;excel-files&quot;&gt;Excel Files&lt;/h2&gt;
&lt;p&gt;Downloading Excel spreadsheets hosted online can be performed just as easily.  Recall that there is not a base R function for importing Excel data; however, &lt;a href=&quot;http://bradleyboehmke.github.io//tutorials/importing_data#excel&quot;&gt;several packages exist&lt;/a&gt; to handle this capability.  One package that works smoothly with pulling Excel data from URLs is &lt;a href=&quot;https://cran.r-project.org/web/packages/gdata/index.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gdata&lt;/code&gt;&lt;/a&gt;.  With &lt;code class=&quot;highlighter-rouge&quot;&gt;gdata&lt;/code&gt; we can use &lt;code class=&quot;highlighter-rouge&quot;&gt;read.xls()&lt;/code&gt; to download this &lt;a href=&quot;http://catalog.data.gov/dataset/fair-market-rents-for-the-section-8-housing-assistance-payments-program&quot;&gt;Fair Market Rents for Section 8 Housing&lt;/a&gt; Excel file from the given url.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# the url for the online Excel file
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;http://www.huduser.org/portal/datasets/fmr/fmr2015f/FY2015F_4050_Final.xls&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# use read.xls to import
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rents&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.xls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;rents&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##    fips2000  fips2010 fmr2 fmr0 fmr1 fmr3 fmr4 county State CouSub
## 1 100199999 100199999  788  628  663 1084 1288      1     1  99999
## 2 100399999 100399999  762  494  643 1123 1318      3     1  99999
## 3 100599999 100599999  670  492  495  834  895      5     1  99999
## 4 100799999 100799999  773  545  652 1015 1142      7     1  99999
## 5 100999999 100999999  773  545  652 1015 1142      9     1  99999
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;101199999&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;101199999&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;599&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;481&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;505&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;791&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1061&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;99999&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Note that many of the arguments covered in the &lt;a href=&quot;http://bradleyboehmke.github.io/tutorials/importing_data#excel&quot;&gt;Importing Data tutorial&lt;/a&gt; (i.e. specifying sheets to read from, skipping lines) also apply to &lt;code class=&quot;highlighter-rouge&quot;&gt;read.xls()&lt;/code&gt;. In addition, &lt;code class=&quot;highlighter-rouge&quot;&gt;gdata&lt;/code&gt; provides some useful functions (&lt;code class=&quot;highlighter-rouge&quot;&gt;sheetCount()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;sheetNames()&lt;/code&gt;) for identifying if multiple sheets exist prior to downloading.&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;zip&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;zip-files&quot;&gt;ZIP Files&lt;/h2&gt;
&lt;p&gt;Another common form of file storage is using zip files.  For instance, the &lt;a href=&quot;http://www.bls.gov/home.htm&quot;&gt;Bureau of Labor Statistics&lt;/a&gt; (BLS) stores their &lt;a href=&quot;http://www.bls.gov/cex/pumdhome.htm&quot;&gt;public-use microdata&lt;/a&gt; for the &lt;a href=&quot;http://www.bls.gov/cex/home.htm&quot;&gt;Consumer Expenditure Survey&lt;/a&gt; in .zip files.  We can use &lt;code class=&quot;highlighter-rouge&quot;&gt;download.file()&lt;/code&gt; to download the file to your working directory and then work with this data as desired.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;http://www.bls.gov/cex/pumd/data/comma/diary14.zip&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# download .zip file and unzip contents
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;download.file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;dataset.zip&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;wb&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;unzip&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;dataset.zip&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;./&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# assess the files contained in the .zip file which
# unzips as a folder named &quot;diary14&quot;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list.files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;diary14&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##  [1] &quot;dtbd141.csv&quot; &quot;dtbd142.csv&quot; &quot;dtbd143.csv&quot; &quot;dtbd144.csv&quot; &quot;dtid141.csv&quot;
##  [6] &quot;dtid142.csv&quot; &quot;dtid143.csv&quot; &quot;dtid144.csv&quot; &quot;expd141.csv&quot; &quot;expd142.csv&quot;
## [11] &quot;expd143.csv&quot; &quot;expd144.csv&quot; &quot;fmld141.csv&quot; &quot;fmld142.csv&quot; &quot;fmld143.csv&quot;
## [16] &quot;fmld144.csv&quot; &quot;memd141.csv&quot; &quot;memd142.csv&quot; &quot;memd143.csv&quot; &quot;memd144.csv&quot;
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# alternatively, if we know the file we want prior to unzipping
# we can extract the file without unzipping using unz():
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zip_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;dataset.zip&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;diary14/expd141.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;zip_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##     NEWID ALLOC COST GIFT PUB_FLAG    UCC EXPNSQDY EXPN_QDY EXPNWKDY   EXPN_KDY
## 1 2825371     0 6.26    2        2 190112        1        D        3        D
## 2 2825371     0 1.20    2        2 190322        1        D        3        D
## 3 2825381     0 0.98    2        2  20510        3        D        2        D
## 4 2825381     0 0.98    2        2  20510        3        D        2        D
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2825381&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2.50&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;        &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;20510&lt;/span&gt;        &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;        &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The .zip archive file format is meant to compress files and are typically used on files of significant size.  For instance, the Consumer Expenditure Survey data we downloaded in the previous example is over 10MB.  Obviously there may be times in which we want to get specific data in the .zip file to analyze but not always permanently store the entire .zip file contents. In these instances we can use the following &lt;a href=&quot;http://stackoverflow.com/questions/3053833/using-r-to-download-zipped-data-file-extract-and-import-data&quot;&gt;process&lt;/a&gt; proposed by &lt;a href=&quot;https://twitter.com/eddelbuettel&quot;&gt;Dirk Eddelbuettel&lt;/a&gt; to temporarily download the .zip file, extract the desired data, and then discard the .zip file.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Create a temp. file name
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tempfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Use download.file() to fetch the file into the temp. file
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;download.file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://www.bls.gov/cex/pumd/data/comma/diary14.zip&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Use unz() to extract the target file from temp. file
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zip_data2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;diary14/expd141.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Remove the temp file via unlink()
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlink&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;zip_data2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##     NEWID ALLOC COST GIFT PUB_FLAG    UCC EXPNSQDY EXPN_QDY EXPNWKDY   EXPN_KDY
## 1 2825371     0 6.26    2        2 190112        1        D        3        D
## 2 2825371     0 1.20    2        2 190322        1        D        3        D
## 3 2825381     0 0.98    2        2  20510        3        D        2        D
## 4 2825381     0 0.98    2        2  20510        3        D        2        D
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2825381&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2.50&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;        &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;20510&lt;/span&gt;        &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;        &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;multiple&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;multiple-files&quot;&gt;Multiple Files&lt;/h2&gt;
&lt;p&gt;One last common scenario I’ll cover when importing spreadsheet data from online is when we identify multiple data sets that we’d like to download but are not centrally stored in a .zip format or the like. As a simple example lets look at the &lt;a href=&quot;http://www.bls.gov/data/#prices&quot;&gt;average consumer price data&lt;/a&gt; from the BLS. The BLS holds multiple data sets for different types of commodities within one &lt;a href=&quot;http://download.bls.gov/pub/time.series/ap/&quot;&gt;url&lt;/a&gt;; however, there are separate links for each individual data set.  More complicated cases of this will have the links to tabular data sets scattered throughout a webpage&lt;sup&gt;&lt;a href=&quot;#fn2&quot; id=&quot;ref2&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. The &lt;a href=&quot;https://cran.r-project.org/web/packages/XML/index.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;XML&lt;/code&gt;&lt;/a&gt; package provides the useful &lt;code class=&quot;highlighter-rouge&quot;&gt;getHTMLLinks()&lt;/code&gt; function to identify these links.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;XML&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# url hosting multiple links to data sets
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;http://download.bls.gov/pub/time.series/ap/&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# identify the links available
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;links&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getHTMLLinks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;links&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##  [1] &quot;/pub/time.series/&quot;                           
##  [2] &quot;/pub/time.series/ap/ap.area&quot;                 
##  [3] &quot;/pub/time.series/ap/ap.contacts&quot;             
##  [4] &quot;/pub/time.series/ap/ap.data.0.Current&quot;       
##  [5] &quot;/pub/time.series/ap/ap.data.1.HouseholdFuels&quot;
##  [6] &quot;/pub/time.series/ap/ap.data.2.Gasoline&quot;      
##  [7] &quot;/pub/time.series/ap/ap.data.3.Food&quot;          
##  [8] &quot;/pub/time.series/ap/ap.footnote&quot;             
##  [9] &quot;/pub/time.series/ap/ap.item&quot;                 
## [10] &quot;/pub/time.series/ap/ap.period&quot;               
## [11] &quot;/pub/time.series/ap/ap.series&quot;               
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/pub/time.series/ap/ap.txt&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This allows us to assess which files exist that may be of interest.  In this case the links that we are primarily interested in are the ones that contain “data” in their name (links 4-7 listed above).  We can use the &lt;a href=&quot;https://cran.r-project.org/web/packages/stringr/index.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;stringr&lt;/code&gt;&lt;/a&gt; package to extract these desired links which we will use to download the data.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stringr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# extract names for desired links and paste to url
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;links_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;links&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str_detect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;links&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;data&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# paste url to data links to have full url for data sets
# use str_sub and regexpr to paste links at appropriate 
# starting point
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;paste0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;links_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;regexpr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ap.data&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;links_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## [1] &quot;http://download.bls.gov/pub/time.series/ap/ap.data.0.Current&quot;       
## [2] &quot;http://download.bls.gov/pub/time.series/ap/ap.data.1.HouseholdFuels&quot;
## [3] &quot;http://download.bls.gov/pub/time.series/ap/ap.data.2.Gasoline&quot;      
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;http://download.bls.gov/pub/time.series/ap/ap.data.3.Food&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We can now proceed to develop a simple &lt;code class=&quot;highlighter-rouge&quot;&gt;for&lt;/code&gt; loop function to download each data set. We store the results in a list which contains 4 items, one item for each data set.  Each list item contains the url in which the data was extracted from and the dataframe containing the downloaded data.  We’re now ready to analyze these data sets as necessary.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# create empty list to dump data into
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_ls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)){&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.delim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filenames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## List of 4
##  $ :List of 2
##   ..$ url : chr &quot;http://download.bls.gov/pub/time.series/ap/ap.data.0.Current&quot;
##   ..$ data:&#39;data.frame&#39;:	144712 obs. of  5 variables:
##   .. ..$ series_id     : Factor w/ 878 levels &quot;APU0000701111    &quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##   .. ..$ year          : int [1:144712] 1995 1995 1995 1995 1995 1995 1995 1995 1995 1995 ...
##   .. ..$ period        : Factor w/ 12 levels &quot;M01&quot;,&quot;M02&quot;,&quot;M03&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
##   .. ..$ value         : num [1:144712] 0.238 0.242 0.242 0.236 0.244 0.244 0.248 0.255 0.256 0.254 ...
##   .. ..$ footnote_codes: logi [1:144712] NA NA NA NA NA NA ...
##  $ :List of 2
##   ..$ url : chr &quot;http://download.bls.gov/pub/time.series/ap/ap.data.1.HouseholdFuels&quot;
##   ..$ data:&#39;data.frame&#39;:	90339 obs. of  5 variables:
##   .. ..$ series_id     : Factor w/ 343 levels &quot;APU000072511     &quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##   .. ..$ year          : int [1:90339] 1978 1978 1979 1979 1979 1979 1979 1979 1979 1979 ...
##   .. ..$ period        : Factor w/ 12 levels &quot;M01&quot;,&quot;M02&quot;,&quot;M03&quot;,..: 11 12 1 2 3 4 5 6 7 8 ...
##   .. ..$ value         : num [1:90339] 0.533 0.545 0.555 0.577 0.605 0.627 0.656 0.709 0.752 0.8 ...
##   .. ..$ footnote_codes: logi [1:90339] NA NA NA NA NA NA ...
##  $ :List of 2
##   ..$ url : chr &quot;http://download.bls.gov/pub/time.series/ap/ap.data.2.Gasoline&quot;
##   ..$ data:&#39;data.frame&#39;:	69357 obs. of  5 variables:
##   .. ..$ series_id     : Factor w/ 341 levels &quot;APU000074712     &quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##   .. ..$ year          : int [1:69357] 1973 1973 1973 1974 1974 1974 1974 1974 1974 1974 ...
##   .. ..$ period        : Factor w/ 12 levels &quot;M01&quot;,&quot;M02&quot;,&quot;M03&quot;,..: 10 11 12 1 2 3 4 5 6 7 ...
##   .. ..$ value         : num [1:69357] 0.402 0.418 0.437 0.465 0.491 0.528 0.537 0.55 0.556 0.558 ...
##   .. ..$ footnote_codes: logi [1:69357] NA NA NA NA NA NA ...
##  $ :List of 2
##   ..$ url : chr &quot;http://download.bls.gov/pub/time.series/ap/ap.data.3.Food&quot;
##   ..$ data:&#39;data.frame&#39;:	122302 obs. of  5 variables:
##   .. ..$ series_id     : Factor w/ 648 levels &quot;APU0000701111    &quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##   .. ..$ year          : int [1:122302] 1980 1980 1980 1980 1980 1980 1980 1980 1980 1980 ...
##   .. ..$ period        : Factor w/ 12 levels &quot;M01&quot;,&quot;M02&quot;,&quot;M03&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
##   .. ..$ value         : num [1:122302] 0.203 0.205 0.211 0.206 0.207 0.21 0.214 0.215 0.214 0.212 ...
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;   &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;footnote_codes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logi&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;122302&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NA&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;These examples provide the fundamentals required for downloading most tabular and Excel files from online. Each instance likely contains its own peculiarities that will need to be dealt with but getting these basics down will get you the majority of the way there (wherever that might be).&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn1&quot;&gt;1. In &lt;a href=&quot;http://www.amazon.com/Automated-Data-Collection-Practical-Scraping/dp/111883481X/ref=pd_sim_14_1?ie=UTF8&amp;amp;dpID=51Tm7FHxWBL&amp;amp;dpSrc=sims&amp;amp;preST=_AC_UL160_SR108%2C160_&amp;amp;refRID=1VJ1GQEY0VCPZW7VKANX&quot;&gt;Automated Data Collection with R&lt;/a&gt; Munzert et al. state that &quot;[t]he first way to get data from the web is almost too banal to be considered here and actually not a case of web scraping in the narrower sense.&quot;&lt;a href=&quot;#ref1&quot; title=&quot;Jump back to footnote 1 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;

&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn2&quot;&gt;2. An example is provided in &lt;a href=&quot;http://www.amazon.com/Automated-Data-Collection-Practical-Scraping/dp/111883481X/ref=pd_sim_14_1?ie=UTF8&amp;amp;dpID=51Tm7FHxWBL&amp;amp;dpSrc=sims&amp;amp;preST=_AC_UL160_SR108%2C160_&amp;amp;refRID=1VJ1GQEY0VCPZW7VKANX&quot;&gt;Automated Data Collection with R&lt;/a&gt; in which they use a similar approach to extract desired CSV files scattered throughout the &lt;a href=&quot;http://www.elections.state.md.us/elections/2012/election_data/index.html&quot;&gt;Maryland State Board of Elections website&lt;/a&gt;.&lt;a href=&quot;#ref2&quot; title=&quot;Jump back to footnote 2 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;



&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 04 Dec 2015 00:00:00 -0500</pubDate>
        <link>http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2015/12/scraping-tabular-and-excel-files-stored-online.html</link>
        <guid isPermaLink="true">http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2015/12/scraping-tabular-and-excel-files-stored-online.html</guid>
        
        <category>r</category>
        
        <category>gdata</category>
        
        <category>xml</category>
        
        <category>data-importing</category>
        
        <category>web-scraping</category>
        
        
        <category>programming</category>
        
      </item>
    
      <item>
        <title>The Basics of Importing Data</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://bradleyboehmke.github.io/2015/11/the-basics-of-importing-data.html&quot;&gt;
&lt;img src=&quot;https://s3.amazonaws.com/assets.datacamp.com/production/course_690/shields/importing_data_r.png?1450099240&quot; alt=&quot;Importing Data&quot; style=&quot;float:left; margin:3px 8px 5px 0px; width: 19%; height: 19%;&quot; /&gt;&lt;/a&gt;
The first step to any data analysis process is to &lt;em&gt;get&lt;/em&gt; the data.  Data can come from many sources but two of the most common include text &amp;amp; Excel files.  This post covers the basics of importing data into R by reading data from common text files and Excel spreadsheets.  In addition, I cover how to load data from saved R object files when transferring data that has been processed in R.  In addition to the the commonly used base R functions to perform data importing, I will also cover functions from the popular &lt;a href=&quot;https://cran.rstudio.com/web/packages/readr/&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;readr&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;https://cran.rstudio.com/web/packages/xlsx/&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;xlsx&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;https://cran.rstudio.com/web/packages/readxl/&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;readxl&lt;/code&gt;&lt;/a&gt; packages.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tldr&quot;&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;Not enough time to peruse this whole post?  That’s fine; feel free to read only specific sections for some instant gratification.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#csv&quot;&gt;Reading data from text files&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#excel&quot;&gt;Reading data from Excel files&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#robject&quot;&gt;Load data from saved R object files&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#importing_resources&quot;&gt;Additional resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;csv&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;reading-data-from-text-files&quot;&gt;Reading data from text files&lt;/h2&gt;
&lt;p&gt;Text files are a popular way to hold and exchange tabular data as almost any data application supports exporting data to the CSV (or other text file) formats.  Text file formats use delimiters to separate the different elements in a line, and each line of data is in its own line in the text file.  Therefore, importing different text kinds of text files can follow a fairly consistent process once you’ve identified the delimiter.&lt;/p&gt;

&lt;p&gt;There are two main groups of functions that we can use to read in text files:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#base_text_import&quot;&gt;Base R functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#readr_text_import&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;readr&lt;/code&gt; package functions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;base_text_import&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;base-r-functions&quot;&gt;Base R functions&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;read.table()&lt;/code&gt; is a multipurpose work-horse function in base R for importing data.  The functions &lt;code class=&quot;highlighter-rouge&quot;&gt;read.csv()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;read.delim()&lt;/code&gt; are special cases of &lt;code class=&quot;highlighter-rouge&quot;&gt;read.table()&lt;/code&gt; in which the defaults have been adjusted for efficiency.  To illustrate these functions let’s work with a CSV file that is saved in our working directory which looks like:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cheese&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To read in the CSV file we can use &lt;code class=&quot;highlighter-rouge&quot;&gt;read.csv()&lt;/code&gt;.  Note that when we assess the structure of the data set that we read in, &lt;code class=&quot;highlighter-rouge&quot;&gt;variable.2&lt;/code&gt; is automatically coerced to a factor variable and &lt;code class=&quot;highlighter-rouge&quot;&gt;variable.3&lt;/code&gt; is automatically coerced to a logical variable.  Furthermore, any whitespace in the column names are replaced with a “.”.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;mydata&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mydata&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;##   variable.1 variable.2 variable.3
## 1         10       beer       TRUE
## 2         25       wine       TRUE
## 3          8     cheese      FALSE
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mydata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## &#39;data.frame&#39;:	3 obs. of  3 variables:
##  $ variable.1: int  10 25 8
##  $ variable.2: Factor w/ 3 levels &quot;beer&quot;,&quot;cheese&quot;,..: 1 3 2
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variable.3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logi&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;For many reasons we may want to read in &lt;code class=&quot;highlighter-rouge&quot;&gt;variable.2&lt;/code&gt; as a character variable rather then a factor.  We can take care of this by changing the &lt;code class=&quot;highlighter-rouge&quot;&gt;stringsAsFactors&lt;/code&gt; argument.  The default has &lt;code class=&quot;highlighter-rouge&quot;&gt;stringsAsFactors = TRUE&lt;/code&gt;; however, setting it equal to &lt;code class=&quot;highlighter-rouge&quot;&gt;FALSE&lt;/code&gt; will read in the variable as a character variable.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;mydata_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stringsAsFactors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mydata_2&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable.1 variable.2 variable.3
## 1         10       beer       TRUE
## 2         25       wine       TRUE
## 3          8     cheese      FALSE
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mydata_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## &#39;data.frame&#39;:	3 obs. of  3 variables:
##  $ variable.1: int  10 25 8
##  $ variable.2: chr  &quot;beer&quot; &quot;wine&quot; &quot;cheese&quot;
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variable.3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logi&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;As previously stated &lt;code class=&quot;highlighter-rouge&quot;&gt;read.csv&lt;/code&gt; is just a wrapper for &lt;code class=&quot;highlighter-rouge&quot;&gt;read.table&lt;/code&gt; but with adjusted default arguments.  Therefore, we can use &lt;code class=&quot;highlighter-rouge&quot;&gt;read.table&lt;/code&gt; to read in this same data.  The two arguments we need to be aware of are the field separator (&lt;code class=&quot;highlighter-rouge&quot;&gt;sep&lt;/code&gt;) and the argument indicating whether the file contains the names of the variables as its first line (&lt;code class=&quot;highlighter-rouge&quot;&gt;header&lt;/code&gt;).  In &lt;code class=&quot;highlighter-rouge&quot;&gt;read.table&lt;/code&gt; the defaults are &lt;code class=&quot;highlighter-rouge&quot;&gt;sep = &quot;&quot;&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;header = FALSE&lt;/code&gt; whereas in &lt;code class=&quot;highlighter-rouge&quot;&gt;read.csv&lt;/code&gt; the defaults are &lt;code class=&quot;highlighter-rouge&quot;&gt;sep = &quot;,&quot;&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;header = TRUE&lt;/code&gt;.  There are multiple other arguments we can use for certain situations which we illustrate below:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# provides same results as read.csv above
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stringsAsFactors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable.1 variable.2 variable.3
## 1         10       beer       TRUE
## 2         25       wine       TRUE
## 3          8     cheese      FALSE
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# set column and row names
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stringsAsFactors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;col.names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Var 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Var 2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Var 3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;row.names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Row 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Row 2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Row 3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##       Var.1  Var.2 Var.3
## Row 1    10   beer  TRUE
## Row 2    25   wine  TRUE
## Row 3     8 cheese FALSE
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# manually set the classes of the columns 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                          &lt;span class=&quot;n&quot;&gt;colClasses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;numeric&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;character&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;character&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## &#39;data.frame&#39;:	3 obs. of  3 variables:
##  $ variable.1: num  10 25 8
##  $ variable.2: chr  &quot;beer&quot; &quot;wine&quot; &quot;cheese&quot;
##  $ variable.3: chr  &quot;TRUE&quot; &quot;TRUE&quot; &quot;FALSE&quot;
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# limit the number of rows to read in
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nrows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable.1 variable.2 variable.3
## 1         10       beer       TRUE
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;         &lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;       &lt;span class=&quot;n&quot;&gt;wine&lt;/span&gt;       &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In addition to CSV files, there are other text files that &lt;code class=&quot;highlighter-rouge&quot;&gt;read.table&lt;/code&gt; works with.  The primary difference is what separates the elements.  For example, tab delimited text files typically end with the &lt;code class=&quot;highlighter-rouge&quot;&gt;.txt&lt;/code&gt; extension.  You can also use the &lt;code class=&quot;highlighter-rouge&quot;&gt;read.delim()&lt;/code&gt; function as, similiar to &lt;code class=&quot;highlighter-rouge&quot;&gt;read.csv()&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;read.delim()&lt;/code&gt; is a wrapper of &lt;code class=&quot;highlighter-rouge&quot;&gt;read.table()&lt;/code&gt; with defaults set specifically for tab delimited files.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# reading in tab delimited text files
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.delim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable.1 variable.2 variable.3
## 1         10       beer       TRUE
## 2         25       wine       TRUE
## 3          8     cheese      FALSE
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# provides same results as read.delim
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;\t&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable.1 variable.2 variable.3
## 1         10       beer       TRUE
## 2         25       wine       TRUE
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;          &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;cheese&lt;/span&gt;      &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;a name=&quot;readr_text_import&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;readr-package&quot;&gt;readr package&lt;/h3&gt;
&lt;p&gt;Compared to the equivalent base functions, &lt;a href=&quot;https://cran.rstudio.com/web/packages/readr/&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;readr&lt;/code&gt;&lt;/a&gt; functions are around 10x faster. They bring consistency to importing functions, they produce data frames in a &lt;code class=&quot;highlighter-rouge&quot;&gt;data.table&lt;/code&gt; format which are easier to view for large data sets, the default settings removes the “hassels” of &lt;code class=&quot;highlighter-rouge&quot;&gt;stringsAsFactors&lt;/code&gt;, and they have a more flexible column specification.&lt;/p&gt;

&lt;p&gt;To illustrate, we can use &lt;code class=&quot;highlighter-rouge&quot;&gt;read_csv()&lt;/code&gt; which is equivalent to base R’s &lt;code class=&quot;highlighter-rouge&quot;&gt;read.csv()&lt;/code&gt; function.  However, note that &lt;code class=&quot;highlighter-rouge&quot;&gt;read_csv()&lt;/code&gt; maintains the full variable name (whereas &lt;code class=&quot;highlighter-rouge&quot;&gt;read.csv&lt;/code&gt; eliminates any spaces in variable names and fills it with ‘.’).  Also, &lt;code class=&quot;highlighter-rouge&quot;&gt;read_csv()&lt;/code&gt; automatically sets &lt;code class=&quot;highlighter-rouge&quot;&gt;stringsAsFactors = FALSE&lt;/code&gt;, which can be a &lt;a href=&quot;http://simplystatistics.org/2015/07/24/stringsasfactors-an-unauthorized-biography/&quot;&gt;controversial topic&lt;/a&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mydata_3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mydata_3&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable 1 variable 2 variable 3
## 1         10       beer       TRUE
## 2         25       wine       TRUE
## 3          8     cheese      FALSE
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mydata_3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:	3 obs. of  3 variables:
##  $ variable 1: int  10 25 8
##  $ variable 2: chr  &quot;beer&quot; &quot;wine&quot; &quot;cheese&quot;
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logi&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;read_csv&lt;/code&gt; also offers many additional arguments for making adjustments to your data as you read it in:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# specify the column class using col_types
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col_types&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col_double&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; 
                                        &lt;span class=&quot;n&quot;&gt;col_character&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; 
                                        &lt;span class=&quot;n&quot;&gt;col_character&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable 1 variable 2 variable 3
## 1         10       beer       TRUE
## 2         25       wine       TRUE
## 3          8     cheese      FALSE
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# we can also specify column classes with a string
# in this example d = double, _ skips column, c = character
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col_types&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;d_c&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable 1 variable 3
## 1         10       TRUE
## 2         25       TRUE
## 3          8      FALSE
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# set column names
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col_names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Var 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Var 2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Var 3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   Var 1  Var 2 Var 3
## 1    10   beer  TRUE
## 2    25   wine  TRUE
## 3     8 cheese FALSE
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# set the maximum number of lines to read in
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable 1 variable 2 variable 3
## 1         10       beer       TRUE
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;         &lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;       &lt;span class=&quot;n&quot;&gt;wine&lt;/span&gt;       &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Similar to base R, &lt;code class=&quot;highlighter-rouge&quot;&gt;readr&lt;/code&gt; also offers functions to import .txt files (&lt;code class=&quot;highlighter-rouge&quot;&gt;read_delim()&lt;/code&gt;), fixed-width files (&lt;code class=&quot;highlighter-rouge&quot;&gt;read_fwf()&lt;/code&gt;), general text files (&lt;code class=&quot;highlighter-rouge&quot;&gt;read_table()&lt;/code&gt;), and more.&lt;/p&gt;

&lt;p&gt;These examples provide the basics for reading in text files. However, sometimes even text files can offer unanticipated difficulties with their formatting.  Both the base R and &lt;code class=&quot;highlighter-rouge&quot;&gt;readr&lt;/code&gt; functions offer many arguments to deal with different formatting issues and I suggest you take time to look at the help files for these functions to learn more (i.e. &lt;code class=&quot;highlighter-rouge&quot;&gt;?read.table&lt;/code&gt;).  Also, you will find more resources at the end of this chapter for importing files.&lt;sup&gt;&lt;a href=&quot;#fn1&quot; id=&quot;ref1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;excel&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;reading-data-from-excel-files&quot;&gt;Reading data from Excel files&lt;/h2&gt;
&lt;p&gt;With Excel still being the spreadsheet software of choice its important to be able to efficiently import and export data from these files.  Often, R users will simply resort to exporting the Excel file as a CSV file and then import into R using &lt;code class=&quot;highlighter-rouge&quot;&gt;read.csv&lt;/code&gt;; however, this is far from efficient.  This section will teach you how to eliminate the CSV step and to import data directly from Excel using two different packages:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#xlsx_import&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;xlsx&lt;/code&gt; package&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#readxl_import&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;readxl&lt;/code&gt; package&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that there are several packages available to connect R with Excel (i.e. &lt;code class=&quot;highlighter-rouge&quot;&gt;gdata&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;RODBC&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;XLConnect&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;RExcel&lt;/code&gt;, etc.); however, I am only going to cover the two main packages that I use which provide all the fundamental requirements I’ve needed for dealing with Excel.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;xlsx_import&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;xlsx-package&quot;&gt;xlsx package&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&quot;https://cran.rstudio.com/web/packages/xlsx/&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;xlsx&lt;/code&gt;&lt;/a&gt; package provides tools neccessary to interact with Excel 2007 (and older) files from R. Many of the benefits of the &lt;code class=&quot;highlighter-rouge&quot;&gt;xlsx&lt;/code&gt; come from being able to &lt;em&gt;export&lt;/em&gt; and &lt;em&gt;format&lt;/em&gt; Excel files from R.  Some of these capabilities will be covered in a later post on exporting data; however, in this post we will simply cover &lt;em&gt;importing&lt;/em&gt; data from Excel with the &lt;code class=&quot;highlighter-rouge&quot;&gt;xlsx&lt;/code&gt; package.&lt;/p&gt;

&lt;p&gt;To illustrate, we’ll use similar data from the &lt;a href=&quot;#base_text_import&quot;&gt;previous section&lt;/a&gt;; however, saved as an .xlsx file in our working director.  To import the Excel data we simply use the &lt;code class=&quot;highlighter-rouge&quot;&gt;read.xlsx()&lt;/code&gt; function:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlsx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# read in first worksheet using an sheet index or name
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.xlsx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheetName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable.1 variable.2 variable.3
## 1         10       beer       TRUE
## 2         25       wine       TRUE
## 3          8     cheese      FALSE
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;read.xlsx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheetIndex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable.1 variable.2 variable.3
## 1         10       beer       TRUE
## 2         25       wine       TRUE
## 3          8     cheese      FALSE
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# read in second worksheet
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.xlsx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheetName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable.4 variable.5
## 1     Dayton     johnny
## 2   Columbus      amber
## 3  Cleveland       tony
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Cincinnati&lt;/span&gt;      &lt;span class=&quot;n&quot;&gt;alice&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Since Excel is such a flexible spreadsheet software, people often make notes, comments, headers, etc. at the beginning or end of the files which we may not want to include.  If we want to read in data that starts further down in the Excel worksheet we can include the &lt;code class=&quot;highlighter-rouge&quot;&gt;startRow&lt;/code&gt; argument.  If we have a specific range of rows (or columns) to include we can use the &lt;code class=&quot;highlighter-rouge&quot;&gt;rowIndex&lt;/code&gt; (or &lt;code class=&quot;highlighter-rouge&quot;&gt;colIndex&lt;/code&gt;) argument.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# a worksheet with comments in the first two lines
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.xlsx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheetName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##                                         HEADER..COMPANY.A        NA.
## 1 What if we want to disregard header text in Excel file?       &amp;lt;NA&amp;gt;
## 2                                              variable 6 variable 7
## 3                                                     200       Male
## 4                                                     225     Female
## 5                                                     400     Female
## 6                                                     310       Male
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# read in all data below the second line
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.xlsx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheetName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;startRow&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable.6 variable.7
## 1        200       Male
## 2        225     Female
## 3        400     Female
## 4        310       Male
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# read in a range of rows
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.xlsx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheetName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowIndex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable.6 variable.7
## 1        200       Male
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;        &lt;span class=&quot;m&quot;&gt;225&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;Female&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We can also change the class type of the columns when we read them in:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# read in all data below the second line
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mydata_sheet1.1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.xlsx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheetName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mydata_sheet1.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## &#39;data.frame&#39;:	3 obs. of  3 variables:
##  $ variable.1: num  10 25 8
##  $ variable.2: Factor w/ 3 levels &quot;beer&quot;,&quot;cheese&quot;,..: 1 3 2
##  $ variable.3: logi  TRUE TRUE FALSE
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mydata_sheet1.2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.xlsx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheetName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                             &lt;span class=&quot;n&quot;&gt;stringsAsFactors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                             &lt;span class=&quot;n&quot;&gt;colClasses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;double&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;character&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;logical&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mydata_sheet1.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## &#39;data.frame&#39;:	3 obs. of  3 variables:
##  $ variable.1: num  10 25 8
##  $ variable.2: chr  &quot;beer&quot; &quot;wine&quot; &quot;cheese&quot;
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variable.3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logi&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Another useful argument is &lt;code class=&quot;highlighter-rouge&quot;&gt;keepFormulas&lt;/code&gt; which allows to see the text of any formulas in the Excel spreadsheet:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# by default keepFormula is set to FALSE so only
# the formula output will be read in
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.xlsx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheetName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet4&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   Future.Value  Rate Periods Present.Value
## 1          500 0.065      10      266.3630
## 2          600 0.085       6      367.7671
## 3          750 0.080      11      321.6621
## 4         1000 0.070      16      338.7346
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# changing the keepFormula to TRUE will display the equations
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.xlsx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheetName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet4&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepFormulas&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   Future.Value  Rate Periods Present.Value
## 1          500 0.065      10  A2/(1+B2)^C2
## 2          600 0.085       6  A3/(1+B3)^C3
## 3          750 0.080      11  A4/(1+B4)^C4
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;         &lt;span class=&quot;m&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.070&lt;/span&gt;      &lt;span class=&quot;m&quot;&gt;16&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;A5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C5&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;a name=&quot;readxl_import&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;readxl-package&quot;&gt;readxl package&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://cran.rstudio.com/web/packages/readxl/&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;readxl&lt;/code&gt;&lt;/a&gt; is one of the newest packages for accessing Excel data with R and was developed by &lt;a href=&quot;https://twitter.com/hadleywickham&quot;&gt;Hadley Wickham&lt;/a&gt; and the &lt;a href=&quot;https://www.rstudio.com/&quot;&gt;RStudio&lt;/a&gt; team who also developed the &lt;code class=&quot;highlighter-rouge&quot;&gt;readr&lt;/code&gt; package.  This package works with both legacy .xls formats and the modern xml-based .xlsx format.  Similar to &lt;code class=&quot;highlighter-rouge&quot;&gt;readr&lt;/code&gt; the &lt;code class=&quot;highlighter-rouge&quot;&gt;readxl&lt;/code&gt; functions are based on a C++ library so they are extremely fast. Unlike most other packages that deal with Excel, &lt;code class=&quot;highlighter-rouge&quot;&gt;readxl&lt;/code&gt; has no external dependencies, so you can use it to read Excel data on just about any platform.  Additional benefits &lt;code class=&quot;highlighter-rouge&quot;&gt;readxl&lt;/code&gt; provides includes the ability to load dates and times as POSIXct formatted dates, automatically drops blank columns, and returns outputs as data.table formatted which provides easier viewing for large data sets.&lt;/p&gt;

&lt;p&gt;To read in Excel data with &lt;code class=&quot;highlighter-rouge&quot;&gt;readxl&lt;/code&gt; you use the &lt;code class=&quot;highlighter-rouge&quot;&gt;read_excel()&lt;/code&gt; function which has very similar operations and arguments as &lt;code class=&quot;highlighter-rouge&quot;&gt;xlsx&lt;/code&gt;.  A few important differences you will see below include: &lt;code class=&quot;highlighter-rouge&quot;&gt;readxl&lt;/code&gt; will automatically convert date and date-time variables to POSIXct formatted variables, character variables will not be coerced to factors, and logical variables will be read in as integers.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readxl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;mydata&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_excel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet5&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mydata&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable 1 variable 2 variable 3 variable 4          variable 5
## 1         10       beer          1      42328 2015-11-20 13:30:00
## 2         25       wine          1         NA 2015-11-21 16:30:00
## 3          8       &amp;lt;NA&amp;gt;          0      42330 2015-11-22 14:45:00
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mydata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:	3 obs. of  5 variables:
##  $ variable 1: num  10 25 8
##  $ variable 2: chr  &quot;beer&quot; &quot;wine&quot; NA
##  $ variable 3: num  1 1 0
##  $ variable 4: num  42328 NA 42330
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;POSIXct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;2015-11-20 13:30:00&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The available arguments allow you to change the data as you import it.  Some examples are provided:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readxl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# change variable names by skipping the first row
# and using col_names to set the new names
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_excel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet5&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
           &lt;span class=&quot;n&quot;&gt;col_names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;paste&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Var&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   Var 1 Var 2 Var 3 Var 4               Var 5
## 1    10  beer     1 42328 2015-11-20 13:30:00
## 2    25  wine     1    NA 2015-11-21 16:30:00
## 3     8  &amp;lt;NA&amp;gt;     0 42330 2015-11-22 14:45:00
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# sometimes missing values are set as a sentinel value
# rather than just left blank - (i.e. &quot;999&quot;)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_excel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet6&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable 1 variable 2 variable 3 variable 4
## 1         10       beer          1      42328
## 2         25       wine          1        999
## 3          8        999          0      42330
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# we can change these to missing values with na argument
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_excel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet6&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;na&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;999&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable 1 variable 2 variable 3 variable 4
## 1         10       beer          1      42328
## 2         25       wine          1         NA
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;          &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;       &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;          &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;      &lt;span class=&quot;m&quot;&gt;42330&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;One unique difference between &lt;code class=&quot;highlighter-rouge&quot;&gt;readxl&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;xlsx&lt;/code&gt; is how to deal with column types.  Whereas &lt;code class=&quot;highlighter-rouge&quot;&gt;read.xlsx()&lt;/code&gt; allows you to change the column types to integer, double, numeric, character, or logical; &lt;code class=&quot;highlighter-rouge&quot;&gt;read_excel()&lt;/code&gt; restricts you to changing column types to blank, numeric, date, or text.  The “blank” option allows you to skip columns; however, to change variable 3 to a logical &lt;code class=&quot;highlighter-rouge&quot;&gt;TRUE&lt;/code&gt;/&lt;code class=&quot;highlighter-rouge&quot;&gt;FALSE&lt;/code&gt; variable requires a second step.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;mydata_ex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_excel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.xlsx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sheet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Sheet5&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;col_types&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;numeric&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;blank&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;numeric&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;blank&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mydata_ex&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable 1 variable 3 variable 4
## 1         10          1 2015-11-20
## 2         25          1       &amp;lt;NA&amp;gt;
## 3          8          0 2015-11-22
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# change variable 3 to a logical variable
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mydata_ex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`variable 3`&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as.logical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mydata_ex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`variable 3`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mydata_ex&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;##   variable 1 variable 3 variable 4
## 1         10       TRUE 2015-11-20
## 2         25       TRUE       &amp;lt;NA&amp;gt;
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;          &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;      &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2015-11-22&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;robject&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;load-data-from-saved-r-object-files&quot;&gt;Load data from saved R object files&lt;/h2&gt;
&lt;p&gt;Sometimes you may need to save data or other R objects outside of your workspace.  You may want to share R data/objects with co-workers, transfer between projects or computers, or simply archive them.  There are three primary ways that people tend to save R data/objects: as .RData, .rda, or as .rds files.  The differences behind when you use each will be covered in a later post that will focus on saving data as an R object file.  This section simply shows how to load these data/object forms.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.RData&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;mydata.rda&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;readRDS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mydata.rds&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;importing_resources&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;additional-resources&quot;&gt;Additional resources&lt;/h2&gt;
&lt;p&gt;In addition to text and Excel files, there are multiple other ways in which data is stored and exchanged.  Commercial statistical software such as SPSS, SAS, Stata, and Minitab often have the option to store data in a specific format for that software.  In addition, analysts commonly use databases to store large quantities of data.  R has good support to work with these additional options which we did not cover here.  The following provides a list of additional resources to learn about data importing for these specific cases:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://cran.r-project.org/doc/manuals/R-data.html&quot;&gt;R data import/export manual&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cran.r-project.org/doc/manuals/R-data.html#Relational-databases&quot;&gt;Working with databases&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://cran.r-project.org/web/packages/RMySQL/index.html&quot;&gt;MySQL&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://cran.r-project.org/web/packages/ROracle/index.html&quot;&gt;Oracle&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://cran.r-project.org/web/packages/RPostgreSQL/index.html&quot;&gt;PostgreSQL&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://cran.r-project.org/web/packages/RSQLite/index.html&quot;&gt;SQLite&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://cran.rstudio.com/web/packages/RODBC/&quot;&gt;Open Database Connectivity databases&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cran.r-project.org/doc/manuals/R-data.html#Importing-from-other-statistical-systems&quot;&gt;Importing data from commercial software&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;The &lt;a href=&quot;http://www.rdocumentation.org/packages/foreign&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;foreign&lt;/code&gt;&lt;/a&gt; package provides functions that help you load data files from other programs such as &lt;a href=&quot;http://www.r-bloggers.com/how-to-open-an-spss-file-into-r/&quot;&gt;SPSS&lt;/a&gt;, &lt;a href=&quot;http://rconvert.com/sas-vs-r-code-compare/5-ways-to-convert-sas-data-to-r/&quot;&gt;SAS&lt;/a&gt;, &lt;a href=&quot;http://www.r-bloggers.com/how-to-read-and-write-stata-data-dta-files-into-r/&quot;&gt;Stata&lt;/a&gt;, and others into R.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;#&quot;&gt;Go to top&lt;/a&gt;&lt;/small&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p class=&quot;footnote&quot; style=&quot;line-height:0.75&quot;&gt;
&lt;sup id=&quot;fn1&quot;&gt;1. These same arguments can be used in `read.table`, `read.csv`, and `read.delim`&lt;a href=&quot;#ref1&quot; title=&quot;Jump back to footnote 1 in the text.&quot;&gt;&quot;&amp;#8617;&quot;&lt;/a&gt;&lt;sup&gt;





&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 22 Nov 2015 00:00:00 -0500</pubDate>
        <link>http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2015/11/the-basics-of-importing-data.html</link>
        <guid isPermaLink="true">http://bradleyboehmke.github.io/http://bradleyboehmke.github.io//2015/11/the-basics-of-importing-data.html</guid>
        
        <category>r</category>
        
        <category>readr</category>
        
        <category>readxl</category>
        
        <category>xlsx</category>
        
        <category>data-importing</category>
        
        
        <category>programming</category>
        
      </item>
    
  </channel>
</rss>
